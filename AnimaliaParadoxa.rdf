<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns:z="http://www.zotero.org/namespaces/export#"
 xmlns:foaf="http://xmlns.com/foaf/0.1/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:dcterms="http://purl.org/dc/terms/"
 xmlns:bib="http://purl.org/net/biblio#"
 xmlns:link="http://purl.org/rss/1.0/modules/link/"
 xmlns:vcard="http://nwalsh.com/rdf/vCard#"
 xmlns:prism="http://prismstandard.org/namespaces/1.2/basic/">
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/tdunning/buzz-wordsdunningmultimodalrecommendation">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Dunning</foaf:surname>
                        <foaf:givenname>Ted</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <dc:title>Multi-Modal Recommendation</dc:title>
        <dcterms:abstract>Multi-model recommendation engines use multiple kinds of behavior as input and can be implemented using standard search engine technology.  I show how and why starting with basic recommendations all the way through full multi-modal systems.</dcterms:abstract>
        <z:type>Technology</z:type>
        <dc:date>Wed Jun 05  2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/tdunning/buzz-wordsdunningmultimodalrecommendation</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-10 16:32:31</dcterms:dateSubmitted>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/tdunning/dfw-big-data-talk-on-mahout-recommenders">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Dunning</foaf:surname>
                        <foaf:givenname>Ted</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <link:link rdf:resource="#item_1224"/>
        <dc:title>Introduction to Mahout and How To Build a Recommender</dc:title>
        <dcterms:abstract>This talk focussed on how to build recommenders using new technology and capabilities from Mahout.  The key here is that recommenders can be built much more easily than you might expect.</dcterms:abstract>
        <z:type>Technology</z:type>
        <dc:date>Sat Aug 24  2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/tdunning/dfw-big-data-talk-on-mahout-recommenders</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-10 16:33:55</dcterms:dateSubmitted>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <z:Attachment rdf:about="#item_1224">
        <z:itemType>attachment</z:itemType>
        <dc:title>Dunning_2013_Introduction_to_Mahout_and_How_To_Build_a_Recommender.pptx</dc:title>
        <link:type>application/vnd.openxmlformats-officedocument.presentationml.presentation</link:type>
    </z:Attachment>
    <bib:Document rdf:about="http://omel.ette.org/blog/2013/02/06/debug-servlets/">
        <z:itemType>webpage</z:itemType>
        <dcterms:isPartOf>
           <z:Website></z:Website>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Zeyliger</foaf:surname>
                        <foaf:givenname>Philip</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_65"/>
        <dc:title>Debug Servlets, or 'HTTP won; use it' - philz</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://omel.ette.org/blog/2013/02/06/debug-servlets/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Document>
    <z:Attachment rdf:about="#item_65">
        <z:itemType>attachment</z:itemType>
        <dc:title>Debug Servlets, or 'HTTP Won; U - Philip Zeyliger.azw3</dc:title>
        <link:type>application/octet-stream</link:type>
    </z:Attachment>
    <bib:Data rdf:about="https://github.com/open-city/dedupe">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Gregg</foaf:surname>
                        <foaf:givenname>Forest</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Eder</foaf:surname>
                        <foaf:givenname>Derek</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Dedupe</dc:title>
        <dcterms:abstract>dedupe - A free python library for accurate and scaleable data deduplication and entity-resolution.</dcterms:abstract>
        <dc:date>21:21:44</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/open-city/dedupe</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 21:21:44</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/lintool/Cloud9">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lin</foaf:surname>
                        <foaf:givenname>Jimmy</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Cloud9</dc:title>
        <dcterms:abstract>Cloud9 is a Hadoop toolkit for working with big data</dcterms:abstract>
        <dc:date>10:20:25</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/lintool/Cloud9</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 10:20:25</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="http://druid.io/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Metamarkets</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Druid</dc:title>
        <dcterms:abstract>Real²time Exploratory Analytics on Large Datasets</dcterms:abstract>
        <dc:identifier>
           <dcterms:URI><rdf:value>http://druid.io/</rdf:value></dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/continuuity/weave">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Continuuity</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Weave</dc:title>
        <dcterms:abstract>weave - Weave : Running YARN apps is as easy as running Java threads.</dcterms:abstract>
        <dc:date>17:30:30</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/continuuity/weave</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-28 17:30:30</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Book rdf:about="urn:isbn:1585009709%20%209781585009701">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Bloomington, Ind.</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>1st Books Library</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kent</foaf:surname>
                        <foaf:givenname>William</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Data and reality</dc:title>
        <dc:date>2000</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 1585009709  9781585009701</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Document rdf:about="http://info.lucidworks.com/blog/bid/272738/Pig-and-HBase-with-LucidWorks-Big-Data">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Arthur</foaf:surname>
                        <foaf:givenname>David</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>
           <z:AutomaticTag><rdf:value>BigData</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Hadoop</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>hbase</dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>HBaseStorage</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>LucidWorks</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Pig</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>Pig</dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Search</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>UDF</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:title>Pig and HBase with LucidWorks Big Data</dc:title>
        <dcterms:abstract>HBase gives you fast random access to your data and Pig makes it very easy to process heterogeneous data sets. This bridge between the two lays the foundation of a very powerful big data processing pipeline.</dcterms:abstract>
        <dc:date>20:07:13</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://info.lucidworks.com/blog/bid/272738/Pig-and-HBase-with-LucidWorks-Big-Data</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-23 20:07:13</dcterms:dateSubmitted>
    </bib:Document>
    <bib:Data rdf:about="http://www.bigsql.org/se/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>OpenSCG</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>hadoop</dc:subject>
        <dc:subject>postgresql</dc:subject>
        <dc:title>BigSQL</dc:title>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://www.bigsql.org/se/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Data>
    <bib:Data rdf:about="http://johnmacfarlane.net/pandoc/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Macfarlane</foaf:surname>
                        <foaf:givenname>John</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Pandoc</dc:title>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://johnmacfarlane.net/pandoc/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-16 07:14:11</dcterms:dateSubmitted>
    </bib:Data>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/oom65/orc-andvectorizationhadoopsummit?ref=http://www.slideshare.net/slideshow/embed_code/23625246">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>O'Malley</foaf:surname>
                        <foaf:givenname>Owen</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <dc:title>ORC File and Vectorization - Hadoop Summit 2013</dc:title>
        <dcterms:abstract>Eric Hanson and I gave this presentation at Hadoop Summit 2013:

Hive’s RCFile has been the standard format for storing Hive data for the last 3 years. However, RCFile has limitations because it treats each column as a binary blob without semantics. Hive 0.11 added a new file format named Optimized Row Columnar (ORC) file that uses and retains the type information from the table definition. ORC uses type specific readers and writers that provide light weight compression techniques such as dictionary encoding, bit packing, delta encoding, and run length encoding — resulting in dramatically smaller files. Additionally, ORC can apply generic compression using zlib, LZO, or Snappy on top of the lightweight compression for even smaller files. However, storage savings are only part of the gain. ORC supports projection, which selects subsets of the columns for reading, so that queries reading only one column read only the required bytes. Furthermore, ORC files include light weight indexes that include the minimum and maximum values for each column in each set of 10,000 rows and the entire file. Using pushdown filters from Hive, the file reader can skip entire sets of rows that aren’t important for this query.
Columnar storage formats like ORC reduce I/O and storage use, but it’s just as important to reduce CPU usage. A technical breakthrough called vectorized query execution works nicely with column store formats to do this. Vectorized query execution has proven to give dramatic performance speedups, on the order of 10X to 100X, for structured data processing. We describe how we’re adding vectorized query execution to Hive, coupling it with ORC with a vectorized iterator.</dcterms:abstract>
        <dc:date>Fri Jun 28  2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/oom65/orc-andvectorizationhadoopsummit?ref=http://www.slideshare.net/slideshow/embed_code/23625246</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-24 13:49:58</dcterms:dateSubmitted>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <bib:Data rdf:about="http://mesos.apache.org/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Apache Software Foundation</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Apache Mesos</dc:title>
        <dcterms:abstract>Apache Mesos is a cluster manager that provides efficient resource isolation and sharing across distributed applications, or frameworks. It can run Hadoop, MPI, Hypertable, Spark, and other applications on a dynamically shared pool of nodes.</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://mesos.apache.org/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
    </bib:Data>
    <bib:Manuscript rdf:about="http://lintool.github.io/MapReduceAlgorithms/index.html">
        <z:itemType>manuscript</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lin</foaf:surname>
                        <foaf:givenname>Jimmy</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Dyer</foaf:surname>
                        <foaf:givenname>Chris</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_409"/>
        <dc:title>Data-intensive text processing with MapReduce</dc:title>
        <dcterms:abstract>Our world is being revolutionized by data-driven methods: access to large amounts of data has generated new insights and opened exciting new opportunities in commerce, science, and computing applications. Processing the enormous quantities of data necessary for these advances requires large clusters, making distributed computing paradigms more crucial than ever. MapReduce is a programming model for expressing distributed computations on massive datasets and an execution framework for large-scale data processing on clusters of commodity servers. The programming model provides an easy-to-understand abstraction for designing scalable algorithms, while the execution framework transparently handles many system-level details, ranging from scheduling to synchronization to fault tolerance. This book focuses on MapReduce algorithm design, with an emphasis on text processing algorithms common in natural language processing, information retrieval, and machine learning. We introduce the notion of MapReduce design patterns, which represent general reusable solutions to commonly occurring problems across a variety of problem domains. This book not only intends to help the reader &quot;think in MapReduce&quot;, but also discusses limitations of the programming model as well.</dcterms:abstract>
        <dc:date>17:36:09</dc:date>
        <z:language>English</z:language>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://lintool.github.io/MapReduceAlgorithms/index.html</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-28 17:36:09</dcterms:dateSubmitted>
    </bib:Manuscript>
    <z:Attachment rdf:about="#item_409">
        <z:itemType>attachment</z:itemType>
        <dc:title>Lin_Dyer_0000_Data-intensive_text_processing_with_MapReduce.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Document rdf:about="http://www.packtpub.com/article/overview-complex-event-processing">
        <z:itemType>webpage</z:itemType>
        <dcterms:isPartOf>
           <z:Website></z:Website>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Alves</foaf:surname>
                        <foaf:givenname>Alexandre</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Williams</foaf:surname>
                        <foaf:givenname>Lloyd</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Smith</foaf:surname>
                        <foaf:givenname>Robin J.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_16"/>
        <dc:subject>CEP</dc:subject>
        <dc:title>An Overview of Complex Event Processing</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.packtpub.com/article/overview-complex-event-processing</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Document>
    <z:Attachment rdf:about="#item_16">
        <z:itemType>attachment</z:itemType>
        <dc:title>An Overview of Complex Event Pr - Alexandre Alves.azw3</dc:title>
        <link:type>application/octet-stream</link:type>
    </z:Attachment>
    <bib:Data rdf:about="http://esper.codehaus.org/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>EsperTech</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>java</dc:subject>
        <dc:title>Esper</dc:title>
        <dcterms:abstract>Complex Event Processing</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://esper.codehaus.org/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Data>
    <bib:Book rdf:about="urn:isbn:1449327052">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Sebastopol, CA</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Sammer</foaf:surname>
                        <foaf:givenname>Eric</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_157"/>
        <dc:title>Hadoop operations</dc:title>
        <dc:date>2012</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 1449327052</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <z:Attachment rdf:about="#item_157">
        <z:itemType>attachment</z:itemType>
        <dc:title>Hadoop Operations - Eric Sammer.epub</dc:title>
        <link:type>application/octet-stream</link:type>
    </z:Attachment>
    <bib:Document rdf:about="http://hortonworks.com/blog/a-set-of-hadoop-related-icons/?mkt_tok=3RkMMJWWfF9wsRoiua7OZKXonjHpfsX54%2BgvXKG%2FlMI%2F0ER3fOvrPUfGjI4CTsdjI%2BSLDwEYGJlv6SgFT7TMMbFh1rgNUxc%3D">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Hortonworks</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>toread</dc:subject>
        <dc:title>Hadoop Icons</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://hortonworks.com/blog/a-set-of-hadoop-related-icons/?mkt_tok=3RkMMJWWfF9wsRoiua7OZKXonjHpfsX54%2BgvXKG%2FlMI%2F0ER3fOvrPUfGjI4CTsdjI%2BSLDwEYGJlv6SgFT7TMMbFh1rgNUxc%3D</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=1</dc:description>
    </bib:Document>
    <bib:Document rdf:about="http://www.business2community.com/big-data/warren-buffett-the-human-big-data-engine-0484510">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog><dc:title>Business 2 Community</dc:title></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Damarla</foaf:surname>
                        <foaf:givenname>Chanu</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>Decision making</dc:subject>
        <dc:title>Warren Buffett, The Human Big Data Engine</dc:title>
        <dc:date>08:30:54</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.business2community.com/big-data/warren-buffett-the-human-big-data-engine-0484510</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-24 08:30:54</dcterms:dateSubmitted>
    </bib:Document>
    <bib:Data rdf:about="https://github.com/mesosphere/marathon">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Mesosphere</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Marathon</dc:title>
        <dcterms:abstract>marathon - An Apache Mesos framework for long-running services.</dcterms:abstract>
        <dc:date>21:27:42</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/mesosphere/marathon</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 21:27:42</dcterms:dateSubmitted>
    </bib:Data>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/r39132/linkedins-segmentation-targeting-platform?ref=http://eventifier.co/event/hadoopsummit2013/slides">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Anand</foaf:surname>
                        <foaf:givenname>Sid</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <link:link rdf:resource="#item_414"/>
        <dc:title>LinkedIn's Segmentation &amp; Targeting Platform</dc:title>
        <dcterms:abstract>This presentation was presented at Hadoop Summit 2013 on June 26, 2013 by Sid Anand and Hien Luu of LinkedIn.</dcterms:abstract>
        <z:type>Business &amp; Mgmt</z:type>
        <dc:date>Wed Jun 26  2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/r39132/linkedins-segmentation-targeting-platform?ref=http://eventifier.co/event/hadoopsummit2013/slides</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-24 17:05:21</dcterms:dateSubmitted>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <z:Attachment rdf:about="#item_414">
        <z:itemType>attachment</z:itemType>
        <dc:title>Anand_2013_LinkedIn's_Segmentation_&amp;_Targeting_Platform.pptx</dc:title>
        <link:type>application/vnd.openxmlformats-officedocument.presentationml.presentation</link:type>
    </z:Attachment>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/r39132/q-con-ny2013modernwebsitescalabilityfinal-22989785">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Sid Anand</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <dc:title>Building a Modern Website for Scale (QCon NY 2013)</dc:title>
        <dcterms:abstract>My talk on how LinkedIn scales for high-traffic and high-availability at QCon NY 2013</dcterms:abstract>
        <z:type>Design</z:type>
        <dc:date>Fri Jun 14  2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/r39132/q-con-ny2013modernwebsitescalabilityfinal-22989785</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-02 14:02:27</dcterms:dateSubmitted>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <bib:Book rdf:about="urn:isbn:1449302645%209781449302641">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Sebastopol, CA</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Gates</foaf:surname>
                        <foaf:givenname>Alan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Programming Pig</dc:title>
        <dcterms:abstract>Annotation</dcterms:abstract>
        <dc:date>2011</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 1449302645 9781449302641</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://proquest.safaribooksonline.com/?fpi=9781449317881</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-27 08:48:14</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Document rdf:about="http://www.thecloudavenue.com/2012/10/debugging-hadoop-mapreduce-program-in.html">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Sripati</foaf:surname>
                        <foaf:givenname>Praveen</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>eclipse</dc:subject>
        <dc:title>Hadoop Tips: Debugging a Hadoop MapReduce Program in Eclipse</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.thecloudavenue.com/2012/10/debugging-hadoop-mapreduce-program-in.html</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Document>
    <bib:Document rdf:about="http://blog.cloudera.com/blog/2013/08/how-to-use-eclipse-with-mapreduce-in-clouderas-quickstart-vm/">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Anderson</foaf:surname>
                        <foaf:givenname>Jesse</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>eclipse</dc:subject>
        <dc:title>How-to: Use Eclipse with MapReduce in Cloudera's QuickStart VM</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://blog.cloudera.com/blog/2013/08/how-to-use-eclipse-with-mapreduce-in-clouderas-quickstart-vm/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Document>
    <bib:Document rdf:about="http://blog.cloudera.com/blog/2012/08/developing-cdh-applications-with-maven-and-eclipse/">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Natkins</foaf:surname>
                        <foaf:givenname>Jon</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>eclipse</dc:subject>
        <dc:title>How-to: Develop CDH Applications with Maven and Eclipse</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://blog.cloudera.com/blog/2012/08/developing-cdh-applications-with-maven-and-eclipse/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Document>
    <bib:Document rdf:about="http://www.mapr.com/blog/basic-notes-on-configuring-eclipse-as-a-hadoop-development-environment-for-mapr">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Botzum</foaf:surname>
                        <foaf:givenname>Keys</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>eclipse</dc:subject>
        <dc:title>Basic Notes on Configuring Eclipse as a Hadoop Development Environment for MapR</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.mapr.com/blog/basic-notes-on-configuring-eclipse-as-a-hadoop-development-environment-for-mapr</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Document>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/r39132/linkedin-data-infrastructure-slides-version-2-13394853">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Sid Anand</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <dc:title>LinkedIn Data Infrastructure Slides (Version 2)</dc:title>
        <dcterms:abstract>Learn about Espresso, Databus, and Voldemort. LinkedIn Data Infrastructure Slides (Version 2). This talk was given in NYC on June 20, 2012You can download the slides as PPT in order to see the transitions here :http://bit.ly/LfH6Ru</dcterms:abstract>
        <dc:date>Thu Jun 21  2012</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/r39132/linkedin-data-infrastructure-slides-version-2-13394853</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-02 14:02:38</dcterms:dateSubmitted>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <bib:Document rdf:about="http://continuum.io/blog/iopro-pyodbc-performance">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Villellas</foaf:surname>
                        <foaf:givenname>Oscar</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>datasource</dc:subject>
        <dc:subject>python</dc:subject>
        <dc:title>Faster, More Memory Efficient SQL queries via IOPro</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://continuum.io/blog/iopro-pyodbc-performance</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Document>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/hortonworks/hadoop-patterns-of-use">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Hortonworks</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <link:link rdf:resource="#item_443"/>
        <dc:title>Hadoop Patterns of Use</dc:title>
        <dcterms:abstract>DOWNLOAD the whitepaper here: http://hortonworks.com/wp-content/plugins/download-monitor/download.php?id=71

As an organization laser focused on developing, distributing and supporting Apache Hadoop for enterprise customers, we have been fortunate to have a unique vantage point.

We’re delighted to share with you these slides and our new whitepaper ‘Apache Hadoop Patterns of Use’. The patterns discussed in the slides and whitepaper are:

Refine: Collect data and apply a known algorithm to it in a trusted operational process.
Explore: Collect data and perform iterative investigation for value.
Enrich: Collect data, analyze and present salient results for online apps.

We hope you enjoy the content.</dcterms:abstract>
        <z:type>Business &amp; Mgmt</z:type>
        <dc:date>Wed Apr 10  2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/hortonworks/hadoop-patterns-of-use</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-25 20:51:13</dcterms:dateSubmitted>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <z:Attachment rdf:about="#item_443">
        <z:itemType>attachment</z:itemType>
        <dc:title>Hortonworks_2013_Hadoop_Patterns_of_Use.pptx</dc:title>
        <link:type>application/vnd.openxmlformats-officedocument.presentationml.presentation</link:type>
    </z:Attachment>
    <bib:Report rdf:about="http://bigdata.infochimps.com/Portals/174427/docs/bigdataprojecthowto.pdf">
        <z:itemType>report</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Infochimps</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>data</dc:subject>
        <dc:title>How to Do a Big Data Project</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://bigdata.infochimps.com/Portals/174427/docs/bigdataprojecthowto.pdf</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=1; TOREAD=0</dc:description>
    </bib:Report>
    <bib:Book rdf:about="urn:isbn:9781449319335%201449319335">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Sebastopol, CA</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly &amp; Associates</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Capriolo</foaf:surname>
                        <foaf:givenname>Edward</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Wampler</foaf:surname>
                        <foaf:givenname>Dean</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Rutherglen</foaf:surname>
                        <foaf:givenname>Jason</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_78"/>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Apache Hadoop</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Apache Hive (Data warehouse system)</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Data warehousing</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Database management</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Hive QL (Computer program language)</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:title>Programming Hive</dc:title>
        <dcterms:abstract>&quot;Need to move a relational database application to Hadoop? This comprehensive guide introduces you to Apache Hive, Hadoop's data warehouse infrastructure. You'll quickly learn how to use Hive's SQL dialect- Hive QL- to summarize, query, and analyze large datasets stored in Hadoop's distributed filesystem. This example-driven guide shows you how to set up and configure Hive in your environment, provides detailed overview of Hadoop and MapReduce, and demonstrates how Hive works within the Hadoop ecosystem. You'll also find real-world case studies that describe how companies have used Hive to solve unique problems involving petabyes of data.&quot;--P. [4] of cover.</dcterms:abstract>
        <dc:date>2012</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781449319335 1449319335</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <z:Attachment rdf:about="#item_78">
        <z:itemType>attachment</z:itemType>
        <dc:title>Programming Hive - Edward Capriolo.epub</dc:title>
        <link:type>application/octet-stream</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://www.analytics-magazine.org/november-december-2011/475-soft-skills-the-killer-app-for-analytics?tmpl=component&amp;print=1&amp;page=">
        <z:itemType>magazineArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Periodical></bib:Periodical>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Leonhardi</foaf:surname>
                        <foaf:givenname>David</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Soft skills: The 'killer app' for analytics</dc:title>
        <dc:date>21:29:33</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.analytics-magazine.org/november-december-2011/475-soft-skills-the-killer-app-for-analytics?tmpl=component&amp;print=1&amp;page=</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 21:29:33</dcterms:dateSubmitted>
    </bib:Article>
    <bib:Document rdf:about="https://github.com/tdsmith/aRrgh">
        <z:itemType>webpage</z:itemType>
        <dcterms:isPartOf>
           <z:Website><dc:title>GitHub</dc:title></z:Website>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Smith</foaf:surname>
                        <foaf:givenname>Tim</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_60"/>
        <dc:title>aRrgh - A newcomer's (angry) guide to data types in R</dc:title>
        <dcterms:abstract>aRrgh - A newcomer's (angry) guide to data types in R</dcterms:abstract>
        <dc:date>21:32:20</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/tdsmith/aRrgh</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 21:32:20</dcterms:dateSubmitted>
    </bib:Document>
    <z:Attachment rdf:about="#item_60">
        <z:itemType>attachment</z:itemType>
        <dc:title>aRrgh - A newcomer's (angry) gu - Tim Smith.azw3</dc:title>
        <link:type>application/octet-stream</link:type>
    </z:Attachment>
    <bib:Data rdf:about="https://github.com/rstudio/rstudio">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>RStudio</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>RStudio</dc:title>
        <dcterms:abstract>rstudio - RStudio is an integrated development environment (IDE) for R</dcterms:abstract>
        <dc:date>21:41:27</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/rstudio/rstudio</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 21:41:27</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/rstudio/shiny">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>RStudio</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>d3</dc:subject>
        <dc:title>Shiny</dc:title>
        <dcterms:abstract>shiny - Easy interactive web applications with R</dcterms:abstract>
        <dc:date>21:41:51</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/rstudio/shiny</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 21:41:51</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Document rdf:about="http://www.vertica.com/2013/04/08/comparing-pattern-mining-on-a-billion-records-with-hp-vertica-and-hadoop/">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lee</foaf:surname>
                        <foaf:givenname>Kyungyong</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Indrajit</foaf:surname>
                        <foaf:givenname>Roy</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Talwar</foaf:surname>
                        <foaf:givenname>Vanish</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Comparing Pattern Mining on a Billion Records with HP Vertica and Hadoop</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.vertica.com/2013/04/08/comparing-pattern-mining-on-a-billion-records-with-hp-vertica-and-hadoop/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Document>
    <bib:Article rdf:about="http://db.disi.unitn.eu/pages/VLDBProgram/pdf/flash/Vertica.pdf">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
                <dc:title>Proceedings of the VLDB Endowment</dc:title>
                <prism:volume>6</prism:volume>
                <prism:number>11</prism:number>
            </bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Tran</foaf:surname>
                        <foaf:givenname>Nga</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Bodagala</foaf:surname>
                        <foaf:givenname>Sreenath</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Dave</foaf:surname>
                        <foaf:givenname>Jaimin</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_369"/>
        <dc:title>Designing Query Optimizers for Big Data Problems of The Future</dc:title>
        <dc:date>2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://db.disi.unitn.eu/pages/VLDBProgram/pdf/flash/Vertica.pdf</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-28 11:45:40</dcterms:dateSubmitted>
        <z:libraryCatalog>Google Scholar</z:libraryCatalog>
    </bib:Article>
    <z:Attachment rdf:about="#item_369">
        <z:itemType>attachment</z:itemType>
        <dc:title>Tran_et_al_2013_Designing_Query_Optimizers_for_Big_Data_Problems_of_The_Future.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Document rdf:about="http://engineering.linkedin.com/data-replication/open-sourcing-databus-linkedins-low-latency-change-data-capture-system">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Botev</foaf:surname>
                        <foaf:givenname>Chavdar</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Open sourcing Databus: LinkedIn's low latency change data capture system</dc:title>
        <dcterms:abstract>We are pleased to announce the open source release of Databus - a real-time change data capture system.</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://engineering.linkedin.com/data-replication/open-sourcing-databus-linkedins-low-latency-change-data-capture-system</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 12:38:32</dcterms:dateSubmitted>
        <z:shortTitle>Open sourcing Databus</z:shortTitle>
    </bib:Document>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/allenwittenauer/2013-hadoopsummitemea?ref=http://eventifier.co/event/hadoopsummit2013/slides">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Wittenauer</foaf:surname>
                        <foaf:givenname>Allen</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <dc:title>Hadoop Operations at LinkedIn</dc:title>
        <dcterms:abstract>This is the slide deck for the talk I gave at SouthWest Big Data (UK) and Hadoop Summit EMEA 2013.  It was recorded, so hopefully a link to video will be available soon. :)</dcterms:abstract>
        <dc:date>Thu Mar 21  2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/allenwittenauer/2013-hadoopsummitemea?ref=http://eventifier.co/event/hadoopsummit2013/slides</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-24 17:21:22</dcterms:dateSubmitted>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <bib:Data rdf:about="https://github.com/Esri/spatial-framework-for-hadoop">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Esri</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Spatial Framework for Hadoop</dc:title>
        <dcterms:abstract>spatial-framework-for-hadoop - The Spatial Framework for Hadoop allows developers and data scientists to use the Hadoop data processing system for spatial data analysis.</dcterms:abstract>
        <dc:date>10:23:52</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://github.com/Esri/spatial-framework-for-hadoop</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 10:23:52</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/Esri/gis-tools-for-hadoop">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Esri</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>GIS Tools for Hadoop</dc:title>
        <dcterms:abstract>gis-tools-for-hadoop - The GIS Tools for Hadoop are a collection of GIS tools for spatial analysis of big data.</dcterms:abstract>
        <dc:date>10:24:08</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/Esri/gis-tools-for-hadoop</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 10:24:08</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/lintool/Ivory">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lin</foaf:surname>
                        <foaf:givenname>Jimmy</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Ivory</dc:title>
        <dcterms:abstract>Ivory - A Hadoop toolkit for web-scale information retrieval research</dcterms:abstract>
        <dc:date>17:42:43</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/lintool/Ivory</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-28 17:42:43</dcterms:dateSubmitted>
    </bib:Data>
    <rdf:Description rdf:about="http://dl.acm.org/citation.cfm?id=2187955">
        <z:itemType>conferencePaper</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Zhai</foaf:surname>
                        <foaf:givenname>Ke</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Boyd-Graber</foaf:surname>
                        <foaf:givenname>Jordan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Asadi</foaf:surname>
                        <foaf:givenname>Nima</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Alkhouja</foaf:surname>
                        <foaf:givenname>Mohamad L.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_188"/>
        <dc:title>Mr. LDA: A flexible large scale topic modeling package using variational inference in MapReduce</dc:title>
        <dc:date>2012</dc:date>
        <bib:pages>879–888</bib:pages>
        <z:shortTitle>Mr. LDA</z:shortTitle>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://dl.acm.org/citation.cfm?id=2187955</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-28 17:45:05</dcterms:dateSubmitted>
        <z:libraryCatalog>Google Scholar</z:libraryCatalog>
    </rdf:Description>
    <z:Attachment rdf:about="#item_188">
        <z:itemType>attachment</z:itemType>
        <dc:title>Zhai_et_al_2012_Mr.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/visualisingdata/andy-kirk-talk-at-big-data-world-europe-september-2012">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kirk</foaf:surname>
                        <foaf:givenname>Andy</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <dc:title>Understanding learning in order to implement efficient visualisation methods</dc:title>
        <z:type>Technology</z:type>
        <dc:date>Fri Sep 21  2012</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/visualisingdata/andy-kirk-talk-at-big-data-world-europe-september-2012</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-29 00:09:11</dcterms:dateSubmitted>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <bib:Data rdf:about="https://github.com/enjalot/tributary">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Johnson</foaf:surname>
                        <foaf:givenname>Ian</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>d3</dc:subject>
        <dc:title>Tributary</dc:title>
        <dcterms:abstract>tributary - rapid prototyping with d3.js</dcterms:abstract>
        <dc:date>22:04:10</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/enjalot/tributary</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 22:04:10</dcterms:dateSubmitted>
    </bib:Data>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/allenwittenauer/2012-lihadoopperf">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Wittenauer</foaf:surname>
                        <foaf:givenname>Allen</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <dc:title>Hadoop Performance at LinkedIn</dc:title>
        <dcterms:abstract>This is part of a presentation I did at Intel a month or so ago.  Some of the content has been removed due to NDA, etc.</dcterms:abstract>
        <dc:date>Sat Jan 19  2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/allenwittenauer/2012-lihadoopperf</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-24 17:22:16</dcterms:dateSubmitted>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <bib:Data rdf:about="http://incubator.apache.org/ambari/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Apache Software Foundation</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Apache Ambari</dc:title>
        <dc:date>21:46:13</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://incubator.apache.org/ambari/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 21:46:13</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Document rdf:about="http://www.michael-noll.com/blog/2013/03/17/reading-and-writing-avro-files-from-the-command-line/">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Noll</foaf:surname>
                        <foaf:givenname>Machael</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>hadoop</dc:subject>
        <dc:title>Reading and Writing Avro Files from the Command Line</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.michael-noll.com/blog/2013/03/17/reading-and-writing-avro-files-from-the-command-line/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Document>
    <bib:Data rdf:about="https://github.com/kennethreitz/httpbin">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Reitz</foaf:surname>
                        <foaf:givenname>Kenneth</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>httpbin</dc:title>
        <dcterms:abstract>httpbin - HTTP Request &amp; Response Service, written in Python + Flask.</dcterms:abstract>
        <dc:date>18:50:35</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/kennethreitz/httpbin</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 18:50:35</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Document rdf:about="http://nullege.com/">
        <z:itemType>webpage</z:itemType>
        <dcterms:isPartOf>
           <z:Website></z:Website>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Nullege</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>python</dc:subject>
        <dc:subject>tools</dc:subject>
        <dc:title>Nullege: A Search Engine for Python source code</dc:title>
        <dc:identifier>
           <dcterms:URI><rdf:value>http://nullege.com/</rdf:value></dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Document>
    <bib:Data rdf:about="https://github.com/jubatus/jubatus">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Preferred Infrastructure</foaf:surname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>NTT Software Innovation Center</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Jubatus</dc:title>
        <dcterms:abstract>jubatus - Framework and Library for Distributed Online Machine Learning</dcterms:abstract>
        <dc:date>17:29:59</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/jubatus/jubatus</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-24 17:29:59</dcterms:dateSubmitted>
    </bib:Data>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/julienledem/parquet-hadoop-summit-2013">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Le Dem</foaf:surname>
                        <foaf:givenname>Julien</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Li</foaf:surname>
                        <foaf:givenname>Nong</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <dc:title>Parquet: Columnar storage for the people</dc:title>
        <dcterms:abstract>Parquet presentation given to the Hadoop summit 2013</dcterms:abstract>
        <z:type>Technology</z:type>
        <dc:date>Thu Jun 27  2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/julienledem/parquet-hadoop-summit-2013</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-24 17:32:34</dcterms:dateSubmitted>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/jpatanooga/hadoop-summit-eu-2013-parallel-linear-regression-iterativereduce-and-yarn">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Patterson</foaf:surname>
                        <foaf:givenname>Josh</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <dc:title>Linear Regression and Metronome</dc:title>
        <dcterms:abstract>Josh Patterson's Hadoop Summit EU 2013 talk on parallel linear linear regression on IterativeReduce and YARN.</dcterms:abstract>
        <dc:date>Sun Mar 24  2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/jpatanooga/hadoop-summit-eu-2013-parallel-linear-regression-iterativereduce-and-yarn</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-24 17:36:23</dcterms:dateSubmitted>
        <z:shortTitle>Hadoop Summit EU 2013</z:shortTitle>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <bib:Data rdf:about="https://github.com/linkedin/hopscotch">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>LinkedIn</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>hopscotch</dc:title>
        <dcterms:abstract>hopscotch - A framework to make it easy for developers to add product tours to their pages.</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/linkedin/hopscotch</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 12:47:11</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/forcedotcom/phoenix">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Salesforce.com</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Phoenix</dc:title>
        <dcterms:abstract>Contribute to phoenix development by creating an account on GitHub.</dcterms:abstract>
        <dc:date>10:26:43</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/forcedotcom/phoenix</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 10:26:43</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/JohnLangford/vowpal_wabbit">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Microsoft</foaf:surname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                   <foaf:Person><foaf:surname>Yahoo</foaf:surname></foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Langford</foaf:surname>
                        <foaf:givenname>John</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>machine learning</dc:subject>
        <dc:title>vowpal_wabbit</dc:title>
        <dcterms:abstract>vowpal_wabbit - John Langford's original release of Vowpal Wabbit -- a fast online learning algorithm</dcterms:abstract>
        <dc:date>17:40:44</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://github.com/JohnLangford/vowpal_wabbit</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-24 17:40:44</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/metadaddy-sfdc/Database.com-FDW-for-PostgreSQL">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Patterson</foaf:surname>
                        <foaf:givenname>Pat</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>postgresql</dc:subject>
        <dc:title>Database.com-FDW</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://github.com/metadaddy-sfdc/Database.com-FDW-for-PostgreSQL</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/rslifka/elasticity">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Sharethrough</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Elasticity</dc:title>
        <dcterms:abstract>elasticity - Programmatic access to Amazon's Elastic Map Reduce service, driven by the Sharethrough team's requirements for belting out EMR jobs.</dcterms:abstract>
        <dc:date>21:51:38</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/rslifka/elasticity</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 21:51:38</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Document rdf:about="http://blog.aggregateknowledge.com/2013/05/16/aws-redshift-how-amazon-changed-the-game/">
        <z:itemType>webpage</z:itemType>
        <dcterms:isPartOf>
           <z:Website></z:Website>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Karnezos</foaf:surname>
                        <foaf:givenname>Timon</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_45"/>
        <dc:title>AWS Redshift: How Amazon Changed The Game</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://blog.aggregateknowledge.com/2013/05/16/aws-redshift-how-amazon-changed-the-game/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Document>
    <z:Attachment rdf:about="#item_45">
        <z:itemType>attachment</z:itemType>
        <dc:title>AWS Redshift_ How Amazon Change - Timon Karnezos.azw3</dc:title>
        <link:type>application/octet-stream</link:type>
    </z:Attachment>
    <bib:Book rdf:about="urn:isbn:0983179697">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
               <foaf:name>McKinsey Global Institute</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Manyika</foaf:surname>
                        <foaf:givenname>James</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Chui</foaf:surname>
                        <foaf:givenname>Michael</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Brown</foaf:surname>
                        <foaf:givenname>Brad</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Bughin</foaf:surname>
                        <foaf:givenname>Jacques</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Dobbs</foaf:surname>
                        <foaf:givenname>Richard</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Roxburgh</foaf:surname>
                        <foaf:givenname>Charles</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Byers</foaf:surname>
                        <foaf:givenname>Angela Hung</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <bib:contributors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>McKinsey Global Institute</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:contributors>
        <link:link rdf:resource="#item_141"/>
        <dc:title>Big Data: The Next Frontier for Innovation, Competition, and Productivity</dc:title>
        <dcterms:abstract>Annotation. The amount of data in our world has been exploding. Companies capture trillions of bytes of information about their customers, suppliers, and operations. Big data -- large pools of data that can be captured, communicated, stored, and analyzed -- is now part of every sector and function of the global economy. The new study, by the McKinsey Global Institute,examines the potential value that big data can create for organizations and seeks to illustrate and quantify that value.</dcterms:abstract>
        <dc:date>2011</dc:date>
        <z:numPages>book</z:numPages>
        <z:language>en</z:language>
        <dc:identifier>ISBN 0983179697</dc:identifier>
        <z:shortTitle>Big Data</z:shortTitle>
        <z:libraryCatalog>Google Books</z:libraryCatalog>
    </bib:Book>
    <z:Attachment rdf:about="#item_141">
        <z:itemType>attachment</z:itemType>
        <dc:title>Big data_ The next frontier for innovati - Dobbs, Richard.epub</dc:title>
        <link:type>application/octet-stream</link:type>
    </z:Attachment>
    <bib:Document rdf:about="http://hbr.org/2013/01/why-it-fumbles-analytics/ar/1?imm_mid=0a4eb2&amp;#38;cmp=em-strata-newsletters-stratasc-video-20130403-elist">
        <z:itemType>webpage</z:itemType>
        <dcterms:isPartOf>
           <z:Website></z:Website>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Marchand</foaf:surname>
                        <foaf:givenname>Donald A.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Peppard</foaf:surname>
                        <foaf:givenname>Joe</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_49"/>
        <dc:title>Why IT Fumbles Analytics</dc:title>
        <dc:date>06:15:55</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://hbr.org/2013/01/why-it-fumbles-analytics/ar/1?imm_mid=0a4eb2&amp;#38;cmp=em-strata-newsletters-stratasc-video-20130403-elist</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-02 06:15:55</dcterms:dateSubmitted>
    </bib:Document>
    <z:Attachment rdf:about="#item_49">
        <z:itemType>attachment</z:itemType>
        <dc:title>Why IT Fumbles Analytics - Donald A. Marchand.azw3</dc:title>
        <link:type>application/octet-stream</link:type>
    </z:Attachment>
    <bib:Data rdf:about="https://github.com/snowplow/snowplow">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Snowplow Analytics</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Snowplow</dc:title>
        <dcterms:abstract>snowplow - Enterprise-strength product and marketing analytics, powered by Hadoop, Redshift and Postgres</dcterms:abstract>
        <dc:date>21:53:31</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/snowplow/snowplow</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 21:53:31</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Book rdf:about="urn:isbn:1849517843%209781849517843">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>[S.l.]</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Packt Publishing Limited</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Perez</foaf:surname>
                        <foaf:givenname>Antonio Santiago</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Openlayers cookbook.</dc:title>
        <dc:date>2012</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 1849517843 9781849517843</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Document rdf:about="http://eventdata.psu.edu/data.dir/GDELT.html#.UWMC3-UnquE.twitter">
        <z:itemType>webpage</z:itemType>
        <dcterms:isPartOf>
           <z:Website></z:Website>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Leetaru</foaf:surname>
                        <foaf:givenname>Kalev</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>datasource</dc:subject>
        <dc:title>GDELT Data</dc:title>
        <dcterms:abstract>Global Data on Events, Location and Tone</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://eventdata.psu.edu/data.dir/GDELT.html#.UWMC3-UnquE.twitter</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Document>
    <bib:Book rdf:about="urn:isbn:9781449311797%20%201449311792">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Farnham</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Davis</foaf:surname>
                        <foaf:givenname>Kord</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Patterson</foaf:surname>
                        <foaf:givenname>Doug</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_91"/>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Business ethics</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Data mining</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Database searching</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Distributed processing</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Electronic data processing</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:title>Ethics of big data</dc:title>
        <dc:date>2012</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781449311797  1449311792</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <z:Attachment rdf:about="#item_91">
        <z:itemType>attachment</z:itemType>
        <dc:title>Ethics of Big Data_ Balancing Risk and Innovation - Kord Davis.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Document rdf:about="http://www.johndcook.com/blog/2013/04/30/recognizing-numbers/">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog><dc:title>The Endeavour</dc:title></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Cook</foaf:surname>
                        <foaf:givenname>John D.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>python</dc:subject>
        <dc:subject>scicomp</dc:subject>
        <dc:title>Recognizing numbers</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.johndcook.com/blog/2013/04/30/recognizing-numbers/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Document>
    <bib:Document rdf:about="http://bost.ocks.org/mike/selection/">
        <z:itemType>webpage</z:itemType>
        <dcterms:isPartOf>
           <z:Website></z:Website>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Bostock</foaf:surname>
                        <foaf:givenname>Michael</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>d3</dc:subject>
        <dc:title>How Selections Work</dc:title>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://bost.ocks.org/mike/selection/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Document>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/pacoid/pattern-an-open-source-project-for-migrating-predictive-models-from-sas-etc-onto-hadoop">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Nathan</foaf:surname>
                        <foaf:givenname>Paco</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <dc:title>Pattern – an open source project for migrating predi...</dc:title>
        <dcterms:abstract>Hadoop Summit 2013 talk:

“Pattern – an open source project for migrating predictive models from SAS, etc., onto Hadoop”</dcterms:abstract>
        <z:type>Technology</z:type>
        <dc:date>Mon Jul 29  2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/pacoid/pattern-an-open-source-project-for-migrating-predictive-models-from-sas-etc-onto-hadoop</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-24 17:54:59</dcterms:dateSubmitted>
        <z:shortTitle>Hadoop Summit</z:shortTitle>
    </bib:ConferenceProceedings>
    <bib:Document rdf:about="http://www.r-bloggers.com/faster-higher-stonger-a-guide-to-speeding-up-r-code-for-busy-people/">
        <z:itemType>webpage</z:itemType>
        <dcterms:isPartOf>
           <z:Website></z:Website>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ross</foaf:surname>
                        <foaf:givenname>Noam</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_55"/>
        <dc:subject>optimization</dc:subject>
        <dc:subject>R</dc:subject>
        <dc:title>FasteR! HigheR! StongeR! -- A Guide to Speeding Up R Code for Busy People</dc:title>
        <dcterms:abstract>FasteR! HigheR! StongeR! – A Guide to Speeding Up R Code for Busy People</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.r-bloggers.com/faster-higher-stonger-a-guide-to-speeding-up-r-code-for-busy-people/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Document>
    <z:Attachment rdf:about="#item_55">
        <z:itemType>attachment</z:itemType>
        <dc:title>FasteR! HigheR! StongeR! - Noam Ross.azw3</dc:title>
        <link:type>application/octet-stream</link:type>
    </z:Attachment>
    <bib:Data rdf:about="http://cassandra.apache.org/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Apache Software Foundation</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Apache Cassandra</dc:title>
        <dc:date>14:08:44</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://cassandra.apache.org/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-02 14:08:44</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Document rdf:about="http://blog.fperez.org/2013/04/literate-computing-and-computational.html">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Perez</foaf:surname>
                        <foaf:givenname>Fernando</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>python</dc:subject>
        <dc:title>Literate computing and computational reproducibility: IPython in the age of data-driven journalism</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://blog.fperez.org/2013/04/literate-computing-and-computational.html</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Document>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/krishflix/genie-hadoop-platform-as-a-service-at-netflix">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Krishnan</foaf:surname>
                        <foaf:givenname>Sriram</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <bib:contributors>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Netflix</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:contributors>
        <dc:title>Genie - Hadoop Platform as a Service at Netflix</dc:title>
        <dcterms:abstract>In a prior tech blog (http://nflx.it/XoySYR), we had discussed the architecture of our petabyte-scale data warehouse in the cloud. Salient features of our architecture include the use of Amazon’s Simple Storage Service (S3) as our &quot;source of truth&quot;, leveraging the elasticity of the cloud to run multiple dynamically resizable Hadoop clusters to support various workloads, and our horizontally scalable Hadoop Platform as a Service called Genie.

We are pleased to announce that Genie is now open source (http://nflx.it/15rd6pJ), and available to the public from the Netflix OSS GitHub site (https://github.com/Netflix/genie).</dcterms:abstract>
        <z:type>Technology</z:type>
        <dc:date>Tue Jun 25  2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/krishflix/genie-hadoop-platform-as-a-service-at-netflix</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-24 18:00:44</dcterms:dateSubmitted>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <bib:Book rdf:about="urn:isbn:1783281375%209781783281374">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>[S.l.]</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Packt Publishing Limited</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Karambelkar</foaf:surname>
                        <foaf:givenname>H</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Scaling big data with hadoop and solr.</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 1783281375 9781783281374</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:1449364624%209781449364625">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Sebastopol, CA</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly Media</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ting</foaf:surname>
                        <foaf:givenname>Kathleen</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Cecho</foaf:surname>
                        <foaf:givenname>Jarek Jarcec</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Apache Sqoop cookbook</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 1449364624 9781449364625</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Data rdf:about="https://github.com/kennethreitz/requests">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Reitz</foaf:surname>
                        <foaf:givenname>Kenneth</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Requests</dc:title>
        <dcterms:abstract>requests - Python HTTP Requests for Humans™.</dcterms:abstract>
        <dc:date>18:51:47</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/kennethreitz/requests</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 18:51:47</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="http://dexvis.com/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Martin</foaf:surname>
                        <foaf:givenname>Patrick</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>d3</dc:subject>
        <dc:subject>javascript</dc:subject>
        <dc:title>Dex</dc:title>
        <dc:identifier>
           <dcterms:URI><rdf:value>http://dexvis.com/</rdf:value></dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Data>
    <bib:Data rdf:about="http://hadoop.apache.org/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Apache Software Foundation</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Apache Hadoop</dc:title>
        <dc:date>14:09:18</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://hadoop.apache.org/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-02 14:09:18</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="http://www.scidb.org/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Paradigm4</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>analytics</dc:subject>
        <dc:subject>database</dc:subject>
        <dc:title>SciDB</dc:title>
        <dc:identifier>
           <dcterms:URI><rdf:value>http://www.scidb.org/</rdf:value></dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Data>
    <rdf:Description rdf:about="https://www.usenix.org/system/files/conference/osdi12/osdi12-final-16.pdf">
        <z:itemType>conferencePaper</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Corbett</foaf:surname>
                        <foaf:givenname>James C.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Dean</foaf:surname>
                        <foaf:givenname>Jeffrey</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Epstein</foaf:surname>
                        <foaf:givenname>Michael</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Fikes</foaf:surname>
                        <foaf:givenname>Andrew</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Frost</foaf:surname>
                        <foaf:givenname>Christopher</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Furman</foaf:surname>
                        <foaf:givenname>J. J.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ghemawat</foaf:surname>
                        <foaf:givenname>Sanjay</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Gubarev</foaf:surname>
                        <foaf:givenname>Andrey</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Heiser</foaf:surname>
                        <foaf:givenname>Christopher</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Hochschild</foaf:surname>
                        <foaf:givenname>Peter</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_184"/>
        <link:link rdf:resource="#item_243"/>
        <dc:title>Spanner: Google’s globally-distributed database</dc:title>
        <dc:date>2012</dc:date>
        <dc:title>Proceedings of OSDI</dc:title>
        <prism:volume>1</prism:volume>
        <z:shortTitle>Spanner</z:shortTitle>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://www.usenix.org/system/files/conference/osdi12/osdi12-final-16.pdf</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 12:50:39</dcterms:dateSubmitted>
        <z:libraryCatalog>Google Scholar</z:libraryCatalog>
    </rdf:Description>
    <z:Attachment rdf:about="#item_184">
        <z:itemType>attachment</z:itemType>
        <dc:title>Corbett_et_al_2012_Spanner.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <z:Attachment rdf:about="#item_243">
        <z:itemType>attachment</z:itemType>
        <dc:title>Corbett_et_al_2012_Spanner.pptx</dc:title>
        <link:type>application/vnd.openxmlformats-officedocument.presentationml.presentation</link:type>
    </z:Attachment>
    <bib:ConferenceProceedings rdf:about="http://style.org/tapestry/">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Corum</foaf:surname>
                        <foaf:givenname>Jonathan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <link:link rdf:resource="#item_216"/>
        <dc:subject>storytelling</dc:subject>
        <dc:title>Storytelling with Data</dc:title>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://style.org/tapestry/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:ConferenceProceedings>
    <z:Attachment rdf:about="#item_216">
        <z:itemType>attachment</z:itemType>
        <dc:title>style.org _ Storytelling with D - Jonathan Corum.azw3</dc:title>
        <link:type>application/octet-stream</link:type>
    </z:Attachment>
    <bib:Data rdf:about="https://github.com/facebook/scribe">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Facebook</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Scribe</dc:title>
        <dcterms:abstract>scribe - Scribe is a server for aggregating log data streamed in real time from a large number of servers. It is designed to be scalable, extensible without client-side modification, and robust to failure of the network or any specific machine.</dcterms:abstract>
        <dc:date>21:55:19</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/facebook/scribe</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 21:55:19</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/0xdata/h2o">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>0xdata</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>H2O</dc:title>
        <dcterms:abstract>h2o = fast statistical, machine learning &amp; math runtime for bigdata</dcterms:abstract>
        <dc:date>10:27:59</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/0xdata/h2o</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 10:27:59</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/twitter/snowflake">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Twitter</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Snowflake</dc:title>
        <dcterms:abstract>snowflake - Snowflake is a network service for generating unique ID numbers at high scale with some simple guarantees.</dcterms:abstract>
        <dc:date>14:09:59</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/twitter/snowflake</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-02 14:09:59</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/thedatachef/sounder">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Perkins</foaf:surname>
                        <foaf:givenname>Jacob A.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Sounder</dc:title>
        <dcterms:abstract>sounder - A grouping of Apache Pig examples.</dcterms:abstract>
        <dc:date>12:59:08</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/thedatachef/sounder</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-28 12:59:08</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Book rdf:about="urn:isbn:9781849517140%201849517142">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Birmingham</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Packt Publishing, Limited</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Jiang</foaf:surname>
                        <foaf:givenname>Y</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>HBase Administration Cookbook</dc:title>
        <dcterms:abstract>Annotation</dcterms:abstract>
        <dc:date>2012</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781849517140 1849517142</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://ezproxy.siast.sk.ca:443/login?url=http://proquest.safaribooksonline.com/9781849517140</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-27 08:50:33</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:1782165169">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Birmingham, UK</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Packt Publishing Ltd.</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Guo</foaf:surname>
                        <foaf:givenname>Shumin</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_118"/>
        <dc:title>Hadoop operations and cluster management cookbook</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 1782165169</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://site.ebrary.com/id/10742618</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-27 08:50:33</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <z:Attachment rdf:about="#item_118">
        <z:itemType>attachment</z:itemType>
        <dc:title>Hadoop Operations and Cluster Management Cookbook - Shumin Guo.epub</dc:title>
        <link:type>application/octet-stream</link:type>
    </z:Attachment>
    <bib:Book rdf:about="urn:isbn:9781449311520%20%201449311520">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                        <vcard:locality>Farnham; Sebastopol, Calif.</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>White</foaf:surname>
                        <foaf:givenname>Tom</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Hadoop: the definitive guide</dc:title>
        <dc:date>2012</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781449311520  1449311520</dc:identifier>
        <z:shortTitle>Hadoop</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Data rdf:about="https://github.com/thedatachef/varaha">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Perkins</foaf:surname>
                        <foaf:givenname>Jacob A.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Varaha</dc:title>
        <dcterms:abstract>varaha - Machine learning and natural language processing with Apache Pig</dcterms:abstract>
        <dc:date>12:59:14</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/thedatachef/varaha</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-28 12:59:14</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Document rdf:about="http://blogs.hbr.org/cs/2013/04/how_p_and_g_presents_data.html">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Davenport</foaf:surname>
                        <foaf:givenname>Tom</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>hbr</dc:subject>
        <dc:subject>visualization</dc:subject>
        <dc:title>How P&amp;G Presents Data to Decision-Makers</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://blogs.hbr.org/cs/2013/04/how_p_and_g_presents_data.html</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Document>
    <bib:Data rdf:about="https://github.com/jondot/graphene">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Nahum</foaf:surname>
                        <foaf:givenname>Dotan J.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>d3</dc:subject>
        <dc:title>Graphene</dc:title>
        <dcterms:abstract>graphene - Graphene is a realtime dashboard &amp; graphing toolkit based on D3 and Backbone.</dcterms:abstract>
        <dc:date>06:27:27</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/jondot/graphene</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-02 06:27:27</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/Netflix/asgard">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Netflix</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Asgard</dc:title>
        <dcterms:abstract>Web interface for application deployments and cloud management in Amazon Web Services (AWS). Binary download: http://netflix.box.com/asgard Snapshot builds: https://netflixoss.ci.cloudbees.com/job/asgard-master/ Twitter: http://twitter.com/AsgardOSS</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/Netflix/asgard</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 13:27:15</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/thedatachef/swineherd">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Perkins</foaf:surname>
                        <foaf:givenname>Jacob A.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>SwineHerd</dc:title>
        <dcterms:abstract>swineherd - Flexible data workflow glue.</dcterms:abstract>
        <dc:date>12:59:19</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/thedatachef/swineherd</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-28 12:59:19</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Document rdf:about="http://blogs.hbr.org/cs/2013/04/visualization_as_process.html">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Thorp</foaf:surname>
                        <foaf:givenname>Jer</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>visualization</dc:subject>
        <dc:title>Visualization as Process, Not Output</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://blogs.hbr.org/cs/2013/04/visualization_as_process.html</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Document>
    <bib:Book rdf:about="urn:isbn:9781118208786%20%201118208781">
        <z:itemType>book</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Franks</foaf:surname>
                        <foaf:givenname>Bill</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Taming the big data tidal wave: finding opportunities in huge data streams with advanced analytics</dc:title>
        <dcterms:abstract>&quot;How to approach creating and evolving a world-class advanced analytics ecosystem in today's big data environment. Written in an informal style by someone who has lived analytics in big business, Taming the Big Data Tidal Wave provides a &quot;from the trenches&quot; viewpoint of analytics. This book shows how big data is changing the world of analytics; what people, processes, technologies, and mindsets are necessary to succeed in analytics in this new era; what trends are developing that will change how businesses do analytics as big data alters the scale of the inputs and growing requirements change the scale of the outputs; and how to think bigger in terms of what analytics can do for a business. Looks at what big data is and why it's important. Examines some of the types of big data and how can they be used to drive new, innovative analytics. Offers the tools and technologies required to tame big data. Reveals the analytic processes and methods needed to bring about change. Discusses how your organization can set itself up for successful analytic innovation. This important book reveals how analytics has evolved in the past decades and how it will continue to evolve in the coming decades. The big data tidal wave is coming. Organizations can either ride the wave to drive analytical innovation and improve their businesses, or they can get dragged under it as it crashes on top of them. This book provides a roadmap for riding the wave successfully in terms that anyone with an interest in the topic will be able to understand&quot;--</dcterms:abstract>
        <dc:date>2012</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781118208786  1118208781</dc:identifier>
        <z:shortTitle>Taming the big data tidal wave</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Data rdf:about="https://github.com/ql-io/ql.io">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>eBay Software Foundation</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>ql.io</dc:title>
        <dcterms:abstract>ql.io - A node.js based declarative, data-retrieval and aggregation gateway for quickly consuming HTTP APIs</dcterms:abstract>
        <dc:date>22:08:08</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/ql-io/ql.io</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 22:08:08</dcterms:dateSubmitted>
    </bib:Data>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/xefyr/hbase-client-apis-for-webapps">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Dimiduk</foaf:surname>
                        <foaf:givenname>Nick</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <link:link rdf:resource="#item_397"/>
        <dc:title>HBase Client APIs (for webapps?)</dc:title>
        <dcterms:abstract>This talk examines HBase client options available to application developers working with HBase. The focus is framed on, but not limited to, building webapps.</dcterms:abstract>
        <dc:date>Thu Mar 28  2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/xefyr/hbase-client-apis-for-webapps</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-24 18:18:04</dcterms:dateSubmitted>
        <z:shortTitle>HBase Client APIs (for webapps?</z:shortTitle>
    </bib:ConferenceProceedings>
    <z:Attachment rdf:about="#item_397">
        <z:itemType>attachment</z:itemType>
        <dc:title>Dimiduk_2013_HBase_Client_APIs_(for_webapps.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Document rdf:about="http://quantifyingmemory.blogspot.com/2013/04/experiments-in-python-and-d3-from-r.html">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog><dc:title>Quantifying Memory</dc:title></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Fredheim</foaf:surname>
                        <foaf:givenname>Rolf</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>
           <z:AutomaticTag><rdf:value>d3</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>events</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>GDELT</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>map</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>R</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Russia</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>shiny</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>visualisations</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:title>Quantifying Memory: Experiments in python and d3 from R: GDELT made easy</dc:title>
        <dc:date>22:09:31</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://quantifyingmemory.blogspot.com/2013/04/experiments-in-python-and-d3-from-r.html</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 22:09:31</dcterms:dateSubmitted>
        <z:shortTitle>Quantifying Memory</z:shortTitle>
    </bib:Document>
    <bib:Data rdf:about="https://github.com/japerk/nltk-trainer">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Perkins</foaf:surname>
                        <foaf:givenname>Jacob</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>NLTK Trainer</dc:title>
        <dcterms:abstract>nltk-trainer - Train NLTK objects with zero code</dcterms:abstract>
        <dc:date>13:00:06</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/japerk/nltk-trainer</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-28 13:00:06</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Book rdf:about="urn:isbn:9781935182191%20%201935182196">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Greenwich, Conn.</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Manning Publications</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lam</foaf:surname>
                        <foaf:givenname>Chuck</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Hadoop in action</dc:title>
        <dcterms:abstract>Big data can be difficult to handle using traditional data-bases. Apache Hadoop is a NoSQL applications framework that runs on distributed clusters. This lets it scale to huge datasets. If you need analytic information from your data, Hadoop's the way to go. Hadoop in Action introduces the subject and teachers you how to write programs in the MapReduce style. It starts with a few easy examples and then moves quickly to show Hadoop use in more complex data analysis tasks. included are best practices and design patterns of MapReduce programming.</dcterms:abstract>
        <dc:date>2011</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781935182191  1935182196</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <rdf:Description rdf:about="http://static.usenix.org/events/nsdi11/tech/full_papers/Hindman_new.pdf">
        <z:itemType>conferencePaper</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Hindman</foaf:surname>
                        <foaf:givenname>Benjamin</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Konwinski</foaf:surname>
                        <foaf:givenname>Andy</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Zaharia</foaf:surname>
                        <foaf:givenname>Matei</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ghodsi</foaf:surname>
                        <foaf:givenname>Ali</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Joseph</foaf:surname>
                        <foaf:givenname>Anthony D.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Katz</foaf:surname>
                        <foaf:givenname>Randy</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Shenker</foaf:surname>
                        <foaf:givenname>Scott</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Stoica</foaf:surname>
                        <foaf:givenname>Ion</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_173"/>
        <dc:title>Mesos: A platform for fine-grained resource sharing in the data center</dc:title>
        <dc:date>2011</dc:date>
        <dc:title>Proceedings of the 8th USENIX conference on Networked systems design and implementation</dc:title>
        <bib:pages>22–22</bib:pages>
        <z:shortTitle>Mesos</z:shortTitle>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://static.usenix.org/events/nsdi11/tech/full_papers/Hindman_new.pdf</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 04:59:42</dcterms:dateSubmitted>
        <z:libraryCatalog>Google Scholar</z:libraryCatalog>
    </rdf:Description>
    <z:Attachment rdf:about="#item_173">
        <z:itemType>attachment</z:itemType>
        <dc:title>Hindman_et_al_2011_Mesos.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Book rdf:about="urn:isbn:9781849517317%20%201849517312">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Birmingham</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Packt Pub.</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Turkington</foaf:surname>
                        <foaf:givenname>Garry</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Hadoop Beginner's Guide</dc:title>
        <dcterms:abstract>As a Packt Beginner's Guide, the book is packed with clear step-by-step instructions for performing the most useful tasks, getting you up and running quickly, and learning by doing. This book assumes no existing experience with Hadoop or cloud services. It assumes you have familiarity with a programming language such as Java or Ruby but gives you the needed background on the other topics.</dcterms:abstract>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781849517317  1849517312</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://public.eblib.com/EBLPublic/PublicView.do?ptiID=1140151</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-27 08:50:33</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Data rdf:about="https://github.com/twitter/scalding">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Twitter</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Scalding</dc:title>
        <dcterms:abstract>scalding - A Scala API for Cascading</dcterms:abstract>
        <dc:date>18:15:14</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/twitter/scalding</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-28 18:15:14</dcterms:dateSubmitted>
    </bib:Data>
    <rdf:Description rdf:about="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6413897">
        <z:itemType>conferencePaper</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ferrera</foaf:surname>
                        <foaf:givenname>Pedro</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>de Prado</foaf:surname>
                        <foaf:givenname>Ivan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Palacios</foaf:surname>
                        <foaf:givenname>Eric</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Fernandez-Marquez</foaf:surname>
                        <foaf:givenname>Jose Luis</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Di Marzo Serugendo</foaf:surname>
                        <foaf:givenname>Giovanna</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_180"/>
        <dc:title>Tuple MapReduce: Beyond classic MapReduce</dc:title>
        <dc:date>2012</dc:date>
        <dc:title>Data Mining (ICDM), 2012 IEEE 12th International Conference on</dc:title>
        <bib:pages>260–269</bib:pages>
        <z:shortTitle>Tuple MapReduce</z:shortTitle>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6413897</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 05:03:21</dcterms:dateSubmitted>
        <z:libraryCatalog>Google Scholar</z:libraryCatalog>
    </rdf:Description>
    <z:Attachment rdf:about="#item_180">
        <z:itemType>attachment</z:itemType>
        <dc:title>Ferrera_et_al_2012_Tuple_MapReduce.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Data rdf:about="http://cloudera.github.com/RecordBreaker/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Cloudera</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>automation</dc:subject>
        <dc:subject>hadoop</dc:subject>
        <dc:title>RecordBreaker</dc:title>
        <dcterms:abstract>Automatic structure for your text-formatted data.</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://cloudera.github.com/RecordBreaker/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Data>
    <bib:Book rdf:about="urn:isbn:0544002695%20%209780544002692">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Boston</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Houghton Mifflin Harcourt</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Mayer-Schönberger</foaf:surname>
                        <foaf:givenname>Viktor</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Cukier</foaf:surname>
                        <foaf:givenname>Kenneth</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Big data: a revolution that will transform how we live, work, and think</dc:title>
        <dcterms:abstract>Explores the idea of big data, which refers to our newfound ability to crunch vast amounts of information, analyze it instantly, and draw profound and surprising conclusions from it.</dcterms:abstract>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 0544002695  9780544002692</dc:identifier>
        <z:shortTitle>Big data</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <rdf:Description rdf:about="http://dl.acm.org/citation.cfm?id=1855711.1855732">
        <z:itemType>conferencePaper</z:itemType>
        <dcterms:isPartOf>
           <bib:Series><dc:title>NSDI'10</dc:title></bib:Series>
        </dcterms:isPartOf>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Berkeley, CA, USA</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>USENIX Association</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Condie</foaf:surname>
                        <foaf:givenname>Tyson</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Conway</foaf:surname>
                        <foaf:givenname>Neil</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Alvaro</foaf:surname>
                        <foaf:givenname>Peter</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Hellerstein</foaf:surname>
                        <foaf:givenname>Joseph M.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Elmeleegy</foaf:surname>
                        <foaf:givenname>Khaled</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Sears</foaf:surname>
                        <foaf:givenname>Russell</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_167"/>
        <dc:title>MapReduce online</dc:title>
        <dcterms:abstract>MapReduce is a popular framework for data-intensive distributed computing of batch jobs. To simplify fault tolerance, many implementations of MapReduce materialize the entire output of each map and reduce task before it can be consumed. In this paper, we propose a modified MapReduce architecture that allows data to be pipelined between operators. This extends the MapReduce programming model beyond batch processing, and can reduce completion times and improve system utilization for batch jobs as well. We present a modified version of the Hadoop MapReduce framework that supports online aggregation, which allows users to see &quot;early returns&quot; from a job as it is being computed. Our Hadoop Online Prototype (HOP) also supports continuous queries, which enable MapReduce programs to be written for applications such as event monitoring and stream processing. HOP retains the fault tolerance properties of Hadoop and can run unmodified user-defined MapReduce programs.</dcterms:abstract>
        <dc:date>2010</dc:date>
        <bib:pages>21–21</bib:pages>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://dl.acm.org/citation.cfm?id=1855711.1855732</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 10:34:31</dcterms:dateSubmitted>
        <z:libraryCatalog>ACM Digital Library</z:libraryCatalog>
    </rdf:Description>
    <z:Attachment rdf:about="#item_167">
        <z:itemType>attachment</z:itemType>
        <dc:title>Condie_et_al_2010_MapReduce_online.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Book rdf:about="urn:isbn:9781449327170%201449327176">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Sebastopol, CA</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Oreilly</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Miner</foaf:surname>
                        <foaf:givenname>Donald</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Shook</foaf:surname>
                        <foaf:givenname>Adam</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_147"/>
        <dc:title>MapReduce design patterns</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781449327170 1449327176</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <z:Attachment rdf:about="#item_147">
        <z:itemType>attachment</z:itemType>
        <dc:title>MapReduce Design Patterns - Donald Miner.epub</dc:title>
        <link:type>application/octet-stream</link:type>
    </z:Attachment>
    <bib:Data rdf:about="http://crunch.apache.org/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Apache Software Foundation</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Apache Crunch</dc:title>
        <dcterms:abstract>The Apache Crunch Java library provides a framework for writing, testing, and running MapReduce pipelines. Its goal is to make pipelines that are composed of many user-defined functions simple to write, easy to test, and efficient to run.</dcterms:abstract>
        <dc:date>21:17:56</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://crunch.apache.org/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-25 21:17:56</dcterms:dateSubmitted>
    </bib:Data>
    <rdf:Description rdf:about="http://static.usenix.org/events/osdi10/tech/full_papers/Ford.pdf">
        <z:itemType>conferencePaper</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ford</foaf:surname>
                        <foaf:givenname>Daniel</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Labelle</foaf:surname>
                        <foaf:givenname>Fran\ccois</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Popovici</foaf:surname>
                        <foaf:givenname>Florentina I.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Stokely</foaf:surname>
                        <foaf:givenname>Murray</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Truong</foaf:surname>
                        <foaf:givenname>Van-Anh</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Barroso</foaf:surname>
                        <foaf:givenname>Luiz</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Grimes</foaf:surname>
                        <foaf:givenname>Carrie</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Quinlan</foaf:surname>
                        <foaf:givenname>Sean</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_186"/>
        <dc:title>Availability in Globally Distributed Storage Systems.</dc:title>
        <dc:date>2010</dc:date>
        <dc:title>OSDI</dc:title>
        <bib:pages>61–74</bib:pages>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://static.usenix.org/events/osdi10/tech/full_papers/Ford.pdf</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 05:04:34</dcterms:dateSubmitted>
        <z:libraryCatalog>Google Scholar</z:libraryCatalog>
    </rdf:Description>
    <z:Attachment rdf:about="#item_186">
        <z:itemType>attachment</z:itemType>
        <dc:title>Ford_et_al_2010_Availability_in_Globally_Distributed_Storage_Systems.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Data rdf:about="https://github.com/numenta/nupic">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Numenta</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>NuPIC</dc:title>
        <dcterms:abstract>nupic - Numenta Platform for Intelligent Computing</dcterms:abstract>
        <dc:date>22:10:46</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/numenta/nupic</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 22:10:46</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/twitter/summingbird">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Twitter</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Summingbird</dc:title>
        <dcterms:abstract>summingbird - Streaming MapReduce with Scalding and Storm</dcterms:abstract>
        <dc:date>18:15:42</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/twitter/summingbird</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-28 18:15:42</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/Yelp/mrjob">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Yelp</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>mrjob</dc:title>
        <dcterms:abstract>mrjob - Run MapReduce jobs on Hadoop or Amazon Web Services</dcterms:abstract>
        <dc:date>21:23:32</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/Yelp/mrjob</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-25 21:23:32</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/twitter/chill">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Twitter</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Chill</dc:title>
        <dcterms:abstract>chill - Scala extensions for the Kryo serialization library</dcterms:abstract>
        <dc:date>18:16:38</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/twitter/chill</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-28 18:16:38</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Book rdf:about="urn:isbn:9780262518284%200262518287">
        <z:itemType>book</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Gitelman</foaf:surname>
                        <foaf:givenname>Lisa</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>&quot;Raw data&quot; is an oxymoron</dc:title>
        <dcterms:abstract>We live in the era of Big Data, with storage and transmission capacity measured not just in terabytes but in petabytes (where peta- denotes a quadrillion, or a thousand trillion). Data collection is constant and even insidious, with every click and every &quot;like&quot; stored somewhere for something. This book reminds us that data is anything but &quot;raw,&quot; that we shouldn't think of data as a natural resource but as a cultural one that needs to be generated, protected, and interpreted. The book's essays describe eight episodes in the history of data from the predigital to the digital. Together they address such issues as the ways that different kinds of data and different domains of inquiry are mutually defining; how data are variously &quot;cooked&quot; in the processes of their collection and use; and conflicts over what can -- or can't -- be &quot;reduced&quot; to data. Contributors discuss the intellectual history of data as a concept; describe early financial modeling and some unusual sources for astronomical data; discover the prehistory of the database in newspaper clippings and index cards; and consider contemporary &quot;dataveillance&quot; of our online habits as well as the complexity of scientific data curation.</dcterms:abstract>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9780262518284 0262518287</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://books.google.com/books?isbn=0262518287</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Document rdf:about="http://infogrid.org/trac/wiki/Reference/PidcockArticle">
        <z:itemType>webpage</z:itemType>
        <dcterms:isPartOf>
           <z:Website></z:Website>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Pidcock</foaf:surname>
                        <foaf:givenname>Woody</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Uschold</foaf:surname>
                        <foaf:givenname>Michael</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_51"/>
        <dc:title>What are the differences between a vocabulary, a taxonomy, a thesaurus, an ontology, and a meta-model?</dc:title>
        <dc:date>19:04:58</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://infogrid.org/trac/wiki/Reference/PidcockArticle</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 19:04:58</dcterms:dateSubmitted>
    </bib:Document>
    <z:Attachment rdf:about="#item_51">
        <z:itemType>attachment</z:itemType>
        <dc:title>InfoGrid Web Graph Database - Woody Pidcock.azw3</dc:title>
        <link:type>application/octet-stream</link:type>
    </z:Attachment>
    <bib:Document rdf:about="http://blogs.the451group.com/information_management/files/2013/02/db_Map_2_13.jpg">
        <z:itemType>webpage</z:itemType>
        <dcterms:isPartOf>
           <z:Website></z:Website>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>451 Research</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_1342"/>
        <dc:subject>database</dc:subject>
        <dc:subject>nosql</dc:subject>
        <dc:subject>sql</dc:subject>
        <dc:title>Database Landscape Map</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://blogs.the451group.com/information_management/files/2013/02/db_Map_2_13.jpg</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Document>
    <z:Attachment rdf:about="#item_1342">
        <z:itemType>attachment</z:itemType>
        <dc:title>451_Research_Database_Landscape_Map2.jpg</dc:title>
        <link:type>image/jpeg</link:type>
        <link:charset>5</link:charset>
    </z:Attachment>
    <bib:Data rdf:about="https://code.google.com/p/augustus/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Open Data Group</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>analysis</dc:subject>
        <dc:subject>python</dc:subject>
        <dc:subject>statistics</dc:subject>
        <dc:title>Augustus</dc:title>
        <dcterms:abstract>- PMML model producer and consumer. Scoring engine.</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://code.google.com/p/augustus/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Data>
    <bib:Data rdf:about="http://nodebox.net/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>EMRG</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>design</dc:subject>
        <dc:subject>python</dc:subject>
        <dc:subject>transformation</dc:subject>
        <dc:subject>visualization</dc:subject>
        <dc:title>NodeBox</dc:title>
        <dcterms:abstract>Cross-platform, node-based GUI for efficient data visualizations and generative design.</dcterms:abstract>
        <dc:identifier>
           <dcterms:URI><rdf:value>http://nodebox.net/</rdf:value></dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/Netflix/Priam">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Netflix</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Priam</dc:title>
        <dcterms:abstract>Priam - Co-Process for backup/recovery, Token Management, and Centralized Configuration management for Cassandra.</dcterms:abstract>
        <dc:date>14:10:53</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/Netflix/Priam</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-02 14:10:53</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Document rdf:about="http://joearms.github.com/2013/03/28/solving-the-wrong-problem.html">
        <z:itemType>webpage</z:itemType>
        <dcterms:isPartOf>
           <z:Website></z:Website>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Armstrong</foaf:surname>
                        <foaf:givenname>Joe</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_25"/>
        <dc:subject>development</dc:subject>
        <dc:title>Solving the wrong problem</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://joearms.github.com/2013/03/28/solving-the-wrong-problem.html</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Document>
    <z:Attachment rdf:about="#item_25">
        <z:itemType>attachment</z:itemType>
        <dc:title>Solving the wrong problem - Joe Armstrong.azw3</dc:title>
        <link:type>application/octet-stream</link:type>
    </z:Attachment>
    <bib:Data rdf:about="https://github.com/mbostock/d3">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Bostock</foaf:surname>
                        <foaf:givenname>Michael</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>d3</dc:subject>
        <dc:title>D3.js</dc:title>
        <dcterms:abstract>d3 - A JavaScript visualization library for HTML and SVG.</dcterms:abstract>
        <dc:date>20:18:30</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/mbostock/d3</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-28 20:18:30</dcterms:dateSubmitted>
    </bib:Data>
    <rdf:Description rdf:about="http://dl.acm.org/citation.cfm?id=2208479">
        <z:itemType>conferencePaper</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Sumbaly</foaf:surname>
                        <foaf:givenname>Roshan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kreps</foaf:surname>
                        <foaf:givenname>Jay</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Gao</foaf:surname>
                        <foaf:givenname>Lei</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Feinberg</foaf:surname>
                        <foaf:givenname>Alex</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Soman</foaf:surname>
                        <foaf:givenname>Chinmay</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Shah</foaf:surname>
                        <foaf:givenname>Sam</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_206"/>
        <dc:title>Serving large-scale batch computed data with project voldemort</dc:title>
        <dc:date>2012</dc:date>
        <dc:title>Proceedings of the 10th USENIX conference on File and Storage Technologies</dc:title>
        <bib:pages>18–18</bib:pages>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://dl.acm.org/citation.cfm?id=2208479</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 05:11:24</dcterms:dateSubmitted>
        <z:libraryCatalog>Google Scholar</z:libraryCatalog>
    </rdf:Description>
    <z:Attachment rdf:about="#item_206">
        <z:itemType>attachment</z:itemType>
        <dc:title>Sumbaly_et_al_2012_Serving_large-scale_batch_computed_data_with_project_voldemort.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Data rdf:about="https://github.com/bwhite/hadoopy">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>White</foaf:surname>
                        <foaf:givenname>Brandyn</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Hadoopy</dc:title>
        <dcterms:abstract>Python MapReduce library written in Cython. Visit us in #hadoopy on freenode.  See the link below for documentation and tutorials.</dcterms:abstract>
        <dc:date>21:24:12</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/bwhite/hadoopy</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-25 21:24:12</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Document rdf:about="http://blog.cloudera.com/blog/2013/03/how-to-import-a-pre-existing-oozie-workflow-into-hue/">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Elmahrek</foaf:surname>
                        <foaf:givenname>Abraham</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>hadoop</dc:subject>
        <dc:title>How-to: Import a Pre-existing Oozie Workflow into Hue</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://blog.cloudera.com/blog/2013/03/how-to-import-a-pre-existing-oozie-workflow-into-hue/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Document>
    <bib:Book rdf:about="urn:isbn:9780521706858%20%200521706858%20%209780521880688%20%200521880688%20%209780521884075%20%200521884071">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Cambridge [u.a.</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Cambridge Univ. Press</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Press</foaf:surname>
                        <foaf:givenname>William H</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Numerical recipes: the art of scientific computing</dc:title>
        <dc:date>2007</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9780521706858  0521706858  9780521880688  0521880688  9780521884075  0521884071</dc:identifier>
        <z:shortTitle>Numerical recipes</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <rdf:Description rdf:about="urn:isbn:978-1-60558-942-8">
        <z:itemType>conferencePaper</z:itemType>
        <dcterms:isPartOf>
           <bib:Series><dc:title>HPDC '10</dc:title></bib:Series>
        </dcterms:isPartOf>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>New York, NY, USA</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>ACM</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Leo</foaf:surname>
                        <foaf:givenname>Simone</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Zanetti</foaf:surname>
                        <foaf:givenname>Gianluigi</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_250"/>
        <dc:title>Pydoop: a Python MapReduce and HDFS API for Hadoop</dc:title>
        <dcterms:abstract>MapReduce has become increasingly popular as a simple and efficient paradigm for large-scale data processing. One of the main reasons for its popularity is the availability of a production-level open source implementation, Hadoop, written in Java. There is considerable interest, however, in tools that enable Python programmers to access the framework, due to the language's high popularity. Here we present a Python package that provides an API for both the MapReduce and the distributed file system sections of Hadoop, and show its advantages with respect to the other available solutions for Hadoop Python programming, Jython and Hadoop Streaming.</dcterms:abstract>
        <dc:date>2010</dc:date>
        <bib:pages>819–825</bib:pages>
        <dc:identifier>DOI 10.1145/1851476.1851594</dc:identifier>
        <dc:identifier>ISBN 978-1-60558-942-8</dc:identifier>
        <z:shortTitle>Pydoop</z:shortTitle>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://doi.acm.org/10.1145/1851476.1851594</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-25 21:25:34</dcterms:dateSubmitted>
        <z:libraryCatalog>ACM Digital Library</z:libraryCatalog>
    </rdf:Description>
    <z:Attachment rdf:about="#item_250">
        <z:itemType>attachment</z:itemType>
        <dc:title>Leo_Zanetti_2010_Pydoop.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Book rdf:about="urn:isbn:9780133039436%20%200133039439">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Upper Saddle River, N.J.</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Financial Times/Prentice Hall</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Davenport</foaf:surname>
                        <foaf:givenname>Thomas H</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Enterprise analytics: optimize performance, process and decisions through big data</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9780133039436  0133039439</dc:identifier>
        <z:shortTitle>Enterprise analytics</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Data rdf:about="https://github.com/novus/nvd3">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Novus</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>NVD3</dc:title>
        <dcterms:abstract>Contribute to nvd3 development by creating an account on GitHub.</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/novus/nvd3</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 14:24:36</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/jbryer/sqlutils">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Bryer</foaf:surname>
                        <foaf:givenname>Jason</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>sqlutils</dc:title>
        <dcterms:abstract>sqlutils - R Utilies for managing libraries of SQL queries. The sqlutils package provides functions to document, cache, and execute SQL queries.</dcterms:abstract>
        <dc:date>19:11:04</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/jbryer/sqlutils</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 19:11:04</dcterms:dateSubmitted>
    </bib:Data>
    <rdf:Description rdf:about="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6228206">
        <z:itemType>conferencePaper</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Auradkar</foaf:surname>
                        <foaf:givenname>Aditya</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Botev</foaf:surname>
                        <foaf:givenname>Chavdar</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Das</foaf:surname>
                        <foaf:givenname>Shirshanka</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>De Maagd</foaf:surname>
                        <foaf:givenname>Dave</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Feinberg</foaf:surname>
                        <foaf:givenname>Alex</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ganti</foaf:surname>
                        <foaf:givenname>Phanindra</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Gao</foaf:surname>
                        <foaf:givenname>Lei</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ghosh</foaf:surname>
                        <foaf:givenname>Bhaskar</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Gopalakrishna</foaf:surname>
                        <foaf:givenname>Kishore</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Harris</foaf:surname>
                        <foaf:givenname>Brendan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_218"/>
        <dc:title>Data Infrastructure at LinkedIn</dc:title>
        <dc:date>2012</dc:date>
        <dc:title>Data Engineering (ICDE), 2012 IEEE 28th International Conference on</dc:title>
        <bib:pages>1370–1381</bib:pages>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6228206</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 05:13:22</dcterms:dateSubmitted>
        <z:libraryCatalog>Google Scholar</z:libraryCatalog>
    </rdf:Description>
    <z:Attachment rdf:about="#item_218">
        <z:itemType>attachment</z:itemType>
        <dc:title>Auradkar_et_al_2012_Data_Infrastructure_at_LinkedIn.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Document rdf:about="http://blog.bigml.com/2013/02/28/data-data-data-thousands-of-public-data-sources/">
        <z:itemType>webpage</z:itemType>
        <dcterms:isPartOf>
           <z:Website></z:Website>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Verwoerd</foaf:surname>
                        <foaf:givenname>Jos</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_64"/>
        <dc:subject>datascience</dc:subject>
        <dc:subject>datasource</dc:subject>
        <dc:title>Data, Data, Data: Thousands of Public Data Sources</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://blog.bigml.com/2013/02/28/data-data-data-thousands-of-public-data-sources/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Document>
    <z:Attachment rdf:about="#item_64">
        <z:itemType>attachment</z:itemType>
        <dc:title>Data, Data, Data_ Thousands of  - Jos Verwoerd.azw3</dc:title>
        <link:type>application/octet-stream</link:type>
    </z:Attachment>
    <bib:Data rdf:about="https://github.com/wal-e/wal-e#wal-e-disaster-recovery">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Farina</foaf:surname>
                        <foaf:givenname>Daniel</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>postgresql</dc:subject>
        <dc:title>WAL-E</dc:title>
        <dcterms:abstract>A S3 based WAL-shipping disaster recovery and standby toolkit</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://github.com/wal-e/wal-e#wal-e-disaster-recovery</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Data>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/indecadenza/daa-s-xchange2013galassopiuntiv04">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>de Cadenza</foaf:surname>
                        <foaf:givenname>Michele</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <dc:title>Online Available Data Services: a Primer</dc:title>
        <dcterms:abstract>Data as a Service (DaaS) is the new paradigm where data will be delivered on-demand to be consumed within platform and third-party services. As Open Data gains mainstream adoption at every level of government around the world, public sector organizations are increasingly looking to participate in data ecosystems and drive adoption of their data as fuel for innovation. In this context open data speed up economics combining not only government's open data but heterogeneous, large and rapidly changing dataset from every public sources like social networks, DBpedia (Wikipedia) and many more. The business idea is to design and implement an effective platform able to collect, aggregate and interlink data accessible via APIs in order to enable the creation of the new apps and services for customers. The main pillars of the entire construction is the ability to abstract both the data store and the data access patterns combining a big data architecture with traditional one depending on the data type and volume. Large datasets may want to live on a Hadoop or HBASE cluster, real-time data may have a Cassandra truth store and relax the transactional guarantees but all keep the same APIs.</dcterms:abstract>
        <z:type>Education</z:type>
        <dc:date>Wed Jul 03  2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/indecadenza/daa-s-xchange2013galassopiuntiv04</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 22:12:52</dcterms:dateSubmitted>
        <z:shortTitle>Online Available Data Services</z:shortTitle>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <bib:Data rdf:about="https://github.com/misoproject/dataset">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>The Miso Project</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Dataset.js</dc:title>
        <dcterms:abstract>dataset - JavaScript library that makes managing the data behind client-side visualisations easy</dcterms:abstract>
        <dc:date>22:16:24</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/misoproject/dataset</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 22:16:24</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="http://ganglia.info/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Ganglia Development Team</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Ganglia Monitoring System</dc:title>
        <dc:date>14:17:19</dc:date>
        <dc:identifier>
           <dcterms:URI><rdf:value>http://ganglia.info/</rdf:value></dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-02 14:17:19</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="http://librdf.org/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Beckett</foaf:surname>
                        <foaf:givenname>Dave</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>library</dc:subject>
        <dc:subject>linked-data</dc:subject>
        <dc:subject>semantic</dc:subject>
        <dc:title>Redland RDF Libraries</dc:title>
        <dc:identifier>
           <dcterms:URI><rdf:value>http://librdf.org/</rdf:value></dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Data>
    <bib:Data rdf:about="http://sourceforge.net/apps/mediawiki/bigdata/index.php?title=Main_Page">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>SYSTAP</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>linked-data</dc:subject>
        <dc:subject>semantic</dc:subject>
        <dc:title>Bigdata</dc:title>
        <dcterms:abstract>Bigdata is a horizontally scaled storage and computing fabric supporting optional transactions, very high concurrency, and very high aggregate IO rates.</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://sourceforge.net/apps/mediawiki/bigdata/index.php?title=Main_Page</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/crs4/pydoop">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>CRS4</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Pydoop</dc:title>
        <dcterms:abstract>pydoop - A Python MapReduce and HDFS API for Hadoop</dcterms:abstract>
        <dc:date>21:26:06</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/crs4/pydoop</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-25 21:26:06</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Book rdf:about="urn:isbn:9780123970336">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Waltham, MA</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Morgan Kaufmann</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Sebastian-Coleman</foaf:surname>
                        <foaf:givenname>Laura</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Data structures (Computer science)</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Databases</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Quality control</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:title>Measuring data quality for ongoing improvement: a data quality assessment framework</dc:title>
        <dc:date>2013</dc:date>
        <z:numPages>324</z:numPages>
        <dc:identifier>ISBN 9780123970336</dc:identifier>
        <z:shortTitle>Measuring data quality for ongoing improvement</z:shortTitle>
        <z:libraryCatalog>Library of Congress ISBN</z:libraryCatalog>
        <dc:subject>
           <dcterms:LCC><rdf:value>QA76.9.D35 S43 2013</rdf:value></dcterms:LCC>
        </dc:subject>
    </bib:Book>
    <bib:Document rdf:about="http://bl.ocks.org/mbostock">
        <z:itemType>webpage</z:itemType>
        <dcterms:isPartOf>
           <z:Website></z:Website>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Bostock</foaf:surname>
                        <foaf:givenname>Michael</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>d3</dc:subject>
        <dc:subject>design</dc:subject>
        <dc:subject>javascript</dc:subject>
        <dc:title>bl.ocks.org - mbostock</dc:title>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://bl.ocks.org/mbostock</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Document>
    <bib:Document rdf:about="http://dpinte.wordpress.com/2010/03/12/interactive-python-graphicsvisualisation-with-excel/">
        <z:itemType>webpage</z:itemType>
        <dcterms:isPartOf>
           <z:Website></z:Website>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Pinte</foaf:surname>
                        <foaf:givenname>Didrik</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_53"/>
        <dc:subject>excel</dc:subject>
        <dc:subject>python</dc:subject>
        <dc:title>Interactive Python graphics/visualisation with Excel</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://dpinte.wordpress.com/2010/03/12/interactive-python-graphicsvisualisation-with-excel/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Document>
    <z:Attachment rdf:about="#item_53">
        <z:itemType>attachment</z:itemType>
        <dc:title>Interactive Python graphics_vis - Didrik Pinte.azw3</dc:title>
        <link:type>application/octet-stream</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://www.netmagazine.com/features/seven-dirty-secrets-data-visualisation">
        <z:itemType>magazineArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Periodical></bib:Periodical>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Rabinowitz</foaf:surname>
                        <foaf:givenname>Nick</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Agrin</foaf:surname>
                        <foaf:givenname>Nate</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>education</dc:subject>
        <dc:subject>statistics</dc:subject>
        <dc:subject>visualization</dc:subject>
        <dc:title>Seven dirty secrets of data visualisation</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.netmagazine.com/features/seven-dirty-secrets-data-visualisation</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Article>
    <bib:Book rdf:about="urn:isbn:9780133372823%200133372820">
        <z:itemType>book</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Phillips</foaf:surname>
                        <foaf:givenname>Judah</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Building a digital analytics organization create value by integrating analytical processes, technology, and people into business operations</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9780133372823 0133372820</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://proquest.safaribooksonline.com/?fpi=9780133372823</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-27 10:10:59</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Data rdf:about="https://github.com/stripe/mosql">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Stripe</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>mongodb</dc:subject>
        <dc:subject>nosql</dc:subject>
        <dc:subject>postgresql</dc:subject>
        <dc:subject>sql</dc:subject>
        <dc:subject>streaming</dc:subject>
        <dc:title>MoSQL</dc:title>
        <dcterms:abstract>MongoDB → PostgreSQL streaming replication</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/stripe/mosql</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Data>
    <bib:Data rdf:about="http://sigmajs.org/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Jacomy</foaf:surname>
                        <foaf:givenname>Alexis</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>graph</dc:subject>
        <dc:subject>html5</dc:subject>
        <dc:subject>javascript</dc:subject>
        <dc:title>sigma.js</dc:title>
        <dc:identifier>
           <dcterms:URI><rdf:value>http://sigmajs.org/</rdf:value></dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Data>
    <bib:Data rdf:about="http://incubator.apache.org/drill/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Apache Software Foundation</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Apache Drill</dc:title>
        <dc:date>14:23:49</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://incubator.apache.org/drill/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-02 14:23:49</dcterms:dateSubmitted>
    </bib:Data>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/cloudera/solrhadoopbigdatasearch">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Cloudera, Inc.</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <link:link rdf:resource="#item_285"/>
        <dc:title>Solr+Hadoop = Big Data Search</dc:title>
        <dcterms:abstract>From Solr committer Mark Miller</dcterms:abstract>
        <z:type>Technology</z:type>
        <dc:date>Mon Jul 15  2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/cloudera/solrhadoopbigdatasearch</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 06:24:01</dcterms:dateSubmitted>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <z:Attachment rdf:about="#item_285">
        <z:itemType>attachment</z:itemType>
        <dc:title>Cloudera,_Inc._2013_Solr+Hadoop_=_Big_Data_Search.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Data rdf:about="https://github.com/d3/d3-plugins">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Bostock</foaf:surname>
                        <foaf:givenname>Michael</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>d3</dc:subject>
        <dc:title>D3 Plugins</dc:title>
        <dcterms:abstract>d3-plugins - A repository for sharing D3.js plugins.</dcterms:abstract>
        <dc:date>06:30:57</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/d3/d3-plugins</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-02 06:30:57</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/misoproject/d3.chart">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>The Miso Project</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>d3</dc:subject>
        <dc:title>d3.chart</dc:title>
        <dcterms:abstract>d3.chart - A framework for creating reusable charts with d3.js.</dcterms:abstract>
        <dc:date>22:17:36</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/misoproject/d3.chart</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 22:17:36</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="http://star.mit.edu/cluster/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>MIT</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>automation</dc:subject>
        <dc:subject>aws</dc:subject>
        <dc:subject>deployment</dc:subject>
        <dc:title>STAR: Cluster</dc:title>
        <dcterms:abstract>StarCluster is an open source cluster-computing toolkit for Amazon’s Elastic Compute Cloud (EC2) released under the LGPL license.</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://star.mit.edu/cluster/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Data>
    <bib:Data rdf:about="http://giraph.apache.org/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Apache Software Foundation</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Apache Giraph</dc:title>
        <dc:date>21:38:50</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://giraph.apache.org/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-25 21:38:50</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://wakari.io/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Continuum Analytics</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>analysis</dc:subject>
        <dc:subject>python</dc:subject>
        <dc:subject>saas</dc:subject>
        <dc:subject>scicomp</dc:subject>
        <dc:title>Wakari</dc:title>
        <dcterms:abstract>Accessed through your browser, Wakari is a ready-to-use, powerful, fully-configured Python analytics environment, available on almost any device.</dcterms:abstract>
        <dc:identifier>
           <dcterms:URI><rdf:value>https://wakari.io/</rdf:value></dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Data>
    <bib:Data rdf:about="http://www.microsoft.com/en-us/sqlserver/solutions-technologies/business-intelligence/big-data.aspx">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Microsoft</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>hadoop</dc:subject>
        <dc:subject>mssql</dc:subject>
        <dc:title>HDInsight</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.microsoft.com/en-us/sqlserver/solutions-technologies/business-intelligence/big-data.aspx</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Data>
    <bib:Book rdf:about="urn:isbn:9781449333683">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
               <foaf:name>O'Reilly Media, Inc.</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Howard</foaf:surname>
                        <foaf:givenname>Jeremy</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Zwemer</foaf:surname>
                        <foaf:givenname>Margit</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Loukides</foaf:surname>
                        <foaf:givenname>Mike</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_127"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computers / Programming / General</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:title>Designing Great Data Products</dc:title>
        <dcterms:abstract>In the past few years, we’ve seen many data products based on predictive modeling. These products range from weather forecasting to recommendation engines like Amazon's. Prediction technology can be interesting and mathematically elegant, but we need to take the next step: going from recommendations to products that can produce optimal strategies for meeting concrete business objectives. We already know how to build these products: they've been in use for the past decade or so, but they're not as common as they should be. This report shows how to take the next step: to go from simple predictions and recommendations to a new generation of data products with the potential to revolutionize entire industries.</dcterms:abstract>
        <dc:date>2012-03-23</dc:date>
        <z:numPages>25</z:numPages>
        <z:language>en</z:language>
        <dc:identifier>ISBN 9781449333683</dc:identifier>
        <z:libraryCatalog>Google Books</z:libraryCatalog>
    </bib:Book>
    <z:Attachment rdf:about="#item_127">
        <z:itemType>attachment</z:itemType>
        <dc:title>Designing Great Data Products - Jeremy Howard.azw3</dc:title>
        <link:type>application/octet-stream</link:type>
    </z:Attachment>
    <bib:Data rdf:about="http://www.cascading.org/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Concurrent</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>distributed</dc:subject>
        <dc:subject>hadoop</dc:subject>
        <dc:subject>java</dc:subject>
        <dc:title>Cascading</dc:title>
        <dcterms:abstract>Application Platform for Enterprise Big Data</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://www.cascading.org/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/linkedin/datafu">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>LinkedIn</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>DataFu</dc:title>
        <dcterms:abstract>datafu - Hadoop library for large-scale data processing</dcterms:abstract>
        <dc:date>10:48:47</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/linkedin/datafu</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 10:48:47</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Document rdf:about="http://bost.ocks.org/mike/map/">
        <z:itemType>webpage</z:itemType>
        <dcterms:isPartOf>
           <z:Website></z:Website>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Bostock</foaf:surname>
                        <foaf:givenname>Michael</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>d3</dc:subject>
        <dc:subject>json</dc:subject>
        <dc:subject>mapping</dc:subject>
        <dc:title>Let's Make a Map</dc:title>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://bost.ocks.org/mike/map/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Document>
    <bib:Book rdf:about="urn:isbn:9781118642108%20%201118642104%20%209781118641866%20%201118641868">
        <z:itemType>book</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Simon</foaf:surname>
                        <foaf:givenname>Phil</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Too big to ignore: the business case for big data</dc:title>
        <dcterms:abstract>How businesses of all shapes and sizes can harness the power of Big Data If you haven't heard of Big Data, you're increasingly in the minority. People produce a mind-boggling amount of data every day-so much that making sense of it all is simply beyond the current capabilities of most organizations. Traditional tools and systems just can't handle Big Data. How does a marketer identify an emerging trend when she can't read every tweet, blog post, and customer review? How do we separate meaningful information from the noise of the 2.5 quintillion bytes of data we create every day? Simpl.</dcterms:abstract>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781118642108  1118642104  9781118641866  1118641868</dc:identifier>
        <z:shortTitle>Too big to ignore</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Data rdf:about="http://www.exploredata.net/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Reshef</foaf:surname>
                        <foaf:givenname>David</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Reshef</foaf:surname>
                        <foaf:givenname>Yakir</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>statistics</dc:subject>
        <dc:title>MINE</dc:title>
        <dcterms:abstract>Maximal Information-based Nonparametric Exploration</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://www.exploredata.net/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Data>
    <bib:Data rdf:about="http://rseek.org/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Goodman</foaf:surname>
                        <foaf:givenname>Sasha C.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>R</dc:subject>
        <dc:subject>statistics</dc:subject>
        <dc:title>RSeek.org</dc:title>
        <dcterms:abstract>R-project Search Engine</dcterms:abstract>
        <dc:identifier>
           <dcterms:URI><rdf:value>http://rseek.org/</rdf:value></dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Data>
    <bib:Book rdf:about="urn:isbn:9781118732281%201118732286%209781118530771%20%201118530772">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Hoboken</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Wiley</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kimball</foaf:surname>
                        <foaf:givenname>Ralph</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ross</foaf:surname>
                        <foaf:givenname>Margy</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>The Data Warehouse Toolkit The Definitive Guide to Dimensional Modeling.</dc:title>
        <dcterms:abstract>Updated new edition of Ralph Kimball's groundbreaking book on dimensional modeling for data warehousing and business intelligence! The first edition of Ralph Kimball's The Data Warehouse Toolkit introduced the industry to dimensional modeling, and now his books are considered the most authoritative guides in this space. This new third edition is a complete library of updated dimensional modeling techniques, the most comprehensive collection ever. It covers new and enhanced star schema dimensional modeling patterns, adds two new chapters on ETL techniques, includes new an.</dcterms:abstract>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781118732281 1118732286 9781118530771  1118530772</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://public.eblib.com/EBLPublic/PublicView.do?ptiID=1313513</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 11:15:44</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Article rdf:about="http://dl.acm.org/citation.cfm?id=2367502.2367525">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf rdf:resource="urn:issn:2150-8097"/>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Wu</foaf:surname>
                        <foaf:givenname>Lili</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Sumbaly</foaf:surname>
                        <foaf:givenname>Roshan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Riccomini</foaf:surname>
                        <foaf:givenname>Chris</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Koo</foaf:surname>
                        <foaf:givenname>Gordon</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kim</foaf:surname>
                        <foaf:givenname>Hyung Jin</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kreps</foaf:surname>
                        <foaf:givenname>Jay</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Shah</foaf:surname>
                        <foaf:givenname>Sam</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_350"/>
        <dc:title>Avatara: OLAP for web-scale analytics products</dc:title>
        <dcterms:abstract>Multidimensional data generated by members on websites has seen massive growth in recent years. OLAP is a well-suited solution for mining and analyzing this data. Providing insights derived from this analysis has become crucial for these websites to give members greater value. For example, LinkedIn, the largest professional social network, provides its professional members rich analytics features like &quot;Who's Viewed My Profile?&quot; and &quot;Who's Viewed This Job?&quot; The data behind these features form cubes that must be efficiently served at scale, and can be neatly sharded to do so. To serve our growing 160 million member base, we built a scalable and fast OLAP serving system called Avatara to solve this many, small cubes problem. At LinkedIn, Avatara has been powering several analytics features on the site for the past two years.</dcterms:abstract>
        <bib:pages>1874–1877</bib:pages>
        <dc:date>August 2012</dc:date>
        <z:shortTitle>Avatara</z:shortTitle>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://dl.acm.org/citation.cfm?id=2367502.2367525</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 12:53:08</dcterms:dateSubmitted>
        <z:libraryCatalog>ACM Digital Library</z:libraryCatalog>
    </bib:Article>
    <bib:Journal rdf:about="urn:issn:2150-8097">
        <dc:title>Proc. VLDB Endow.</dc:title>
        <prism:volume>5</prism:volume>
        <prism:number>12</prism:number>
        <dc:identifier>ISSN 2150-8097</dc:identifier>
    </bib:Journal>
    <z:Attachment rdf:about="#item_350">
        <z:itemType>attachment</z:itemType>
        <dc:title>Wu_et_al_2012_Avatara.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Book rdf:about="urn:isbn:1299407412%20%209781299407411%20%209781118654934%201118654935">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Hoboken, N.J.</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Wiley</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Yau</foaf:surname>
                        <foaf:givenname>Nathan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Data points visualization that means something</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 1299407412  9781299407411  9781118654934 1118654935</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://lib.myilibrary.com?id=471991</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 11:15:56</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <rdf:Description rdf:about="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6228205">
        <z:itemType>conferencePaper</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Busch</foaf:surname>
                        <foaf:givenname>Michael</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Gade</foaf:surname>
                        <foaf:givenname>Krishna</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Larson</foaf:surname>
                        <foaf:givenname>Brian</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lok</foaf:surname>
                        <foaf:givenname>Patrick</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Luckenbill</foaf:surname>
                        <foaf:givenname>Samuel</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lin</foaf:surname>
                        <foaf:givenname>Jimmy</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_261"/>
        <dc:title>Earlybird: Real-time search at twitter</dc:title>
        <dc:date>2012</dc:date>
        <dc:title>Data Engineering (ICDE), 2012 IEEE 28th International Conference on</dc:title>
        <bib:pages>1360–1369</bib:pages>
        <z:shortTitle>Earlybird</z:shortTitle>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6228205</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 05:29:42</dcterms:dateSubmitted>
        <z:libraryCatalog>Google Scholar</z:libraryCatalog>
    </rdf:Description>
    <z:Attachment rdf:about="#item_261">
        <z:itemType>attachment</z:itemType>
        <dc:title>Busch_et_al_2012_Earlybird.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Data rdf:about="http://www.quandl.com/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Quandl</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>analysis</dc:subject>
        <dc:subject>datasource</dc:subject>
        <dc:title>Quandl</dc:title>
        <dcterms:abstract>Intelligent Search for Numerical Data</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://www.quandl.com/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/DigitalPebble/behemoth">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>DigitalPebble</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Behemoth</dc:title>
        <dcterms:abstract>behemoth - Behemoth is an open source platform for large scale document analysis based on Apache Hadoop.</dcterms:abstract>
        <dc:date>21:44:24</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/DigitalPebble/behemoth</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-25 21:44:24</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/elasticsearch/elasticsearch-hadoop">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Elasticsearch</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Elasticsearch Hadoop</dc:title>
        <dcterms:abstract>elasticsearch-hadoop - Read and write data to/from ElasticSearch within Hadoop</dcterms:abstract>
        <dc:date>21:46:29</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://github.com/elasticsearch/elasticsearch-hadoop</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-25 21:46:29</dcterms:dateSubmitted>
    </bib:Data>
    <rdf:Description rdf:about="http://dl.acm.org/citation.cfm?id=1996105">
        <z:itemType>conferencePaper</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lin</foaf:surname>
                        <foaf:givenname>Jimmy</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ryaboy</foaf:surname>
                        <foaf:givenname>Dmitriy</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Weil</foaf:surname>
                        <foaf:givenname>Kevin</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_273"/>
        <dc:title>Full-text indexing for optimizing selection operations in large-scale data analytics</dc:title>
        <dc:date>2011</dc:date>
        <dc:title>Proceedings of the second international workshop on MapReduce and its applications</dc:title>
        <bib:pages>59–66</bib:pages>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://dl.acm.org/citation.cfm?id=1996105</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 05:30:37</dcterms:dateSubmitted>
        <z:libraryCatalog>Google Scholar</z:libraryCatalog>
    </rdf:Description>
    <z:Attachment rdf:about="#item_273">
        <z:itemType>attachment</z:itemType>
        <dc:title>Lin_et_al_2011_Full-text_indexing_for_optimizing_selection_operations_in_large-scale_data.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Data rdf:about="https://github.com/elasticsearch/elasticsearch">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Elasticsearch</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>ElasticSearch</dc:title>
        <dcterms:abstract>elasticsearch - Open Source, Distributed, RESTful Search Engine</dcterms:abstract>
        <dc:date>21:48:26</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://github.com/elasticsearch/elasticsearch</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-25 21:48:26</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/precog/labcoat-new">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>SlamData</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Labcoat</dc:title>
        <dcterms:abstract>labcoat-new - The next-generation of Labcoat, a powerful development environment for Quirrel scripts.</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/precog/labcoat-new</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 18:19:26</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/iconara/piglet">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Hultberg</foaf:surname>
                        <foaf:givenname>Theo</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Piglet</dc:title>
        <dcterms:abstract>piglet - Piglet is a DSL for writing Pig scripts in Ruby</dcterms:abstract>
        <dc:date>18:20:11</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/iconara/piglet</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-28 18:20:11</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Article rdf:about="http://dl.acm.org/citation.cfm?id=2367516">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
                <dc:title>Proceedings of the VLDB Endowment</dc:title>
                <prism:volume>5</prism:volume>
                <prism:number>12</prism:number>
            </bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lee</foaf:surname>
                        <foaf:givenname>George</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lin</foaf:surname>
                        <foaf:givenname>Jimmy</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Liu</foaf:surname>
                        <foaf:givenname>Chuang</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lorek</foaf:surname>
                        <foaf:givenname>Andrew</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ryaboy</foaf:surname>
                        <foaf:givenname>Dmitriy</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_279"/>
        <dc:title>The unified logging infrastructure for data analytics at Twitter</dc:title>
        <bib:pages>1771–1780</bib:pages>
        <dc:date>2012</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://dl.acm.org/citation.cfm?id=2367516</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 05:30:37</dcterms:dateSubmitted>
        <z:libraryCatalog>Google Scholar</z:libraryCatalog>
    </bib:Article>
    <z:Attachment rdf:about="#item_279">
        <z:itemType>attachment</z:itemType>
        <dc:title>Lee_et_al_2012_The_unified_logging_infrastructure_for_data_analytics_at_Twitter.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Data rdf:about="https://gephi.org/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>The Gephi Consortium</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>database</dc:subject>
        <dc:subject>graph</dc:subject>
        <dc:subject>tools</dc:subject>
        <dc:subject>visualization</dc:subject>
        <dc:title>Gephi</dc:title>
        <dcterms:abstract>open source graph visualization and manipulation software</dcterms:abstract>
        <dc:identifier>
           <dcterms:URI><rdf:value>https://gephi.org/</rdf:value></dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Data>
    <bib:Data rdf:about="http://www.citusdata.com/downloads">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Citus Data</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>CitusDB</dc:title>
        <dc:date>21:51:57</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://www.citusdata.com/downloads</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-25 21:51:57</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/OpenRefine/OpenRefine">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>OpenRefine Development Team</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>tools</dc:subject>
        <dc:subject>transformation</dc:subject>
        <dc:title>OpenRefine</dc:title>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/OpenRefine/OpenRefine</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Data>
    <bib:Book rdf:about="urn:isbn:9781593273842">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>San Francisco</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>No Starch Press</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Matloff</foaf:surname>
                        <foaf:givenname>Norman S.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_143"/>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Data processing</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>R (Computer program language)</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>statistics</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:title>The art of R programming: tour of statistical software design</dc:title>
        <dc:date>2011</dc:date>
        <z:numPages>373</z:numPages>
        <dc:identifier>ISBN 9781593273842</dc:identifier>
        <z:shortTitle>The art of R programming</z:shortTitle>
        <z:libraryCatalog>Library of Congress ISBN</z:libraryCatalog>
        <dc:subject>
           <dcterms:LCC><rdf:value>QA276.4 .M2925 2011</rdf:value></dcterms:LCC>
        </dc:subject>
    </bib:Book>
    <z:Attachment rdf:about="#item_143">
        <z:itemType>attachment</z:itemType>
        <dc:title>The Art of R Programming_ A Tour of Stat - Norman Matloff.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Data rdf:about="http://vis.stanford.edu/wrangler/app/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Stanford Visualization Group</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>analysis</dc:subject>
        <dc:subject>tools</dc:subject>
        <dc:subject>transformation</dc:subject>
        <dc:title>Data Wrangler</dc:title>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://vis.stanford.edu/wrangler/app/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Data>
    <bib:Data rdf:about="http://code.google.com/p/madis/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>University of Athens</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>analysis</dc:subject>
        <dc:subject>database</dc:subject>
        <dc:subject>python</dc:subject>
        <dc:subject>sql</dc:subject>
        <dc:title>madIS</dc:title>
        <dcterms:abstract>madIS' main goal is to promote the handling of data related tasks within an extended relational model. In doing so, it upgrades the database, from having a support role (storing and retrieving data), to being a full data processing system on its own.</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://code.google.com/p/madis/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Data>
    <bib:Book rdf:about="urn:isbn:9781935504344">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Westfield, NJ</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Technics Publications, LLC</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Eckerson</foaf:surname>
                        <foaf:givenname>Wayne</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Secrets of analytical leaders: insights from information insiders</dc:title>
        <prism:edition>1st ed</prism:edition>
        <dc:date>2012</dc:date>
        <dc:identifier>ISBN 9781935504344</dc:identifier>
        <z:shortTitle>Secrets of analytical leaders</z:shortTitle>
        <z:libraryCatalog>Library of Congress ISBN</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9781935182214">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Greenwich, 74° w. long</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Manning</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Etzion</foaf:surname>
                        <foaf:givenname>Opher</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <bib:contributors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Niblett</foaf:surname>
                        <foaf:givenname>Peter</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:contributors>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Business</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Business enterprises</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer networks</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Data processing</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Discrete-time systems</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Event processing (Computer science)</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
                <rdf:value>Service-oriented architecture (Computer science)</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:title>Event processing in action</dc:title>
        <dc:date>2011</dc:date>
        <z:numPages>360</z:numPages>
        <dc:identifier>ISBN 9781935182214</dc:identifier>
        <z:libraryCatalog>Library of Congress ISBN</z:libraryCatalog>
        <dc:subject>
           <dcterms:LCC><rdf:value>TK5105.5828 .E89 2011</rdf:value></dcterms:LCC>
        </dc:subject>
    </bib:Book>
    <bib:Data rdf:about="https://github.com/GravityLabs/HPaste">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Gravity</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>HPaste</dc:title>
        <dcterms:abstract>HPaste - HBase DSL for Scala with MapReduce support</dcterms:abstract>
        <dc:date>21:52:42</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/GravityLabs/HPaste</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-25 21:52:42</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Article rdf:about="http://lambda.csail.mit.edu/~chet/papers/others/p/pike/sawzall-sciprog.pdf">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Pike</foaf:surname>
                        <foaf:givenname>Rob</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Dorward</foaf:surname>
                        <foaf:givenname>Sean</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Griesemer</foaf:surname>
                        <foaf:givenname>Robert</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Quinlan</foaf:surname>
                        <foaf:givenname>Sean</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_355"/>
        <dc:title>Interpreting the Data: Parallel Analysis with Sawzall</dc:title>
        <dc:date>14:28:57</dc:date>
        <z:shortTitle>Interpreting the Data</z:shortTitle>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://lambda.csail.mit.edu/~chet/papers/others/p/pike/sawzall-sciprog.pdf</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-02 14:28:57</dcterms:dateSubmitted>
        <z:libraryCatalog>Google Scholar</z:libraryCatalog>
    </bib:Article>
    <z:Attachment rdf:about="#item_355">
        <z:itemType>attachment</z:itemType>
        <dc:title>Pike_et_al_0000_Interpreting_the_Data.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Document rdf:about="http://jeffjonas.typepad.com/jeff_jonas/2007/04/streaming_analy.html">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Jonas</foaf:surname>
                        <foaf:givenname>Jeff</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Streaming Analytics vs. Perpetual Analytics (Advantages of Windowless Thinking)</dc:title>
        <dcterms:abstract>The terms &quot;streaming&quot; and &quot;perpetual&quot; probably sound like the same thing to most people. However, in the context of intelligent systems, I think there is a big difference. [Note: when I use the term &quot;observation&quot; below, feel free to think...</dcterms:abstract>
        <dc:date>19:24:09</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://jeffjonas.typepad.com/jeff_jonas/2007/04/streaming_analy.html</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 19:24:09</dcterms:dateSubmitted>
        <z:shortTitle>Jeff Jonas</z:shortTitle>
    </bib:Document>
    <bib:Article rdf:about="http://online.liebertpub.com/doi/full/10.1089/big.2012.1501">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
                <dc:title>Big Data</dc:title>
                <prism:volume>1</prism:volume>
                <prism:number>1</prism:number>
            </bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lin</foaf:surname>
                        <foaf:givenname>Jimmy</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_293"/>
        <dc:title>Mapreduce is Good Enough? If All You Have is a Hammer, Throw Away Everything That's Not a Nail!</dc:title>
        <bib:pages>28–37</bib:pages>
        <dc:date>2013</dc:date>
        <z:shortTitle>Mapreduce is Good Enough?</z:shortTitle>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://online.liebertpub.com/doi/full/10.1089/big.2012.1501</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 05:31:56</dcterms:dateSubmitted>
        <z:libraryCatalog>Google Scholar</z:libraryCatalog>
    </bib:Article>
    <z:Attachment rdf:about="#item_293">
        <z:itemType>attachment</z:itemType>
        <dc:title>Lin_2013_Mapreduce_is_Good_Enough.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Data rdf:about="http://flume.apache.org/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Apache Software Foundation</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>data</dc:subject>
        <dc:subject>streaming</dc:subject>
        <dc:title>Apache Flume</dc:title>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://flume.apache.org/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Data>
    <bib:Book rdf:about="urn:isbn:9781430248736%20%201430248734">
        <z:itemType>book</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Mohanty</foaf:surname>
                        <foaf:givenname>Soumendra</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Jagadeesh</foaf:surname>
                        <foaf:givenname>Madhu</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Srivatsa</foaf:surname>
                        <foaf:givenname>Harsha</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Big data imperatives: enterprise big data warehouse, BI implementations and analytics</dc:title>
        <dcterms:abstract>Big Data Imperatives, focuses on resolving the key questions on everyones mind: Which data matters? Do you have enough data volume to justify the usage? How you want to process this amount of data? How long do you really need to keep it active for your analysis, marketing, and BI applications? Big data is emerging from the realm of one-off projects to mainstream business adoption; however, the real value of big data is not in the overwhelming size of it, but more in its effective use. This book addresses the following big data characteristics: Very large, distributed aggregations of loosely structured data often incomplete and inaccessible Petabytes/Exabytes of data Millions/billions of people providing/contributing to the context behind the data Flat schema's with few complex interrelationships Involves time-stamped events Made up of incomplete data Includes connections between data elements that must be probabilistically inferred Big Data Imperativesexplains 'what big data can do'. It can batch process millions and billions of records both unstructured and structured much faster and cheaper. Big data analytics provide a platform to merge all analysis which enables data analysis to be more accurate, well-rounded, reliable and focused on a specific business capability. Big Data Imperativesdescribes the complementary nature of traditional data warehouses and big-data analytics platforms and how they feed each other. This book aims to bring the big data and analytics realms together with a greater focus on architectures that leverage the scale and power of big data and the ability to integrate and apply analytics principles to data which earlier was not accessible. This book can also be used as a handbook for practitioners; helping them on methodology,technical architecture, analytics techniques and best practices. At the same time, this book intends to hold the interest of those new to big data and analytics by giving them a deep insight into the realm of big data.</dcterms:abstract>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781430248736  1430248734</dc:identifier>
        <z:shortTitle>Big data imperatives</z:shortTitle>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://dx.doi.org/10.1007/978-1-4302-4873-6</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 11:16:06</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Data rdf:about="http://kafka.apache.org">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Apache Software Foundation</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>data</dc:subject>
        <dc:subject>streaming</dc:subject>
        <dc:title>Apache Kafka</dc:title>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://kafka.apache.org</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Data>
    <bib:Data rdf:about="http://www.microsoft.com/sqlserver/en/us/solutions-technologies/business-intelligence/streaming-data.aspx">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Microsoft</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>data</dc:subject>
        <dc:subject>database</dc:subject>
        <dc:subject>mssql</dc:subject>
        <dc:subject>streaming</dc:subject>
        <dc:title>StreamInsight</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.microsoft.com/sqlserver/en/us/solutions-technologies/business-intelligence/streaming-data.aspx</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Data>
    <bib:Book rdf:about="urn:isbn:9781118043868">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Hoboken, N.J</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Wiley</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Brown</foaf:surname>
                        <foaf:givenname>Aaron</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <bib:contributors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kim</foaf:surname>
                        <foaf:givenname>Eric</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:contributors>
        <dc:subject>
           <z:AutomaticTag><rdf:value>20th century</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>21st century</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Decision making</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>finance</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Financial risk</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>History</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Risk</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Risk management</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Speculation</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>United States</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:title>Red-blooded risk: the secret history of Wall Street</dc:title>
        <dc:date>2012</dc:date>
        <z:numPages>415</z:numPages>
        <dc:identifier>ISBN 9781118043868</dc:identifier>
        <z:shortTitle>Red-blooded risk</z:shortTitle>
        <z:libraryCatalog>Library of Congress ISBN</z:libraryCatalog>
        <dc:subject>
           <dcterms:LCC><rdf:value>HD61 .B77 2012</rdf:value></dcterms:LCC>
        </dc:subject>
    </bib:Book>
    <bib:Data rdf:about="https://developers.google.com/bigquery/docs/overview">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Google</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>analysis</dc:subject>
        <dc:subject>distributed</dc:subject>
        <dc:title>Google BigQuery</dc:title>
        <dcterms:abstract>Dremel as a service</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://developers.google.com/bigquery/docs/overview</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Data>
    <bib:Data rdf:about="http://www.enthought.com/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Enthought</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>python</dc:subject>
        <dc:title>EPD</dc:title>
        <dcterms:abstract>Enthought Python Distribution</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://www.enthought.com/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Data>
    <bib:Data rdf:about="http://www.datameer.com/index.html">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Datameer</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>analytics</dc:subject>
        <dc:subject>hadoop</dc:subject>
        <dc:title>Datameer</dc:title>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://www.datameer.com/index.html</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/onyxfish/csvkit">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Groskopf</foaf:surname>
                        <foaf:givenname>Christopher</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>csvkit</dc:title>
        <dcterms:abstract>csvkit - A suite of utilities for converting to and working with CSV, the king of tabular file formats.</dcterms:abstract>
        <dc:date>06:35:31</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/onyxfish/csvkit</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-02 06:35:31</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="http://www.jboss.org/teiid/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Redhat</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>data</dc:subject>
        <dc:subject>database</dc:subject>
        <dc:subject>federation</dc:subject>
        <dc:subject>java</dc:subject>
        <dc:subject>oracle</dc:subject>
        <dc:subject>virtualization</dc:subject>
        <dc:title>JBoss Teiid</dc:title>
        <dcterms:abstract>Teiid is a data virtualization system that allows applications to use data from multiple, heterogenous data stores.</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://www.jboss.org/teiid/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/spotify/luigi">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Spotify</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Luigi</dc:title>
        <dcterms:abstract>luigi - Luigi is a Python module that helps you build complex pipelines of batch jobs. It handles dependency resolution, workflow management, visualization etc. It also comes with Hadoop support built in.</dcterms:abstract>
        <dc:date>10:49:19</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/spotify/luigi</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 10:49:19</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/atbrox/atbr">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Atbrox</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>atbr</dc:title>
        <dcterms:abstract>atbr - large-memory key-value pair store for Python</dcterms:abstract>
        <dc:date>21:56:09</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/atbrox/atbr</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-25 21:56:09</dcterms:dateSubmitted>
    </bib:Data>
    <rdf:Description rdf:about="http://dl.acm.org/citation.cfm?id=2488433">
        <z:itemType>conferencePaper</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Gupta</foaf:surname>
                        <foaf:givenname>Pankaj</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Goel</foaf:surname>
                        <foaf:givenname>Ashish</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lin</foaf:surname>
                        <foaf:givenname>Jimmy</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Sharma</foaf:surname>
                        <foaf:givenname>Aneesh</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Wang</foaf:surname>
                        <foaf:givenname>Dong</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Zadeh</foaf:surname>
                        <foaf:givenname>Reza</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_303"/>
        <dc:title>Wtf: The who to follow service at twitter</dc:title>
        <dc:date>2013</dc:date>
        <dc:title>Proceedings of the 22nd international conference on World Wide Web</dc:title>
        <bib:pages>505–514</bib:pages>
        <z:shortTitle>Wtf</z:shortTitle>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://dl.acm.org/citation.cfm?id=2488433</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 05:33:22</dcterms:dateSubmitted>
        <z:libraryCatalog>Google Scholar</z:libraryCatalog>
    </rdf:Description>
    <z:Attachment rdf:about="#item_303">
        <z:itemType>attachment</z:itemType>
        <dc:title>Gupta_et_al_2013_Wtf.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Data rdf:about="http://hive.apache.org/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Apache Software Foundation</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>hadoop</dc:subject>
        <dc:subject>Hive</dc:subject>
        <dc:subject>sql</dc:subject>
        <dc:title>Apache Hive</dc:title>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://hive.apache.org/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Data>
    <bib:Data rdf:about="http://sqoop.apache.org/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Apache Software Foundation</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>hadoop</dc:subject>
        <dc:title>Apache Sqoop</dc:title>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://sqoop.apache.org/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Data>
    <bib:Book rdf:about="urn:isbn:9781449390419%20%201449390412">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Beijing</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Hewitt</foaf:surname>
                        <foaf:givenname>Eben</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Cassandra: the definitive guide</dc:title>
        <dcterms:abstract>A guide to Apache Cassandra covers such topics as write, update, and read Cassandra data; add or remove nodes from the cluster; use the JMX interface to monitor a cluster's usage; and tune memory settings and data storage for better performance.</dcterms:abstract>
        <dc:date>2011</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781449390419  1449390412</dc:identifier>
        <z:shortTitle>Cassandra</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Data rdf:about="https://github.com/jkbr/httpie">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Roztočil</foaf:surname>
                        <foaf:givenname>Jakub</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>HTTPie</dc:title>
        <dcterms:abstract>httpie - HTTPie is a CLI, cURL-like tool for humans.</dcterms:abstract>
        <dc:date>19:25:33</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/jkbr/httpie</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 19:25:33</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="http://nltk.org/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Bird</foaf:surname>
                        <foaf:givenname>Steven</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>nlp</dc:subject>
        <dc:subject>python</dc:subject>
        <dc:title>NLTK</dc:title>
        <dcterms:abstract>The Natural Language Toolkit (NLTK) is a Python package for natural language processing.</dcterms:abstract>
        <dc:identifier>
           <dcterms:URI><rdf:value>http://nltk.org/</rdf:value></dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Data>
    <bib:Data rdf:about="urn:isbn:B007US6CIO">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Amazon Web Services</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>analytics</dc:subject>
        <dc:subject>aws</dc:subject>
        <dc:subject>framework</dc:subject>
        <dc:subject>hadoop</dc:subject>
        <dc:subject>java</dc:subject>
        <dc:title>Amazon Elastic MapReduce (EMR)</dc:title>
        <dc:identifier>ISBN B007US6CIO</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://aws.amazon.com/elasticmapreduce/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Data>
    <bib:Data rdf:about="http://www-958.ibm.com/software/data/cognos/manyeyes/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>IBM</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>analysis</dc:subject>
        <dc:subject>tools</dc:subject>
        <dc:subject>visualization</dc:subject>
        <dc:title>Many Eyes</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www-958.ibm.com/software/data/cognos/manyeyes/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/kennethreitz/elephant">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Reitz</foaf:surname>
                        <foaf:givenname>Kenneth</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Elephant</dc:title>
        <dcterms:abstract>elephant - A persistent, full-text searchable key-value store. Powered by Flask, ElasticSearch, and good intentions.</dcterms:abstract>
        <dc:date>19:28:21</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/kennethreitz/elephant</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 19:28:21</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Article rdf:about="http://dl.acm.org/citation.cfm?id=2481247">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
                <dc:title>ACM SIGKDD Explorations Newsletter</dc:title>
                <prism:volume>14</prism:volume>
                <prism:number>2</prism:number>
            </bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lin</foaf:surname>
                        <foaf:givenname>Jimmy</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ryaboy</foaf:surname>
                        <foaf:givenname>Dmitriy</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_312"/>
        <dc:title>Scaling big data mining infrastructure: the twitter experience</dc:title>
        <bib:pages>6–19</bib:pages>
        <dc:date>2013</dc:date>
        <z:shortTitle>Scaling big data mining infrastructure</z:shortTitle>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://dl.acm.org/citation.cfm?id=2481247</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 05:33:51</dcterms:dateSubmitted>
        <z:libraryCatalog>Google Scholar</z:libraryCatalog>
    </bib:Article>
    <z:Attachment rdf:about="#item_312">
        <z:itemType>attachment</z:itemType>
        <dc:title>Lin_Ryaboy_2013_Scaling_big_data_mining_infrastructure.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Data rdf:about="http://callimachusproject.org/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>3 Round Stones</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>Linked Data</dc:subject>
        <dc:title>Callimachus</dc:title>
        <dcterms:abstract>Data-driven applications made easy</dcterms:abstract>
        <dc:date>21:58:48</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://callimachusproject.org/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-25 21:58:48</dcterms:dateSubmitted>
    </bib:Data>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/MapRTechnologies/technical-overview-of-apache-drill-by-jac?from_search=1">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Nadeau</foaf:surname>
                        <foaf:givenname>Jacques</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <bib:contributors>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>MapR</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:contributors>
        <link:link rdf:resource="#item_341"/>
        <dc:title>Technical Overview of Apache Drill</dc:title>
        <dcterms:abstract>A deep dive into Apache Drill given by Jacques Nadeau on May 2013.</dcterms:abstract>
        <z:type>Technology</z:type>
        <dc:date>Tue Aug 13  2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/MapRTechnologies/technical-overview-of-apache-drill-by-jac?from_search=1</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 06:27:57</dcterms:dateSubmitted>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <z:Attachment rdf:about="#item_341">
        <z:itemType>attachment</z:itemType>
        <dc:title>MapR_Technologies_2013_Technical_Overview_of_Apache_Drill_by_Jacques_Nadeau.pptx</dc:title>
        <link:type>application/vnd.openxmlformats-officedocument.presentationml.presentation</link:type>
    </z:Attachment>
    <bib:Book rdf:about="urn:isbn:9781933988382">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                        <vcard:locality>Shelter Island, NY : London</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Manning ; Pearson Education [distributor]</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ingersoll</foaf:surname>
                        <foaf:givenname>Grant S.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <bib:contributors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Morton</foaf:surname>
                        <foaf:givenname>Thomas S.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Farris</foaf:surname>
                        <foaf:givenname>Andrew L.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:contributors>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Text processing (Computer science)</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:title>Taming text: how to find, organise, and manipulate it</dc:title>
        <dc:date>2013</dc:date>
        <z:numPages>298</z:numPages>
        <dc:identifier>ISBN 9781933988382</dc:identifier>
        <z:shortTitle>Taming text</z:shortTitle>
        <z:libraryCatalog>Library of Congress ISBN</z:libraryCatalog>
    </bib:Book>
    <bib:Data rdf:about="https://github.com/calufa/tales-core">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Chinchilla</foaf:surname>
                        <foaf:givenname>Carlos</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Tales</dc:title>
        <dcterms:abstract>tales-core - Tales is a block tolerant web scraper that runs on top of aws and rackspace. Tales is design to be easy to deploy, configure, and manage.</dcterms:abstract>
        <dc:date>22:00:25</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/calufa/tales-core</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-25 22:00:25</dcterms:dateSubmitted>
    </bib:Data>
    <rdf:Description rdf:about="http://www.aaai.org/ocs/index.php/icwsm/icwsm12/paper/download/4785/5095">
        <z:itemType>conferencePaper</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Rios</foaf:surname>
                        <foaf:givenname>Miguel</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lin</foaf:surname>
                        <foaf:givenname>Jimmy</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_320"/>
        <dc:title>Distilling massive amounts of data into simple visualizations: Twitter case studies</dc:title>
        <dc:date>2012</dc:date>
        <dc:title>Workshop on Social Media Visualization at ICWSM</dc:title>
        <z:shortTitle>Distilling massive amounts of data into simple visualizations</z:shortTitle>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.aaai.org/ocs/index.php/icwsm/icwsm12/paper/download/4785/5095</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 05:34:14</dcterms:dateSubmitted>
        <z:libraryCatalog>Google Scholar</z:libraryCatalog>
    </rdf:Description>
    <z:Attachment rdf:about="#item_320">
        <z:itemType>attachment</z:itemType>
        <dc:title>Rios_Lin_2012_Distilling_massive_amounts_of_data_into_simple_visualizations.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Data rdf:about="http://spark-project.org/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Apache Software Foundation</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>analysis</dc:subject>
        <dc:subject>data</dc:subject>
        <dc:subject>distributed</dc:subject>
        <dc:subject>java</dc:subject>
        <dc:subject>python</dc:subject>
        <dc:subject>scicomp</dc:subject>
        <dc:subject>tools</dc:subject>
        <dc:title>Apache Spark</dc:title>
        <dcterms:abstract>Lightning-Fast Cluster Computing</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://spark-project.org/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>PRIVATE=0; TOREAD=0</dc:description>
    </bib:Data>
    <bib:Book rdf:about="urn:isbn:9780124158115">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Waltham, MA</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Morgan Kaufmann</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Wise</foaf:surname>
                        <foaf:givenname>Lyndsay</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <bib:contributors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Dierna</foaf:surname>
                        <foaf:givenname>Andrea</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:contributors>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Business intelligence</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer programs</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Management information systems</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Open source intelligence</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Open source software</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:title>Using open source platforms for business intelligence: avoid pitfalls and maximize ROI</dc:title>
        <dc:date>2012</dc:date>
        <z:numPages>210</z:numPages>
        <dc:identifier>ISBN 9780124158115</dc:identifier>
        <z:shortTitle>Using open source platforms for business intelligence</z:shortTitle>
        <z:libraryCatalog>Library of Congress ISBN</z:libraryCatalog>
        <dc:subject>
           <dcterms:LCC><rdf:value>HD38.7 .W566 2012</rdf:value></dcterms:LCC>
        </dc:subject>
    </bib:Book>
    <bib:Document rdf:about="http://labs.umbrella.com/2013/04/08/pig-jruby/">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog><dc:title>Umbrella Security Labs</dc:title></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Denis</foaf:surname>
                        <foaf:givenname>Frank</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>Pig</dc:subject>
        <dc:title>Why we love Apache Pig</dc:title>
        <dcterms:abstract>How OpenDNS uses Pig and JRuby for security research.</dcterms:abstract>
        <dc:date>20:10:20</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://labs.umbrella.com/2013/04/08/pig-jruby/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-23 20:10:20</dcterms:dateSubmitted>
    </bib:Document>
    <bib:Data rdf:about="https://github.com/twitter/hadoop-lzo">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Twitter</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Hadoop-LZO</dc:title>
        <dcterms:abstract>hadoop-lzo - Refactored version of code.google.com/hadoop-gpl-compression for hadoop 0.20</dcterms:abstract>
        <dc:date>18:20:28</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/twitter/hadoop-lzo</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-28 18:20:28</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="http://code.google.com/p/kryo/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Sweet</foaf:surname>
                        <foaf:givenname>Nathan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Kryo</dc:title>
        <dcterms:abstract>Fast, efficient Java serialization and cloning</dcterms:abstract>
        <dc:date>18:23:35</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://code.google.com/p/kryo/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-28 18:23:35</dcterms:dateSubmitted>
    </bib:Data>
    <rdf:Description rdf:about="http://www.aaai.org/ocs/index.php/ICWSM/ICWSM13/paper/viewPaper/6127">
        <z:itemType>conferencePaper</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Rios</foaf:surname>
                        <foaf:givenname>Miguel</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lin</foaf:surname>
                        <foaf:givenname>Jimmy</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_326"/>
        <dc:title>Visualizing the&quot; Pulse&quot; of World Cities on Twitter</dc:title>
        <dc:date>2013</dc:date>
        <dc:title>Seventh International AAAI Conference on Weblogs and Social Media</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.aaai.org/ocs/index.php/ICWSM/ICWSM13/paper/viewPaper/6127</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 05:36:39</dcterms:dateSubmitted>
        <z:libraryCatalog>Google Scholar</z:libraryCatalog>
    </rdf:Description>
    <z:Attachment rdf:about="#item_326">
        <z:itemType>attachment</z:itemType>
        <dc:title>Rios_Lin_2013_Visualizing_the_Pulse_of_World_Cities_on_Twitter.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Data rdf:about="https://github.com/kevinweil/elephant-bird">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Twitter</foaf:surname></foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Weil</foaf:surname>
                        <foaf:givenname>Kevin</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ryaboy</foaf:surname>
                        <foaf:givenname>Dmitriy</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Liu</foaf:surname>
                        <foaf:givenname>Chuang</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Leibert</foaf:surname>
                        <foaf:givenname>Florian</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Elephant Bird</dc:title>
        <dcterms:abstract>elephant-bird - Twitter's collection of LZO and Protocol Buffer-related Hadoop, Pig, Hive, and HBase code.</dcterms:abstract>
        <dc:date>18:23:49</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/kevinweil/elephant-bird</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-28 18:23:49</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/mortardata/bacon-bits">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Mortar Data</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>bacon-bits</dc:title>
        <dcterms:abstract>Contribute to bacon-bits development by creating an account on GitHub.</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/mortardata/bacon-bits</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 18:23:48</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/json-ld/json-ld.org">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>JSON-LD</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>JSON-LD</dc:title>
        <dcterms:abstract>json-ld.org - JSON for Linked Data</dcterms:abstract>
        <dc:date>19:30:23</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/json-ld/json-ld.org</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 19:30:23</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Article rdf:about="http://online.wsj.com/article/SB10001424127887323419604578571684135006800.html">
        <z:itemType>newspaperArticle</z:itemType>
        <dcterms:isPartOf rdf:resource="urn:issn:0099-9660"/>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Murphy</foaf:surname>
                        <foaf:givenname>Maxwell</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>CFOs Ignore Big Data at Their Peril</dc:title>
        <dcterms:abstract>Many finance chiefs are holding off on big-data investments for now, saying their existing tools work just fine. Some experts say they're missing out.</dcterms:abstract>
        <dc:date>Updated July 18, 2013, 12:30 P.m. ET</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://online.wsj.com/article/SB10001424127887323419604578571684135006800.html</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-02 06:37:59</dcterms:dateSubmitted>
        <z:libraryCatalog>Wall Street Journal</z:libraryCatalog>
    </bib:Article>
    <bib:Newspaper rdf:about="urn:issn:0099-9660">
        <dc:title>Wall Street Journal</dc:title>
        <dc:identifier>ISSN 0099-9660</dc:identifier>
    </bib:Newspaper>
    <bib:Article rdf:about="http://arxiv.org/abs/1304.7544">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
               <dc:title>arXiv preprint arXiv:1304.7544</dc:title>
            </bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lin</foaf:surname>
                        <foaf:givenname>Jimmy</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_336"/>
        <dc:title>Monoidify! Monoids as a Design Principle for Efficient MapReduce Algorithms</dc:title>
        <dc:date>2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://arxiv.org/abs/1304.7544</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 05:38:01</dcterms:dateSubmitted>
        <z:libraryCatalog>Google Scholar</z:libraryCatalog>
    </bib:Article>
    <z:Attachment rdf:about="#item_336">
        <z:itemType>attachment</z:itemType>
        <dc:title>Lin_2013_Monoidify!_Monoids_as_a_Design_Principle_for_Efficient_MapReduce_Algorithms.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://doi.acm.org/10.1145/79173.79181">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf rdf:resource="urn:issn:0001-0782"/>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Valiant</foaf:surname>
                        <foaf:givenname>Leslie G.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_373"/>
        <dc:title>A bridging model for parallel computation</dc:title>
        <dcterms:abstract>The success of the von Neumann model of sequential computation is attributable to the fact that it is an efficient bridge between software and hardware: high-level languages can be efficiently compiled on to this model; yet it can be effeciently implemented in hardware. The author argues that an analogous bridge between software and hardware in required for parallel computation if that is to become as widely used. This article introduces the bulk-synchronous parallel (BSP) model as a candidate for this role, and gives results quantifying its efficiency both in implementing high-level language features and algorithms, as well as in being implemented in hardware.</dcterms:abstract>
        <bib:pages>103–111</bib:pages>
        <dc:date>August 1990</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://doi.acm.org/10.1145/79173.79181</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-01 12:50:13</dcterms:dateSubmitted>
        <z:libraryCatalog>ACM Digital Library</z:libraryCatalog>
    </bib:Article>
    <bib:Journal rdf:about="urn:issn:0001-0782">
        <dc:title>Commun. ACM</dc:title>
        <prism:volume>33</prism:volume>
        <prism:number>8</prism:number>
        <dc:identifier>DOI 10.1145/79173.79181</dc:identifier>
        <dc:identifier>ISSN 0001-0782</dc:identifier>
    </bib:Journal>
    <z:Attachment rdf:about="#item_373">
        <z:itemType>attachment</z:itemType>
        <dc:title>Valiant_1990_A_bridging_model_for_parallel_computation.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/Hadoop_Summit/large-scale-search-discover-analytics-mahoot-solr">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ingersoll</foaf:surname>
                        <foaf:givenname>Grant S.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <dc:title>Large-Scale Search Discovery Analytics with Hadoop, Mahout, Solr</dc:title>
        <z:type>Technology</z:type>
        <dc:date>Wed Jun 20  2012</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/Hadoop_Summit/large-scale-search-discover-analytics-mahoot-solr</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-01 15:32:14</dcterms:dateSubmitted>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <bib:Article rdf:about="http://vis.stanford.edu/files/2011-D3-InfoVis.pdf">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Bostock</foaf:surname>
                        <foaf:givenname>Michael</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ogievetsky</foaf:surname>
                        <foaf:givenname>Vadim</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Heer</foaf:surname>
                        <foaf:givenname>Jeffrey</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_222"/>
        <dc:subject>d3</dc:subject>
        <dc:title>D 3: Data-Driven Documents</dc:title>
        <dc:date>20:20:43</dc:date>
        <z:shortTitle>D 3</z:shortTitle>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://vis.stanford.edu/files/2011-D3-InfoVis.pdf</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-28 20:20:43</dcterms:dateSubmitted>
        <z:libraryCatalog>Google Scholar</z:libraryCatalog>
    </bib:Article>
    <z:Attachment rdf:about="#item_222">
        <z:itemType>attachment</z:itemType>
        <dc:title>Bostock_et_al_0000_D_3.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <rdf:Description rdf:about="urn:isbn:978-1-4503-0032-2">
        <z:itemType>conferencePaper</z:itemType>
        <dcterms:isPartOf>
           <bib:Series><dc:title>SIGMOD '10</dc:title></bib:Series>
        </dcterms:isPartOf>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>New York, NY, USA</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>ACM</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Malewicz</foaf:surname>
                        <foaf:givenname>Grzegorz</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Austern</foaf:surname>
                        <foaf:givenname>Matthew H.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Bik</foaf:surname>
                        <foaf:givenname>Aart J.C</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Dehnert</foaf:surname>
                        <foaf:givenname>James C.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Horn</foaf:surname>
                        <foaf:givenname>Ilan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Leiser</foaf:surname>
                        <foaf:givenname>Naty</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Czajkowski</foaf:surname>
                        <foaf:givenname>Grzegorz</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_165"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>distributed computing</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>graph algorigthms</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:title>Pregel: a system for large-scale graph processing</dc:title>
        <dcterms:abstract>Many practical computing problems concern large graphs. Standard examples include the Web graph and various social networks. The scale of these graphs - in some cases billions of vertices, trillions of edges - poses challenges to their efficient processing. In this paper we present a computational model suitable for this task. Programs are expressed as a sequence of iterations, in each of which a vertex can receive messages sent in the previous iteration, send messages to other vertices, and modify its own state and that of its outgoing edges or mutate graph topology. This vertex-centric approach is flexible enough to express a broad set of algorithms. The model has been designed for efficient, scalable and fault-tolerant implementation on clusters of thousands of commodity computers, and its implied synchronicity makes reasoning about programs easier. Distribution-related details are hidden behind an abstract API. The result is a framework for processing large graphs that is expressive and easy to program.</dcterms:abstract>
        <dc:date>2010</dc:date>
        <bib:pages>135–146</bib:pages>
        <dc:identifier>DOI 10.1145/1807167.1807184</dc:identifier>
        <dc:identifier>ISBN 978-1-4503-0032-2</dc:identifier>
        <z:shortTitle>Pregel</z:shortTitle>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://doi.acm.org/10.1145/1807167.1807184</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-01 12:51:12</dcterms:dateSubmitted>
        <z:libraryCatalog>ACM Digital Library</z:libraryCatalog>
    </rdf:Description>
    <z:Attachment rdf:about="#item_165">
        <z:itemType>attachment</z:itemType>
        <dc:title>Malewicz_et_al_2010_Pregel.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Document rdf:about="http://timelyportfolio.blogspot.com/2013/04/d3-lifeline-from-vega-and-clickme.html">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog><dc:title>Timely Portfolio</dc:title></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Klr</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>
           <z:AutomaticTag><rdf:value>clickme</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>d3</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>R</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>ractive</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>vega</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:title>d3 Lifeline from vega and clickme</dc:title>
        <dc:date>Thursday, April 4, 2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://timelyportfolio.blogspot.com/2013/04/d3-lifeline-from-vega-and-clickme.html</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-28 20:24:25</dcterms:dateSubmitted>
        <z:shortTitle>Timely Portfolio</z:shortTitle>
    </bib:Document>
    <bib:Data rdf:about="https://github.com/nathanmarz/storm">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Marz</foaf:surname>
                        <foaf:givenname>Nathan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Storm</dc:title>
        <dcterms:abstract>storm - Distributed and fault-tolerant realtime computation: stream processing, continuous computation, distributed RPC, and more</dcterms:abstract>
        <dc:date>22:01:45</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/nathanmarz/storm</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-25 22:01:45</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Report rdf:about="http://arxiv.org/abs/1301.7592">
        <z:itemType>report</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Apt</foaf:surname>
                        <foaf:givenname>Krzysztof R.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Markakis</foaf:surname>
                        <foaf:givenname>Evangelos</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Simon</foaf:surname>
                        <foaf:givenname>Sunil</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>
            <z:AutomaticTag>
                <rdf:value>Computer Science - Computer Science and Game Theory</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
                <rdf:value>Computer Science - Social and Information Networks</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:title>Paradoxes in Social Networks with Multiple Products</dc:title>
        <dcterms:abstract>Recently, we introduced in arXiv:1105.2434 a model for product adoption in social networks with multiple products, where the agents, influenced by their neighbours, can adopt one out of several alternatives. We identify and analyze here four types of paradoxes that can arise in these networks. To this end, we use social network games that we recently introduced in arxiv:1202.2209. These paradoxes shed light on possible inefficiencies arising when one modifies the sets of products available to the agents forming a social network. One of the paradoxes corresponds to the well-known Braess paradox in congestion games and shows that by adding more choices to a node, the network may end up in a situation that is worse for everybody. We exhibit a dual version of this, where removing available choices from someone can eventually make everybody better off. The other paradoxes that we identify show that by adding or removing a product from the choice set of some node may lead to permanent instability. Finally, we also identify conditions under which some of these paradoxes cannot arise.</dcterms:abstract>
        <prism:number>1301.7592</prism:number>
        <z:type>arXiv e-print</z:type>
        <dc:date>2013-01-31</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://arxiv.org/abs/1301.7592</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-02 06:41:31</dcterms:dateSubmitted>
        <z:libraryCatalog>arXiv.org</z:libraryCatalog>
    </bib:Report>
    <bib:Article rdf:about="http://arxiv.org/abs/1210.7350">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
               <dc:title>arXiv preprint arXiv:1210.7350</dc:title>
            </bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Mishne</foaf:surname>
                        <foaf:givenname>Gilad</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Dalton</foaf:surname>
                        <foaf:givenname>Jeff</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Li</foaf:surname>
                        <foaf:givenname>Zhenghua</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Sharma</foaf:surname>
                        <foaf:givenname>Aneesh</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lin</foaf:surname>
                        <foaf:givenname>Jimmy</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_343"/>
        <dc:title>Fast Data in the Era of Big Data: Twitter's Real-Time Related Query Suggestion Architecture</dc:title>
        <dc:date>2012</dc:date>
        <z:shortTitle>Fast Data in the Era of Big Data</z:shortTitle>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://arxiv.org/abs/1210.7350</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 05:38:28</dcterms:dateSubmitted>
        <z:libraryCatalog>Google Scholar</z:libraryCatalog>
    </bib:Article>
    <z:Attachment rdf:about="#item_343">
        <z:itemType>attachment</z:itemType>
        <dc:title>Mishne_et_al_2012_Fast_Data_in_the_Era_of_Big_Data.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/visualisingdata/the-8-hats-of-data-visualisation">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kirk</foaf:surname>
                        <foaf:givenname>Andy</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <dc:title>The 8 Hats of Data Visualisation</dc:title>
        <dcterms:abstract>These slides are from recent talks by Andy Kirk of visualisingdata.com. The subject refers to the many different mindsets or roles that are required to be fulfilled for the effective design of data visualisation.</dcterms:abstract>
        <z:type>Technology</z:type>
        <dc:date>Sat Jun 23  2012</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/visualisingdata/the-8-hats-of-data-visualisation</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-29 00:12:37</dcterms:dateSubmitted>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <bib:Report rdf:about="http://arxiv.org/abs/1006.2361">
        <z:itemType>report</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Rodriguez</foaf:surname>
                        <foaf:givenname>Marko A.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Neubauer</foaf:surname>
                        <foaf:givenname>Peter</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>
            <z:AutomaticTag>
                <rdf:value>Computer Science - Data Structures and Algorithms</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>E.1</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:title>Constructions from Dots and Lines</dc:title>
        <dcterms:abstract>A graph is a data structure composed of dots (i.e. vertices) and lines (i.e. edges). The dots and lines of a graph can be organized into intricate arrangements. The ability for a graph to denote objects and their relationships to one another allow for a surprisingly large number of things to be modeled as a graph. From the dependencies that link software packages to the wood beams that provide the framing to a house, most anything has a corresponding graph representation. However, just because it is possible to represent something as a graph does not necessarily mean that its graph representation will be useful. If a modeler can leverage the plethora of tools and algorithms that store and process graphs, then such a mapping is worthwhile. This article explores the world of graphs in computing and exposes situations in which graphical models are beneficial.</dcterms:abstract>
        <prism:number>1006.2361</prism:number>
        <z:type>arXiv e-print</z:type>
        <dc:date>2010-06-11</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://arxiv.org/abs/1006.2361</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-01 12:55:26</dcterms:dateSubmitted>
        <z:libraryCatalog>arXiv.org</z:libraryCatalog>
        <dc:description>Bulletin of the American Society for Information Science and Technology, American Society for Information Science and Technology, 36,(6), pp. 35-41, ISSN:1550-8366, August 2010</dc:description>
    </bib:Report>
    <bib:Data rdf:about="https://github.com/klbostee/dumbo">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Bosteels</foaf:surname>
                        <foaf:givenname>Klaas</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Dumbo</dc:title>
        <dcterms:abstract>dumbo - Python module that allows one to easily write and run Hadoop programs.</dcterms:abstract>
        <dc:date>10:50:33</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/klbostee/dumbo</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 10:50:33</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Book rdf:about="urn:isbn:0124016960%209780124016965">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>[S.l.]</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Morgan Kaufmann</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Sheikh</foaf:surname>
                        <foaf:givenname>Nauman</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Implementing analytics: a blueprint for design, development, and adoption.</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 0124016960 9780124016965</dc:identifier>
        <z:shortTitle>Implementing analytics</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Document rdf:about="http://thedatachef.blogspot.com/2013/08/using-hadoop-to-explore-chaos.html">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog><dc:title>Data Recipes</dc:title></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Perkins</foaf:surname>
                        <foaf:givenname>Jacob</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Data Recipes: Using Hadoop to Explore Chaos</dc:title>
        <dc:date>Monday, August 12, 2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://thedatachef.blogspot.com/2013/08/using-hadoop-to-explore-chaos.html</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 10:59:49</dcterms:dateSubmitted>
        <z:shortTitle>Data Recipes</z:shortTitle>
    </bib:Document>
    <bib:Document rdf:about="https://www.facebook.com/notes/facebook-engineering/scaling-apache-giraph-to-a-trillion-edges/10151617006153920">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ching</foaf:surname>
                        <foaf:givenname>Avery</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Scaling Apache Giraph to a trillion edges</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://www.facebook.com/notes/facebook-engineering/scaling-apache-giraph-to-a-trillion-edges/10151617006153920</rdf:value>
            </dcterms:URI>
        </dc:identifier>
    </bib:Document>
    <bib:Document rdf:about="https://communities.intel.com/community/datastack/blog/2013/08/15/hadoop-tutorials-ingesting-xml-in-hive-using-xpath">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog><dc:title>The Data Stack</dc:title></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Singh</foaf:surname>
                        <foaf:givenname>Chandeep</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>
           <z:AutomaticTag><rdf:value>big_data</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>cloud_computing</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>data_center_management</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Hadoop</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:title>Ingesting XML in Hive using XPath</dc:title>
        <dcterms:abstract>In the first of my series of Hadoop tutorials, I wanted to share an interesting case that arose when I was experiencing poor performance trying to do queries and computations on a set of XML Data. These computations could be mathematical as well as s...</dcterms:abstract>
        <dc:date>11:02:02</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://communities.intel.com/community/datastack/blog/2013/08/15/hadoop-tutorials-ingesting-xml-in-hive-using-xpath</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 11:02:02</dcterms:dateSubmitted>
    </bib:Document>
    <bib:Book rdf:about="urn:isbn:9781617290237">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Shelter Island, NY</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Manning</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Holmes</foaf:surname>
                        <foaf:givenname>Alex</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_125"/>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Apache Hadoop</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Distributed processing</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Electronic data processing</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>File organization (Computer science)</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:title>Hadoop in practice</dc:title>
        <dc:date>2012</dc:date>
        <z:numPages>511</z:numPages>
        <dc:identifier>ISBN 9781617290237</dc:identifier>
        <z:libraryCatalog>Library of Congress ISBN</z:libraryCatalog>
        <dc:subject>
           <dcterms:LCC><rdf:value>QA76.9.D5 H64 2012</rdf:value></dcterms:LCC>
        </dc:subject>
    </bib:Book>
    <z:Attachment rdf:about="#item_125">
        <z:itemType>attachment</z:itemType>
        <dc:title>Hadoop in Practice - Alex Holmes.epub</dc:title>
        <link:type>application/octet-stream</link:type>
    </z:Attachment>
    <bib:Data rdf:about="https://github.com/iconara/rubydoop">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Hultberg</foaf:surname>
                        <foaf:givenname>Theo</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Rubydoop</dc:title>
        <dcterms:abstract>rubydoop - Write Hadoop jobs in JRuby</dcterms:abstract>
        <dc:date>11:03:30</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/iconara/rubydoop</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 11:03:30</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/hanborq/pigml">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Hanborq</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>PigML</dc:title>
        <dcterms:abstract>pigml - An Apache Pig based machine learning pack for bigdata</dcterms:abstract>
        <dc:date>11:09:46</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/hanborq/pigml</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 11:09:46</dcterms:dateSubmitted>
    </bib:Data>
    <rdf:Description rdf:about="http://dl.acm.org/citation.cfm?id=1559865">
        <z:itemType>conferencePaper</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Pavlo</foaf:surname>
                        <foaf:givenname>Andrew</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Paulson</foaf:surname>
                        <foaf:givenname>Erik</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Rasin</foaf:surname>
                        <foaf:givenname>Alexander</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Abadi</foaf:surname>
                        <foaf:givenname>Daniel J.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>DeWitt</foaf:surname>
                        <foaf:givenname>David J.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Madden</foaf:surname>
                        <foaf:givenname>Samuel</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Stonebraker</foaf:surname>
                        <foaf:givenname>Michael</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_367"/>
        <dc:title>A comparison of approaches to large-scale data analysis</dc:title>
        <dc:date>2009</dc:date>
        <dc:title>Proceedings of the 2009 ACM SIGMOD International Conference on Management of data</dc:title>
        <bib:pages>165–178</bib:pages>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://dl.acm.org/citation.cfm?id=1559865</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 12:56:34</dcterms:dateSubmitted>
        <z:libraryCatalog>Google Scholar</z:libraryCatalog>
    </rdf:Description>
    <z:Attachment rdf:about="#item_367">
        <z:itemType>attachment</z:itemType>
        <dc:title>Pavlo_et_al_2009_A_comparison_of_approaches_to_large-scale_data_analysis.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Data rdf:about="https://github.com/hanborq/rockstor">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Hanborq</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>RockStor</dc:title>
        <dcterms:abstract>rockstor - An Object Storage System implementation based on Hadoop and HBase, with similar features like S3 (Amazon Simple Storage Service).</dcterms:abstract>
        <dc:date>11:10:01</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/hanborq/rockstor</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 11:10:01</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/nathanmarz/elephantdb">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Marz</foaf:surname>
                        <foaf:givenname>Nathan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>ElephantDB</dc:title>
        <dcterms:abstract>elephantdb - Distributed database specialized in exporting key/value data from Hadoop</dcterms:abstract>
        <dc:date>11:18:06</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/nathanmarz/elephantdb</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 11:18:06</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/mortardata/mortar">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Mortar Data</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>Pig</dc:subject>
        <dc:title>Mortar Development Framework</dc:title>
        <dcterms:abstract>mortar - Mortar Development Framework</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/mortardata/mortar</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 18:24:38</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Document rdf:about="http://strata.oreilly.com/2013/07/near-realtime-streaming-and-perpetual-analytics.html?imm_mid=0adcff&amp;cmp=em-strata-na-na-newsltr_20130807_elist">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lorica</foaf:surname>
                        <foaf:givenname>Ben</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>
           <z:AutomaticTag><rdf:value>accumulo</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Hadoop ecosystem</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>HBase</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>perpetual analytics</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>real time</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>real time analytics</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>realtime</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>real-time big data</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>realtime data</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>streaming data</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>streams</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:title>Near realtime, streaming, and perpetual analytics</dc:title>
        <dcterms:abstract>Simple example of a near realtime app built with Hadoop and HBase Over the past year Hadoop emerged from its batch processing roots and began to take on interactive...</dcterms:abstract>
        <dc:date>11:18:50</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://strata.oreilly.com/2013/07/near-realtime-streaming-and-perpetual-analytics.html?imm_mid=0adcff&amp;cmp=em-strata-na-na-newsltr_20130807_elist</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 11:18:50</dcterms:dateSubmitted>
    </bib:Document>
    <bib:Document rdf:about="http://hortonworks.com/blog/pig-eye-for-the-sql-guy/">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog><dc:title>Hortonworks</dc:title></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Miller</foaf:surname>
                        <foaf:givenname>Cat</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Pig Eye for the SQL Guy</dc:title>
        <dc:date>11:20:58</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://hortonworks.com/blog/pig-eye-for-the-sql-guy/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 11:20:58</dcterms:dateSubmitted>
    </bib:Document>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/cloudera/hbasecon-2013-evolving-a-firstgeneration-apache-hbase-deployment-to-second-generation-and-beyond">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Khanwalkar</foaf:surname>
                        <foaf:givenname>Manoj</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Asawa</foaf:surname>
                        <foaf:givenname>Govind</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <link:link rdf:resource="#item_451"/>
        <dc:title>Evolving a First-Generation Apache HBase Deployment...</dc:title>
        <dcterms:abstract>Explorys has been using HBase and Hadoop since HBase 0.20, and will walk through lessons learned over years of usage from their first HBase implementation through a series of upgrades and changes, including impacts to schema design, data loading, data indexing, data access and analytics, and operational processes.</dcterms:abstract>
        <z:type>Technology</z:type>
        <dc:date>Fri Aug 02  2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/cloudera/hbasecon-2013-evolving-a-firstgeneration-apache-hbase-deployment-to-second-generation-and-beyond</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 11:25:09</dcterms:dateSubmitted>
        <z:shortTitle>HBaseCon 2013</z:shortTitle>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <z:Attachment rdf:about="#item_451">
        <z:itemType>attachment</z:itemType>
        <dc:title>Khanwalkar_Asawa_2013_Evolving_a_First-Generation_Apache_HBase_Deployment.pptx</dc:title>
        <link:type>application/vnd.openxmlformats-officedocument.presentationml.presentation</link:type>
    </z:Attachment>
    <bib:Data rdf:about="https://github.com/mozilla/socorro">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Mozilla Foundation</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Socorro</dc:title>
        <dcterms:abstract>socorro - Socorro is a server to accept and process Breakpad crash reports.</dcterms:abstract>
        <dc:date>12:12:13</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/mozilla/socorro</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 12:12:13</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/sonalgoyal/hiho">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Goyal</foaf:surname>
                        <foaf:givenname>Sonal</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>HIHO</dc:title>
        <dcterms:abstract>hiho - Hadoop Data Integration with various databases, ftp servers, salesforce. Incremental update, dedup, append, merge your data on Hadoop.</dcterms:abstract>
        <dc:date>12:12:45</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/sonalgoyal/hiho</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 12:12:45</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/spotify/snakebite">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Spotify</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Snakebite</dc:title>
        <dcterms:abstract>snakebite - A pure python HDFS client</dcterms:abstract>
        <dc:date>12:13:47</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/spotify/snakebite</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 12:13:47</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/spring-projects/spring-hadoop">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>SpringSource</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Spring for Apache Hadoop</dc:title>
        <dcterms:abstract>spring-hadoop - Spring for Apache Hadoop is a framework for application developers to take advantage of the features of both Hadoop and Spring.</dcterms:abstract>
        <dc:date>12:14:26</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://github.com/spring-projects/spring-hadoop</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 12:14:26</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="http://orange.biolab.si/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>University of Ljubljana</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Orange</dc:title>
        <dcterms:abstract>Data Mining Fruitful &amp; Fun</dcterms:abstract>
        <dc:date>12:24:23</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://orange.biolab.si/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 12:24:23</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Document rdf:about="https://github.com/vhf/free-programming-books">
        <z:itemType>webpage</z:itemType>
        <dcterms:isPartOf>
           <z:Website><dc:title>GitHub</dc:title></z:Website>
        </dcterms:isPartOf>
        <dc:title>free-programming-books</dc:title>
        <dcterms:abstract>Contribute to free-programming-books development by creating an account on GitHub.</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://github.com/vhf/free-programming-books</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 12:59:48</dcterms:dateSubmitted>
    </bib:Document>
    <bib:Data rdf:about="http://rapid-i.com/content/view/181/190/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Rapid-I</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>RapidMiner</dc:title>
        <dc:date>12:24:57</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://rapid-i.com/content/view/181/190/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 12:24:57</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="http://www.cs.waikato.ac.nz/%7Eml/weka/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>University of Waikato</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Weka 3</dc:title>
        <dcterms:abstract>Data Mining with Open Source Machine Learning Software in Java</dcterms:abstract>
        <dc:date>12:25:07</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://www.cs.waikato.ac.nz/%7Eml/weka/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 12:25:07</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="http://www.knime.org/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>KNIME.com AG</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>KNIME</dc:title>
        <dcterms:abstract>Konstanz Information Miner</dcterms:abstract>
        <dc:date>12:25:36</dc:date>
        <dc:identifier>
           <dcterms:URI><rdf:value>http://www.knime.org/</rdf:value></dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 12:25:36</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Document rdf:about="http://www.visual-literacy.org/periodic_table/periodic_table.html">
        <z:itemType>webpage</z:itemType>
        <dcterms:isPartOf>
           <z:Website></z:Website>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lengler</foaf:surname>
                        <foaf:givenname>Ralph</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Eppler</foaf:surname>
                        <foaf:givenname>Martin</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_383"/>
        <dc:title>A Periodic Table of Visualization Methods</dc:title>
        <dc:date>12:27:19</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.visual-literacy.org/periodic_table/periodic_table.html</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 12:27:19</dcterms:dateSubmitted>
    </bib:Document>
    <z:Attachment rdf:about="#item_383">
        <z:itemType>attachment</z:itemType>
        <dc:title>A Periodic Table of Visualization Methods</dc:title>
        <dcterms:dateSubmitted>2013-09-26 12:27:20</dcterms:dateSubmitted>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.visual-literacy.org/periodic_table/periodic_table.html</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <link:type>text/html</link:type>
    </z:Attachment>
    <bib:Document rdf:about="http://zenfractal.com/2013/08/21/a-powerful-big-data-trio/">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Massie</foaf:surname>
                        <foaf:givenname>Matt</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>A powerful Big Data trio: Spark, Parquet and Avro</dc:title>
        <dc:date>12:27:50</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://zenfractal.com/2013/08/21/a-powerful-big-data-trio/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 12:27:50</dcterms:dateSubmitted>
    </bib:Document>
    <bib:Data rdf:about="http://sourceforge.net/projects/hadoopdb/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Abouzeid</foaf:surname>
                        <foaf:givenname>Azza</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Bajda-Pawlikowski</foaf:surname>
                        <foaf:givenname>Kamil</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Abadi</foaf:surname>
                        <foaf:givenname>Daniel J.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Silberschatz</foaf:surname>
                        <foaf:givenname>Avi</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Community</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>database</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Development</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>distributed computing</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Downloads</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Free Software</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Open Source</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Open source software</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Secure</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Source Code</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:title>HadoopDB</dc:title>
        <dcterms:abstract>HadoopDB is a hybrid of parallel database and MapReduce technologies. It approaches parallel databases in performance and efficiency, yet still yields the ...</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://sourceforge.net/projects/hadoopdb/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 13:03:08</dcterms:dateSubmitted>
    </bib:Data>
    <bib:ConferenceProceedings rdf:about="http://strataconf.com/strata2013/public/schedule/detail/27438">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Xin</foaf:surname>
                        <foaf:givenname>Reynold</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <dc:title>An Introduction to the Berkeley Data Analytics Stack (BDAS) Featuring Spark, Spark Streaming, and Shark</dc:title>
        <dc:date>23:11:02</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://strataconf.com/strata2013/public/schedule/detail/27438</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-22 23:11:02</dcterms:dateSubmitted>
    </bib:ConferenceProceedings>
    <bib:Document rdf:about="http://hadapt.com/blog/2013/10/02/classifying-the-sql-on-hadoop-solutions/">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog><dc:title>Hadapt</dc:title></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Abadi</foaf:surname>
                        <foaf:givenname>Daniel</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Classifying the SQL-on-Hadoop Solutions</dc:title>
        <dcterms:abstract>Given all of the &quot;SQL-on-Hadoop&quot; initiatives, now is a good time to classify them and study the similarities and differences between these approaches.</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://hadapt.com/blog/2013/10/02/classifying-the-sql-on-hadoop-solutions/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 13:07:12</dcterms:dateSubmitted>
        <z:shortTitle>Hadapt</z:shortTitle>
    </bib:Document>
    <bib:Article rdf:about="http://dl.acm.org/citation.cfm?id=1920886">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
                <dc:title>Proceedings of the VLDB Endowment</dc:title>
                <prism:volume>3</prism:volume>
                <prism:number>1-2</prism:number>
            </bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Melnik</foaf:surname>
                        <foaf:givenname>Sergey</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Gubarev</foaf:surname>
                        <foaf:givenname>Andrey</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Long</foaf:surname>
                        <foaf:givenname>Jing Jing</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Romer</foaf:surname>
                        <foaf:givenname>Geoffrey</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Shivakumar</foaf:surname>
                        <foaf:givenname>Shiva</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Tolton</foaf:surname>
                        <foaf:givenname>Matt</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Vassilakis</foaf:surname>
                        <foaf:givenname>Theo</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_352"/>
        <dc:title>Dremel: interactive analysis of web-scale datasets</dc:title>
        <bib:pages>330–339</bib:pages>
        <dc:date>2010</dc:date>
        <z:shortTitle>Dremel</z:shortTitle>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://dl.acm.org/citation.cfm?id=1920886</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-22 23:53:06</dcterms:dateSubmitted>
        <z:libraryCatalog>Google Scholar</z:libraryCatalog>
    </bib:Article>
    <z:Attachment rdf:about="#item_352">
        <z:itemType>attachment</z:itemType>
        <dc:title>Melnik_et_al_2010_Dremel.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="https://www.ndm.net/datawarehouse/pdf/High_Performance_Paradigms.pdf">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Loshin</foaf:surname>
                        <foaf:givenname>David</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_334"/>
        <dc:title>New Paradigms for High Performance Analytical Computing</dc:title>
        <dc:date>2009</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://www.ndm.net/datawarehouse/pdf/High_Performance_Paradigms.pdf</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-22 23:54:22</dcterms:dateSubmitted>
        <z:libraryCatalog>Google Scholar</z:libraryCatalog>
    </bib:Article>
    <z:Attachment rdf:about="#item_334">
        <z:itemType>attachment</z:itemType>
        <dc:title>Loshin_2009_New_Paradigms_for_High_Performance_Analytical_Computing.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <rdf:Description rdf:about="http://dl.acm.org/citation.cfm?id=2213958">
        <z:itemType>conferencePaper</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lin</foaf:surname>
                        <foaf:givenname>Jimmy</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kolcz</foaf:surname>
                        <foaf:givenname>Alek</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_255"/>
        <dc:title>Large-scale machine learning at twitter</dc:title>
        <dc:date>2012</dc:date>
        <bib:pages>793–804</bib:pages>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://dl.acm.org/citation.cfm?id=2213958</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-22 23:54:35</dcterms:dateSubmitted>
        <z:libraryCatalog>Google Scholar</z:libraryCatalog>
    </rdf:Description>
    <z:Attachment rdf:about="#item_255">
        <z:itemType>attachment</z:itemType>
        <dc:title>Lin_Kolcz_2012_Large-scale_machine_learning_at_twitter.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Document rdf:about="http://engineering.linkedin.com/developer-productivity/quick-deploy-distributed-systems-approach-developer-productivity">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Cataldo</foaf:surname>
                        <foaf:givenname>Adam</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Quick Deploy: a distributed systems approach to developer productivity</dc:title>
        <dcterms:abstract>The ideal model for a developer is to deploy locally only the services he is actually modifying.</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://engineering.linkedin.com/developer-productivity/quick-deploy-distributed-systems-approach-developer-productivity</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 13:11:19</dcterms:dateSubmitted>
        <z:shortTitle>Quick Deploy</z:shortTitle>
    </bib:Document>
    <bib:Article rdf:about="http://dl.acm.org/citation.cfm?id=2367518">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
                <dc:title>Proceedings of the VLDB Endowment</dc:title>
                <prism:volume>5</prism:volume>
                <prism:number>12</prism:number>
            </bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lamb</foaf:surname>
                        <foaf:givenname>Andrew</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Fuller</foaf:surname>
                        <foaf:givenname>Matt</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Varadarajan</foaf:surname>
                        <foaf:givenname>Ramakrishna</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Tran</foaf:surname>
                        <foaf:givenname>Nga</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Vandiver</foaf:surname>
                        <foaf:givenname>Ben</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Doshi</foaf:surname>
                        <foaf:givenname>Lyric</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Bear</foaf:surname>
                        <foaf:givenname>Chuck</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_301"/>
        <dc:title>The vertica analytic database: C-store 7 years later</dc:title>
        <bib:pages>1790–1801</bib:pages>
        <dc:date>2012</dc:date>
        <z:shortTitle>The vertica analytic database</z:shortTitle>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://dl.acm.org/citation.cfm?id=2367518</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-22 23:54:53</dcterms:dateSubmitted>
        <z:libraryCatalog>Google Scholar</z:libraryCatalog>
    </bib:Article>
    <z:Attachment rdf:about="#item_301">
        <z:itemType>attachment</z:itemType>
        <dc:title>Lamb_et_al_2012_The_vertica_analytic_database.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://dl.acm.org/citation.cfm?id=1687553.1687568">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
                <dc:title>Proc. VLDB Endow.</dc:title>
                <prism:volume>2</prism:volume>
                <prism:number>2</prism:number>
                <dc:identifier>ISSN 2150-8097</dc:identifier>
            </bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Gates</foaf:surname>
                        <foaf:givenname>Alan F.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Natkovich</foaf:surname>
                        <foaf:givenname>Olga</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Chopra</foaf:surname>
                        <foaf:givenname>Shubham</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kamath</foaf:surname>
                        <foaf:givenname>Pradeep</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Narayanamurthy</foaf:surname>
                        <foaf:givenname>Shravan M.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Olston</foaf:surname>
                        <foaf:givenname>Christopher</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Reed</foaf:surname>
                        <foaf:givenname>Benjamin</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Srinivasan</foaf:surname>
                        <foaf:givenname>Santhosh</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Srivastava</foaf:surname>
                        <foaf:givenname>Utkarsh</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_416"/>
        <dc:title>Building a high-level dataflow system on top of Map-Reduce: the Pig experience</dc:title>
        <dcterms:abstract>Increasingly, organizations capture, transform and analyze enormous data sets. Prominent examples include internet companies and e-science. The Map-Reduce scalable dataflow paradigm has become popular for these applications. Its simple, explicit dataflow programming model is favored by some over the traditional high-level declarative approach: SQL. On the other hand, the extreme simplicity of Map-Reduce leads to much low-level hacking to deal with the many-step, branching dataflows that arise in practice. Moreover, users must repeatedly code standard operations such as join by hand. These practices waste time, introduce bugs, harm readability, and impede optimizations. Pig is a high-level dataflow system that aims at a sweet spot between SQL and Map-Reduce. Pig offers SQL-style high-level data manipulation constructs, which can be assembled in an explicit dataflow and interleaved with custom Map- and Reduce-style functions or executables. Pig programs are compiled into sequences of Map-Reduce jobs, and executed in the Hadoop Map-Reduce environment. Both Pig and Hadoop are open-source projects administered by the Apache Software Foundation. This paper describes the challenges we faced in developing Pig, and reports performance comparisons between Pig execution and raw Map-Reduce execution.</dcterms:abstract>
        <bib:pages>1414–1425</bib:pages>
        <dc:date>August 2009</dc:date>
        <z:shortTitle>Building a high-level dataflow system on top of Map-Reduce</z:shortTitle>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://dl.acm.org/citation.cfm?id=1687553.1687568</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 13:13:37</dcterms:dateSubmitted>
        <z:libraryCatalog>ACM Digital Library</z:libraryCatalog>
    </bib:Article>
    <z:Attachment rdf:about="#item_416">
        <z:itemType>attachment</z:itemType>
        <dc:title>Gates_et_al_2009_Building_a_high-level_dataflow_system_on_top_of_Map-Reduce.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <rdf:Description rdf:about="https://www.usenix.org/system/files/login/articles/zaharia.pdf">
        <z:itemType>conferencePaper</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Zaharia</foaf:surname>
                        <foaf:givenname>MATEI</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Chowdhury</foaf:surname>
                        <foaf:givenname>MOSHARAF</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Das</foaf:surname>
                        <foaf:givenname>TATHAGATA</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Dave</foaf:surname>
                        <foaf:givenname>ANKUR</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ma</foaf:surname>
                        <foaf:givenname>JUSTIN</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>McCauley</foaf:surname>
                        <foaf:givenname>MURPHY</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Franklin</foaf:surname>
                        <foaf:givenname>M.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Shenker</foaf:surname>
                        <foaf:givenname>SCOTT</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Stoica</foaf:surname>
                        <foaf:givenname>I.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_405"/>
        <dc:title>Fast and interactive analytics over Hadoop data with Spark</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://www.usenix.org/system/files/login/articles/zaharia.pdf</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 06:04:30</dcterms:dateSubmitted>
        <z:libraryCatalog>Google Scholar</z:libraryCatalog>
    </rdf:Description>
    <z:Attachment rdf:about="#item_405">
        <z:itemType>attachment</z:itemType>
        <dc:title>Zaharia_et_al_Fast_and_interactive_analytics_over_Hadoop_data_with_Spark.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:ConferenceProceedings rdf:about="http://strataconf.com/strata2013/public/schedule/detail/27475">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Shekhar</foaf:surname>
                        <foaf:givenname>Jayant</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <bib:contributors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Cloudera</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:contributors>
        <dc:title>Building Recommendation Platforms with Hadoop</dc:title>
        <dcterms:abstract>This talks dives into the extreme details of Building Recommendation Platforms. It covers the end to end Architecture and Design of such a system. It dives into the various ML Algorithms to be used along with their details. It also covers the Solutions to commonly seen Recommendation Patterns and detailed Use Cases along with their Solution.</dcterms:abstract>
        <dc:date>00:08:52</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://strataconf.com/strata2013/public/schedule/detail/27475</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-23 00:08:52</dcterms:dateSubmitted>
        <z:shortTitle>Building Recommendation Platforms with Hadoop</z:shortTitle>
    </bib:ConferenceProceedings>
    <bib:ConferenceProceedings rdf:about="http://strataconf.com/strata2013/public/schedule/detail/27419">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>William</foaf:surname>
                        <foaf:givenname>Sam</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <bib:contributors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>StumbleUpon</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:contributors>
        <link:link rdf:resource="#item_1268"/>
        <dc:title>Building Scalable Big Data Infrastructure Using Open Source Software</dc:title>
        <dcterms:abstract>The Infrastructure team at Stumbleupon leverages the state of the art tools and technologies to build platforms that enable us collect, categorize, organize, store and analyze huge volumes of data. The platform is fast and robust that it adds minimal latency to the site.Timely collection and analysis of data helps data scientists, analysts and executives make the best decisions and validate them.</dcterms:abstract>
        <dc:date>00:09:43</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://strataconf.com/strata2013/public/schedule/detail/27419</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-23 00:09:43</dcterms:dateSubmitted>
        <z:shortTitle>Building Scalable Big Data Infrastructure Using Open Source Software</z:shortTitle>
    </bib:ConferenceProceedings>
    <z:Attachment rdf:about="#item_1268">
        <z:itemType>attachment</z:itemType>
        <dc:title>William_2013_Building_Scalable_Big_Data_Infrastructure_Using_Open_Source_Software.ppt</dc:title>
        <link:type>application/msword</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://dl.acm.org/citation.cfm?id=2367533">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
                <dc:title>Proceedings of the VLDB Endowment</dc:title>
                <prism:volume>5</prism:volume>
                <prism:number>12</prism:number>
            </bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Agarwal</foaf:surname>
                        <foaf:givenname>Sameer</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Iyer</foaf:surname>
                        <foaf:givenname>Anand P.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Panda</foaf:surname>
                        <foaf:givenname>Aurojit</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Madden</foaf:surname>
                        <foaf:givenname>Samuel</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Mozafari</foaf:surname>
                        <foaf:givenname>Barzan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Stoica</foaf:surname>
                        <foaf:givenname>Ion</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_403"/>
        <dc:title>Blink and it's done: interactive queries on very large data</dc:title>
        <bib:pages>1902–1905</bib:pages>
        <dc:date>2012</dc:date>
        <z:shortTitle>Blink and it's done</z:shortTitle>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://dl.acm.org/citation.cfm?id=2367533</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 06:04:30</dcterms:dateSubmitted>
        <z:libraryCatalog>Google Scholar</z:libraryCatalog>
    </bib:Article>
    <z:Attachment rdf:about="#item_403">
        <z:itemType>attachment</z:itemType>
        <dc:title>Agarwal_et_al_2012_Blink_and_it's_done.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Data rdf:about="https://github.com/mortardata/watchtower">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Mortar Data</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>Pig</dc:subject>
        <dc:title>Mortar Watchtower</dc:title>
        <dcterms:abstract>watchtower - Who said scientific progress couldn't go boink?</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/mortardata/watchtower</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 18:26:56</dcterms:dateSubmitted>
    </bib:Data>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/xefyr/h-base-for-architectspptx">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Nick Dimiduk</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <link:link rdf:resource="#item_411"/>
        <dc:title>HBase for Architects</dc:title>
        <dcterms:abstract>HBase can be an intimidating beast for someone considering its adoption. For what kinds of workloads is it well suited? How does it integrate into the rest of my application infrastructure? What are the data semantics upon which applications can be built? What are the deployment and operational concerns? In this talk, I'll address each of these questions in turn. As supporting evidence, both high-level application architecture and internal details will be discussed. This is an interactive talk: bring your questions and your use-cases!</dcterms:abstract>
        <z:type>Business &amp; Mgmt</z:type>
        <dc:date>Tue May 28  2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/xefyr/h-base-for-architectspptx</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 06:41:15</dcterms:dateSubmitted>
    </bib:ConferenceProceedings>
    <z:Attachment rdf:about="#item_411">
        <z:itemType>attachment</z:itemType>
        <dc:title>Nick_Dimiduk_2013_HBase_for_Architects.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:ConferenceProceedings rdf:about="http://strataconf.com/strata2013/public/schedule/detail/27485">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ogievetsky</foaf:surname>
                        <foaf:givenname>Vadim</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <bib:contributors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Metamarkets</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:contributors>
        <dc:title>Facet: The Recursive Approach to Visualization</dc:title>
        <dcterms:abstract>Visualization is a powerful way to understand data, but today building the right data set and accompanying data visualization requires sophisticated programming skills. We discuss an approach to a unified language describing both visualization and database queries. This approach could be used by both programmers and business users, accelerating data exploration and speeding time to insight.</dcterms:abstract>
        <dc:date>00:11:54</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://strataconf.com/strata2013/public/schedule/detail/27485</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-23 00:11:54</dcterms:dateSubmitted>
        <z:shortTitle>Facet</z:shortTitle>
    </bib:ConferenceProceedings>
    <bib:ConferenceProceedings rdf:about="http://strataconf.com/strata2013/public/schedule/detail/26899">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Wampler</foaf:surname>
                        <foaf:givenname>Dean</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <dc:subject>Hive</dc:subject>
        <dc:title>Hadoop Data Warehousing with Hive</dc:title>
        <dcterms:abstract>This hands-on tutorial teaches you how to use Hive, a high-level, data warehouse tool for Hadoop. Hive provides a SQL-like query language, HiveQL, that is easy to learn for people with prior SQL experience, making Hive attractive for data warehousing teams. Hive leverages the power of Hadoop for working with massive data sets without requiring expertise in MapReduce programming.</dcterms:abstract>
        <dc:date>00:12:36</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://strataconf.com/strata2013/public/schedule/detail/26899</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-23 00:12:36</dcterms:dateSubmitted>
        <z:shortTitle>Hadoop Data Warehousing with Hive</z:shortTitle>
    </bib:ConferenceProceedings>
    <bib:ConferenceProceedings rdf:about="http://strataconf.com/strata2013/public/schedule/detail/27610">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Marz</foaf:surname>
                        <foaf:givenname>Nathan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <bib:contributors>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Twitter</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:contributors>
        <dc:title>Human Fault-tolerance</dc:title>
        <dcterms:abstract>Designing for human fault-tolerance leads to important conclusions on the fundamental ways data systems should be architected.</dcterms:abstract>
        <dc:date>00:12:41</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://strataconf.com/strata2013/public/schedule/detail/27610</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-23 00:12:41</dcterms:dateSubmitted>
        <z:shortTitle>Human Fault-tolerance</z:shortTitle>
    </bib:ConferenceProceedings>
    <bib:Document rdf:about="http://www.kiji.org/2013/10/08/fixing-classpath-ordering-issues-in-hadoop/">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Sheng</foaf:surname>
                        <foaf:givenname>Lee</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Fixing classpath ordering issues in Hadoop</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.kiji.org/2013/10/08/fixing-classpath-ordering-issues-in-hadoop/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 18:32:31</dcterms:dateSubmitted>
    </bib:Document>
    <bib:Report rdf:about="http://hortonworks.com/blog/apache-hadoop-patterns-of-use-refine-enrich-and-explore/">
        <z:itemType>report</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Hortonworks</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Apache Hadoop Patterns of Use: Refine, Enrich and Explore</dc:title>
        <dcterms:abstract>Download a whitepaper from Hortonworks that covers 3 key patterns of Apache Hadoop use: Refine, Enrich and Explore.</dcterms:abstract>
        <dc:date>00:15:55</dc:date>
        <z:shortTitle>Apache Hadoop Patterns of Use</z:shortTitle>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://hortonworks.com/blog/apache-hadoop-patterns-of-use-refine-enrich-and-explore/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-23 00:15:55</dcterms:dateSubmitted>
    </bib:Report>
    <bib:ConferenceProceedings rdf:about="http://strataconf.com/strata2013/public/schedule/detail/27991">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Erickson</foaf:surname>
                        <foaf:givenname>Justin</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <bib:contributors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Cloudera</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:contributors>
        <link:link rdf:resource="#item_418"/>
        <dc:subject>hbase</dc:subject>
        <dc:subject>Hive</dc:subject>
        <dc:title>Impala: A Modern SQL Engine for Hadoop</dc:title>
        <dcterms:abstract>The Cloudera Impala project is for the first time making scalable parallel database technology, which is the underpinning of Google's Dremel as well as that of commercial analytic DBMSs, available to the Hadoop community.</dcterms:abstract>
        <dc:date>00:17:11</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://strataconf.com/strata2013/public/schedule/detail/27991</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-23 00:17:11</dcterms:dateSubmitted>
        <z:shortTitle>Impala</z:shortTitle>
    </bib:ConferenceProceedings>
    <z:Attachment rdf:about="#item_418">
        <z:itemType>attachment</z:itemType>
        <dc:title>Erickson_0000_Impala.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:ConferenceProceedings rdf:about="http://strataconf.com/strata2013/public/schedule/detail/27311">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Bahmani</foaf:surname>
                        <foaf:givenname>Bahman</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <link:link rdf:resource="#item_171"/>
        <dc:title>Sketching Techniques for Real-time Big Data</dc:title>
        <dcterms:abstract>In many modern web and big data applications the data arrives in a streaming fashion and needs to be processed on the fly. Due to the size of data, the computations need to be done incrementally, and hence sketches of data are used that take a small amount of memory but allow for fast updates and queries. We will present the techniques to design these sketches and provide clarifying examples.</dcterms:abstract>
        <dc:date>00:19:56</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://strataconf.com/strata2013/public/schedule/detail/27311</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-23 00:19:56</dcterms:dateSubmitted>
        <z:shortTitle>Sketching Techniques for Real-time Big Data</z:shortTitle>
    </bib:ConferenceProceedings>
    <z:Attachment rdf:about="#item_171">
        <z:itemType>attachment</z:itemType>
        <dc:title>Bahmani_0000_Sketching_Techniques_for_Real-time_Big_Data.pptx</dc:title>
        <link:type>application/vnd.openxmlformats-officedocument.presentationml.presentation</link:type>
    </z:Attachment>
    <bib:ConferenceProceedings rdf:about="http://strataconf.com/strata2013/public/schedule/detail/27194">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Zeyliger</foaf:surname>
                        <foaf:givenname>Philip</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <bib:contributors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Cloudera</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:contributors>
        <dc:title>Tricks for Distributed System Debugging and Diagnosis</dc:title>
        <dcterms:abstract>All is quiet on the log file front, but yet the system is down. What next? Three parts practical know-how (“here’s my toolbox”) and one part position paper (“must-haves for comprehensibility”), this talk will cover the tricks of the trade for debugging distributed systems. Motivated by experience gained diagnosing Hadoop, we’ll dig into the JVM, Linux esoterica, and outlier visualization.</dcterms:abstract>
        <dc:date>00:22:43</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://strataconf.com/strata2013/public/schedule/detail/27194</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-23 00:22:43</dcterms:dateSubmitted>
        <z:shortTitle>Tricks for Distributed System Debugging and Diagnosis</z:shortTitle>
    </bib:ConferenceProceedings>
    <bib:ConferenceProceedings rdf:about="http://strataconf.com/strata2013/public/schedule/detail/28638">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Peterson</foaf:surname>
                        <foaf:givenname>Mike</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <bib:contributors>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Neustar</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:contributors>
        <link:link rdf:resource="#item_1287"/>
        <dc:title>Using Hadoop to Expand Data Warehousing</dc:title>
        <dcterms:abstract>Learn how Neustar has expanded their data warehouse capacity, agility for data analysis, reduced costs, and enabled new data products. Discuss challenges and opportunities in capturing 100′s of TB’s of compact binary network data, ad hoc analysis, integration with a scale out relational database, more agile data development, and building new products integrating multiple big data sets.</dcterms:abstract>
        <dc:date>00:22:47</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://strataconf.com/strata2013/public/schedule/detail/28638</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-23 00:22:47</dcterms:dateSubmitted>
        <z:shortTitle>Using Hadoop to Expand Data Warehousing</z:shortTitle>
    </bib:ConferenceProceedings>
    <z:Attachment rdf:about="#item_1287">
        <z:itemType>attachment</z:itemType>
        <dc:title>Peterson_2013_Using_Hadoop_to_Expand_Data_Warehousing.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:ConferenceProceedings rdf:about="http://strataconf.com/strata2013/public/schedule/detail/27109">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Hsieh</foaf:surname>
                        <foaf:givenname>Jonathan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Vashishtha</foaf:surname>
                        <foaf:givenname>Himanshu</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <bib:contributors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Cloudera</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:contributors>
        <dc:subject>hbase</dc:subject>
        <dc:title>Using HBase effectively - What You Need to Know as an Application Developer</dc:title>
        <dcterms:abstract>HBase is one of the more popular open source NoSQL databases that have cropped up over the last few years. Building applications that use HBase effectively is challenging. This tutorial is geared towards teaching the basics of building applications using HBase and covers concepts that a developer should know while using HBase as a backend store for their application.</dcterms:abstract>
        <dc:date>00:22:50</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://strataconf.com/strata2013/public/schedule/detail/27109</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-23 00:22:50</dcterms:dateSubmitted>
        <z:shortTitle>Using HBase effectively - What You Need to Know as an Application Developer</z:shortTitle>
    </bib:ConferenceProceedings>
    <bib:Report rdf:about="http://hortonworks.com/blog/the-business-value-of-hadoop-as-seen-through-the-big-data/">
        <z:itemType>report</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Hortonworks</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>The Business Value of Hadoop as seen through the Big Data</dc:title>
        <dcterms:abstract>What is the value of Hadoop and Big Data? Find out in this whitepaper covering types of data from clickstream, to sentiment, to sensor logs.</dcterms:abstract>
        <dc:date>00:25:06</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://hortonworks.com/blog/the-business-value-of-hadoop-as-seen-through-the-big-data/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-23 00:25:06</dcterms:dateSubmitted>
    </bib:Report>
    <bib:Document rdf:about="http://engineering.linkedin.com/52/autometrics-self-service-metrics-collection">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Johnson</foaf:surname>
                        <foaf:givenname>Grier</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Autometrics: Self-service metrics collection</dc:title>
        <dcterms:abstract>We're seeking intelligent problem solvers who are inspired and motivated to change the world.</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://engineering.linkedin.com/52/autometrics-self-service-metrics-collection</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 13:16:02</dcterms:dateSubmitted>
        <z:shortTitle>Autometrics</z:shortTitle>
    </bib:Document>
    <bib:ConferenceProceedings rdf:about="http://strataconf.com/strata2013/public/schedule/detail/27993">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Croll</foaf:surname>
                        <foaf:givenname>Alistair</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <link:link rdf:resource="#item_353"/>
        <dc:title>The Business Singularity: Why Software Means Cycle Time Trumps Scale</dc:title>
        <dcterms:abstract>For centuries, business has been about scale. Business students are taught that cconomies of scale are the only long-term sustainable advantage, because with scale you can control markets, set prices, own channels, influence regulators, and so on. But thanks to software and big data, however, scale’s importance is waning.</dcterms:abstract>
        <dc:date>00:25:54</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://strataconf.com/strata2013/public/schedule/detail/27993</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-23 00:25:54</dcterms:dateSubmitted>
        <z:shortTitle>The Business Singularity</z:shortTitle>
    </bib:ConferenceProceedings>
    <z:Attachment rdf:about="#item_353">
        <z:itemType>attachment</z:itemType>
        <dc:title>Croll_0000_The_Business_Singularity.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Book rdf:about="urn:isbn:9781617290527">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Shelter Island, NY</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Manning</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Dimiduk</foaf:surname>
                        <foaf:givenname>Nick</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <bib:contributors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Khurana</foaf:surname>
                        <foaf:givenname>Amandeep</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ryan</foaf:surname>
                        <foaf:givenname>Mark Henry</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:contributors>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computers / Databases / General</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Database management</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Distributed databases</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Distributed processing</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Electronic data processing</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Open source software</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:title>HBase in action</dc:title>
        <dc:date>2013</dc:date>
        <z:numPages>334</z:numPages>
        <dc:identifier>ISBN 9781617290527</dc:identifier>
        <z:libraryCatalog>Library of Congress ISBN</z:libraryCatalog>
        <dc:subject>
           <dcterms:LCC><rdf:value>QA76.9.D5 D434 2013</rdf:value></dcterms:LCC>
        </dc:subject>
    </bib:Book>
    <bib:Article rdf:about="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.182.5667&amp;rep=rep1&amp;type=pdf">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
                <dc:title>Journal of Statistical Software</dc:title>
                <prism:volume>40</prism:volume>
                <prism:number>1</prism:number>
            </bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Wickham</foaf:surname>
                        <foaf:givenname>Hadley</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_381"/>
        <dc:title>The split-apply-combine strategy for data analysis</dc:title>
        <bib:pages>1–29</bib:pages>
        <dc:date>2011</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.182.5667&amp;rep=rep1&amp;type=pdf</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-23 00:45:31</dcterms:dateSubmitted>
        <z:libraryCatalog>Google Scholar</z:libraryCatalog>
    </bib:Article>
    <z:Attachment rdf:about="#item_381">
        <z:itemType>attachment</z:itemType>
        <dc:title>Wickham_2011_The_split-apply-combine_strategy_for_data_analysis.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Report rdf:about="http://www.idgconnect.com/view_abstract/14386/visual-discovery-tools-market-segmentation-product-positioning">
        <z:itemType>report</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Eckerson</foaf:surname>
                        <foaf:givenname>Wayne</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Visual Discovery Tools: Market Segmentation and Product Positioning</dc:title>
        <dcterms:abstract>This white paper provides an overview of Visual Discovery Tools, looking at their use and market trends in user organizations and the vendor marketplace.</dcterms:abstract>
        <dc:date>00:50:08</dc:date>
        <z:shortTitle>IDG Connect – Visual Discovery Tools</z:shortTitle>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.idgconnect.com/view_abstract/14386/visual-discovery-tools-market-segmentation-product-positioning</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-23 00:50:08</dcterms:dateSubmitted>
    </bib:Report>
    <bib:Document rdf:about="http://blogs.hbr.org/2012/12/what-a-big-data-business-model/">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog><dc:title>Harvard Business Review</dc:title></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Wang</foaf:surname>
                        <foaf:givenname>R. “Ray”</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                   <foaf:Person><foaf:surname>2012</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>
           <z:AutomaticTag><rdf:value>accounting</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>business management articles resources</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
                <rdf:value>business resources books articles case studies</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>communication</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>entrepreneurship</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>execution</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>finance</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Harvard Business School Publishing</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>HBO</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>HBP</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>HBR</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>HBSP</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>innovation</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>international global business strategy</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>leadership</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>managing people</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>operations</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>organizational development</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>technology</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:title>What a Big-Data Business Model Looks Like</dc:title>
        <dcterms:abstract>There are three main ways to profit from the data revolution.</dcterms:abstract>
        <dc:date>22:24:37</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://blogs.hbr.org/2012/12/what-a-big-data-business-model/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 22:24:37</dcterms:dateSubmitted>
    </bib:Document>
    <bib:Data rdf:about="https://github.com/alexholmes/htuple">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Holmes</foaf:surname>
                        <foaf:givenname>Alex</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>htuple</dc:title>
        <dcterms:abstract>htuple - A library to simplify compound field partitioning, sorting and grouping in MapReduce.</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/alexholmes/htuple</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 18:35:34</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="http://continuuity.com/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Continuuity</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Continuuity Reactor</dc:title>
        <dc:date>12:30:48</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://continuuity.com/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 12:30:48</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Document rdf:about="http://developer.yahoo.com/blogs/hadoop/pig-hive-yahoo-464.html">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog><dc:title>Yahoo</dc:title></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Gates</foaf:surname>
                        <foaf:givenname>Alan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>Hive</dc:subject>
        <dc:subject>Pig</dc:subject>
        <dc:title>Pig and Hive at Yahoo!</dc:title>
        <dcterms:abstract>Yahoo! has begun evaluating Hive for use as part of its Hadoop stack. Since, in many peoples' minds, Hive and Pig are roughly equivalent and Pig Latin is very close to SQL, this has led to some confusion. Why are … Continue reading →</dcterms:abstract>
        <dc:date>20:11:58</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://developer.yahoo.com/blogs/hadoop/pig-hive-yahoo-464.html</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-23 20:11:58</dcterms:dateSubmitted>
    </bib:Document>
    <bib:Document rdf:about="http://www.datastax.com/dev/blog/tools-for-testing-cassandra">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog><dc:title>DataStax</dc:title></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Mcguire</foaf:surname>
                        <foaf:givenname>Ryan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Tools for Testing Cassandra</dc:title>
        <dcterms:abstract>A showcase of several tools that I have found invaluable in my day-to-day testing of Cassandra.</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.datastax.com/dev/blog/tools-for-testing-cassandra</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 18:39:14</dcterms:dateSubmitted>
    </bib:Document>
    <bib:Document rdf:about="http://blog.mortardata.com/post/60765120319/domesticating-pig-with-lipstick">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog><dc:title>Mortar Data Blog</dc:title></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Daniels</foaf:surname>
                        <foaf:givenname>Doug</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>
           <z:AutomaticTag><rdf:value>apache pig</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>lipstick</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>Pig</dc:subject>
        <dc:title>Domesticating Pig with Lipstick</dc:title>
        <dcterms:abstract>Doug Daniels
tl;dr
We’ve integrated Netflix’s awesome Pig visualization tool, Lipstick, into Mortar. Lipstick shows exactly what your pigscript is doing in realtime, and gives you samples of data and...</dcterms:abstract>
        <dc:date>20:20:17</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://blog.mortardata.com/post/60765120319/domesticating-pig-with-lipstick</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-23 20:20:17</dcterms:dateSubmitted>
    </bib:Document>
    <bib:Document rdf:about="http://hortonworks.com/blog/pig-tojson-and-redis-to-publish-data-with-flask/">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog><dc:title>Hortonworks</dc:title></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Journey</foaf:surname>
                        <foaf:givenname>Russell</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>Pig</dc:subject>
        <dc:title>Pig, ToJson, and Redis to publish data with Flask</dc:title>
        <dc:date>20:22:50</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://hortonworks.com/blog/pig-tojson-and-redis-to-publish-data-with-flask/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-23 20:22:50</dcterms:dateSubmitted>
    </bib:Document>
    <bib:Data rdf:about="https://github.com/myui/hivemall">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Makoto Yui</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Hivemall</dc:title>
        <dcterms:abstract>hivemall - Scalable machine learning library for Hive/Hadoop</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/myui/hivemall</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 18:40:56</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Document rdf:about="http://blog.linkedin.com/2010/07/01/linkedin-apache-pig/">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Journey</foaf:surname>
                        <foaf:givenname>Russell</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>Pig</dc:subject>
        <dc:title>LinkedIn, Apache Pig, and Open Source</dc:title>
        <dcterms:abstract>Code Alert! This is a part of our continuing series on Engineering at LinkedIn. If this isn’t your cup of Java, check back tomorrow for regular LinkedIn programming. In the meanwhile, check out some of our latest product features, tips and tricks, or user</dcterms:abstract>
        <dc:date>20:23:28</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://blog.linkedin.com/2010/07/01/linkedin-apache-pig/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-23 20:23:28</dcterms:dateSubmitted>
    </bib:Document>
    <bib:Data rdf:about="https://github.com/infochimps-labs/pigsy">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Infochimps</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>Pig</dc:subject>
        <dc:title>Pigsy</dc:title>
        <dcterms:abstract>pigsy - UDFs and Loaders for Apache Pig -- geodata and more on hadoop</dcterms:abstract>
        <dc:date>20:29:08</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/infochimps-labs/pigsy</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-23 20:29:08</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/AmazonEMR/bootstrap.actions">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Amazon Web Services</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>EMR Bootstrap Actions</dc:title>
        <dcterms:abstract>A Bootstrap Action is a shell script stored in Amazon S3 that Amazon EMR executes on every node of your cluster.</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://github.com/AmazonEMR/bootstrap.actions</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 18:46:42</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Document rdf:about="http://ragrawal.wordpress.com/2013/02/24/on-writing-python-udf-for-pig-a-perspective/">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog><dc:title>Memento</dc:title></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Agrawal</foaf:surname>
                        <foaf:givenname>Ritesh</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>Pig</dc:subject>
        <dc:title>On Writing Python UDF for Pig: A perspective</dc:title>
        <dcterms:abstract>In this post I show three different approaches for writing python UDF for apache pig. One has to think about generality of the UDF when deciding about which approach to take.</dcterms:abstract>
        <dc:date>20:29:41</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://ragrawal.wordpress.com/2013/02/24/on-writing-python-udf-for-pig-a-perspective/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-23 20:29:41</dcterms:dateSubmitted>
        <z:shortTitle>On Writing Python UDF for Pig</z:shortTitle>
    </bib:Document>
    <bib:Data rdf:about="https://github.com/internetarchive/waimea">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Internet Archive</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>Pig</dc:subject>
        <dc:title>Waimea</dc:title>
        <dcterms:abstract>waimea - Full-text indexing pipeline based on Hadoop/Pig scripts.</dcterms:abstract>
        <dc:date>20:32:23</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/internetarchive/waimea</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-23 20:32:23</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/AmazonEMR/sample.apps">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Amazon Web Services</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>EMR Sample Apps</dc:title>
        <dcterms:abstract>sample.apps - Amazon Elastic MapReduce code samples</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/AmazonEMR/sample.apps</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 18:48:45</dcterms:dateSubmitted>
    </bib:Data>
    <bib:ConferenceProceedings rdf:about="https://github.com/andrewclegg/pig-data-mining-talk">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Clegg</foaf:surname>
                        <foaf:givenname>Andrew</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <dc:subject>Pig</dc:subject>
        <dc:title>pig-data-mining-talk</dc:title>
        <dcterms:abstract>pig-data-mining-talk - Notes and resources for my talk at the Hadoop UK Users' Group in June 2012</dcterms:abstract>
        <dc:date>20:33:09</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://github.com/andrewclegg/pig-data-mining-talk</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-23 20:33:09</dcterms:dateSubmitted>
    </bib:ConferenceProceedings>
    <bib:Data rdf:about="https://github.com/airbnb/chronos">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Airbnb</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Chronos</dc:title>
        <dcterms:abstract>chronos - Fault tolerant job scheduler that handles dependencies and iso8601 based schedules.</dcterms:abstract>
        <dc:date>06:48:36</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/airbnb/chronos</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-02 06:48:36</dcterms:dateSubmitted>
    </bib:Data>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/hortonworks/hwxqubolehiveudfguide10">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Hortonworks</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <dc:title>Hive Functions Cheat Sheet</dc:title>
        <dcterms:abstract>This Cheat Sheet helps you use and build Apache Hive User Defined Functions (UDFs) for data analysis.
Brought to you by Hortonworks and Qubole.</dcterms:abstract>
        <z:type>Technology</z:type>
        <dc:date>Mon Sep 16  2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/hortonworks/hwxqubolehiveudfguide10</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 18:50:28</dcterms:dateSubmitted>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <bib:Data rdf:about="http://pig.apache.org/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Apache Software Foundation</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>Pig</dc:subject>
        <dc:title>Apache Pig</dc:title>
        <dc:date>20:37:09</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://pig.apache.org/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-23 20:37:09</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/vertica/Vertica-Hadoop-Connector">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Vertica</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Vertica-Hadoop-Connector</dc:title>
        <dcterms:abstract>Vertica-Hadoop-Connector - Vertica Hadoop Connector</dcterms:abstract>
        <dc:date>20:38:30</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://github.com/vertica/Vertica-Hadoop-Connector</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-23 20:38:30</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Document rdf:about="http://vichargrave.com/securing-hadoop-with-ossec/">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Hargrave</foaf:surname>
                        <foaf:givenname>Vic</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Securing Hadoop with OSSEC</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://vichargrave.com/securing-hadoop-with-ossec/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 18:54:03</dcterms:dateSubmitted>
    </bib:Document>
    <bib:Document rdf:about="http://hortonworks.com/blog/howto-use-hive-to-sqlize-your-own-tweets-part-two-loading-hive-sql-queries/">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog><dc:title>Hortonworks</dc:title></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Journey</foaf:surname>
                        <foaf:givenname>Russell</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>Hive</dc:subject>
        <dc:title>HOWTO use Hive to SQLize your own Tweets - Part Two: Loading Hive, SQL Queries</dc:title>
        <dc:date>20:55:52</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://hortonworks.com/blog/howto-use-hive-to-sqlize-your-own-tweets-part-two-loading-hive-sql-queries/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-23 20:55:52</dcterms:dateSubmitted>
        <z:shortTitle>HOWTO use Hive to SQLize your own Tweets - Part Two</z:shortTitle>
    </bib:Document>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/brendangregg/linux-performance-analysis-and-tools">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Gregg</foaf:surname>
                        <foaf:givenname>Brendan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <link:link rdf:resource="#item_427"/>
        <dc:title>Linux Performance Analysis and Tools</dc:title>
        <dcterms:abstract>Video: http://joyent.com/blog/linux-performance-analysis-and-tools-brendan-gregg-s-talk-at-scale-11x ; This talk for SCaLE11x covers system performance analysis methodologies and the Linux tools to support them, so that you can get the most out of your systems and solve performance issues quickly. This includes a wide variety of tools, including basics like top(1), advanced tools like perf, and new tools like the DTrace for Linux prototypes.</dcterms:abstract>
        <dc:date>Fri Mar 01  2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/brendangregg/linux-performance-analysis-and-tools</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 19:36:58</dcterms:dateSubmitted>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <z:Attachment rdf:about="#item_427">
        <z:itemType>attachment</z:itemType>
        <dc:title>Gregg_2013_Linux_Performance_Analysis_and_Tools.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Document rdf:about="http://hortonworks.com/blog/how-to-perform-spatial-analytics-with-hive-and-hadoop/">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog><dc:title>Hortonworks</dc:title></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Shanklin</foaf:surname>
                        <foaf:givenname>Carter</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>Hive</dc:subject>
        <dc:title>How To Perform Spatial Analytics with Hive and Hadoop</dc:title>
        <dcterms:abstract>Hadoop Tutorial on Spatial Analytics with Hive</dcterms:abstract>
        <dc:date>20:58:31</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://hortonworks.com/blog/how-to-perform-spatial-analytics-with-hive-and-hadoop/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-23 20:58:31</dcterms:dateSubmitted>
    </bib:Document>
    <bib:Letter rdf:about="http://mail-archives.apache.org/mod_mbox/hadoop-hdfs-user/201107.mbox/%3C374D8F3F-B8B1-499F-BEDB-BFEE3219010C@hortonworks.com%3E">
        <z:itemType>email</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Murthy</foaf:surname>
                        <foaf:givenname>Arun</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_7"/>
        <dc:title>Re: About the combiner execution</dc:title>
        <dc:date>20:59:38</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://mail-archives.apache.org/mod_mbox/hadoop-hdfs-user/201107.mbox/%3C374D8F3F-B8B1-499F-BEDB-BFEE3219010C@hortonworks.com%3E</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-23 20:59:38</dcterms:dateSubmitted>
    </bib:Letter>
    <z:Attachment rdf:about="#item_7">
        <z:itemType>attachment</z:itemType>
        <dc:title>Murthy_2013_.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Data rdf:about="https://github.com/hortonworks/gohadoop">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Hortonworks</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>gohadoop</dc:title>
        <dcterms:abstract>Contribute to gohadoop development by creating an account on GitHub.</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/hortonworks/gohadoop</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 18:56:34</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Document rdf:about="http://hortonworks.com/blog/100x-faster-hive/">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog><dc:title>Hortonworks</dc:title></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Gates</foaf:surname>
                        <foaf:givenname>Alan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>Hive</dc:subject>
        <dc:title>How to Make Apache Hive 100X Faster? Apache Hive Stinger</dc:title>
        <dcterms:abstract>Apache Hive is the defacto Hadoop interface. Now Open Source Stinger Initiative vastly improves performance/functionality. Stinger Diagram, Overview</dcterms:abstract>
        <dc:date>21:00:13</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://hortonworks.com/blog/100x-faster-hive/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-23 21:00:13</dcterms:dateSubmitted>
        <z:shortTitle>How to Make Apache Hive 100X Faster?</z:shortTitle>
    </bib:Document>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/adammuise/2013-sept-17thughbasetechnicalintroduction">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Muise</foaf:surname>
                        <foaf:givenname>Adam</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <dc:title>HBase Technical Deep Dive</dc:title>
        <dcterms:abstract>HBase Technical Introduction. This deck includes a description of memory design, write path, read path, some operational tidbits, SQL on HBase (Phoenix and Hive), as well as HOYA (HBase on YARN).</dcterms:abstract>
        <dc:date>Wed Sep 18  2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/adammuise/2013-sept-17thughbasetechnicalintroduction</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 18:58:16</dcterms:dateSubmitted>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/adammuise/2013-jul-23thughivetuningdeepdive">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Muise</foaf:surname>
                        <foaf:givenname>Adam</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <dc:title>Hive Tuning</dc:title>
        <dcterms:abstract>Hive Deep Dive, Hive 0.11 Tuning tips, Hive 0.11 performance optimizations, and Tez</dcterms:abstract>
        <dc:date>Tue Jul 23  2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/adammuise/2013-jul-23thughivetuningdeepdive</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 18:58:28</dcterms:dateSubmitted>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <bib:Data rdf:about="https://github.com/analytically/hadoop-ansible">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Bogaert</foaf:surname>
                        <foaf:givenname>Mathias</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Hadoop Ansible Playbook</dc:title>
        <dcterms:abstract>hadoop-ansible - Ansible Playbook that installs a Hadoop cluster (running on Java 7), with Ganglia, Fluentd, ElasticSearch and Kibana 3 for monitoring and centralized log indexing.</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://github.com/analytically/hadoop-ansible</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 19:03:41</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="http://pangool.net/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Datasalt</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Pangool</dc:title>
        <dcterms:abstract>Hadoop API made easy</dcterms:abstract>
        <dc:date>21:16:14</dc:date>
        <dc:identifier>
           <dcterms:URI><rdf:value>http://pangool.net/</rdf:value></dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-23 21:16:14</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Document rdf:about="http://engineering.linkedin.com/data-streams/apache-samza-linkedins-real-time-stream-processing-framework">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Riccomini</foaf:surname>
                        <foaf:givenname>Chris</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Apache Samza: LinkedIn's Real-time Stream Processing Framework</dc:title>
        <dcterms:abstract>We're seeking intelligent problem solvers who are inspired and motivated to change the world.</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://engineering.linkedin.com/data-streams/apache-samza-linkedins-real-time-stream-processing-framework</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 19:04:59</dcterms:dateSubmitted>
        <z:shortTitle>Apache Samza</z:shortTitle>
    </bib:Document>
    <bib:Document rdf:about="http://www.vertica.com/2013/02/21/presto-distributed-r-for-big-data/">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Roy</foaf:surname>
                        <foaf:givenname>Indrajit</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Distributed R for Big Data</dc:title>
        <dc:date>21:19:59</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.vertica.com/2013/02/21/presto-distributed-r-for-big-data/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-23 21:19:59</dcterms:dateSubmitted>
    </bib:Document>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/DonaldMiner/data-scienceandhadoop">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Miner</foaf:surname>
                        <foaf:givenname>Donald</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <dc:title>Data science and Hadoop</dc:title>
        <dcterms:abstract>A talk I gave on what Hadoop does for the data scientist. I talk about data exploration, NLP, Classifiers, and recommendation systems, plus some other things. I tried to depict a realistic view of Hadoop here.</dcterms:abstract>
        <z:type>Technology</z:type>
        <dc:date>Thu Oct 10  2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/DonaldMiner/data-scienceandhadoop</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 19:08:33</dcterms:dateSubmitted>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <bib:Document rdf:about="http://hbase.apache.org/book/book.html">
        <z:itemType>webpage</z:itemType>
        <dcterms:isPartOf>
           <z:Website></z:Website>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Apache Software Foundation</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>hbase</dc:subject>
        <dc:title>The Apache HBase Reference Guide</dc:title>
        <dc:date>21:20:48</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://hbase.apache.org/book/book.html</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-23 21:20:48</dcterms:dateSubmitted>
    </bib:Document>
    <bib:Recording rdf:about="http://vimeo.com/73211764">
        <z:itemType>videoRecording</z:itemType>
        <z:directors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Miner</foaf:surname>
                        <foaf:givenname>Donald</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:directors>
        <dc:title>Pig vs. MapReduce: When, Why, and How</dc:title>
        <dcterms:abstract>Donald Miner, author of MapReduce Design Patterns and CTO at ClearEdge IT Solutions discusses how he chooses between Pig and MapReduce, considering developer and…</dcterms:abstract>
        <dc:date>2013-08-27</dc:date>
        <z:runningTime>PT01H03M41S</z:runningTime>
        <z:shortTitle>Pig vs. MapReduce</z:shortTitle>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://vimeo.com/73211764</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 19:09:38</dcterms:dateSubmitted>
        <z:libraryCatalog>vimeo.com</z:libraryCatalog>
    </bib:Recording>
    <bib:Document rdf:about="http://labs.ericsson.com/blog/hbase-performance-tuners">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kumar</foaf:surname>
                        <foaf:givenname>Hari</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>hbase</dc:subject>
        <dc:title>HBase: Performance Tuners</dc:title>
        <dc:date>21:21:40</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://labs.ericsson.com/blog/hbase-performance-tuners</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-23 21:21:40</dcterms:dateSubmitted>
    </bib:Document>
    <bib:ConferenceProceedings rdf:about="https://speakerdeck.com/mhausenblas/hug-stockholm-apache-drill">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Hausenblas</foaf:surname>
                        <foaf:givenname>Michael</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <link:link rdf:resource="#item_477"/>
        <dc:title>Apache Drill: Interactive analytics for large-­scale datasets</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://speakerdeck.com/mhausenblas/hug-stockholm-apache-drill</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 19:11:28</dcterms:dateSubmitted>
    </bib:ConferenceProceedings>
    <z:Attachment rdf:about="#item_477">
        <z:itemType>attachment</z:itemType>
        <dc:title>Hausenblas_Apache_Drill.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Book rdf:about="urn:isbn:9781449340254%20%201449340253%20%209781449340223%20%201449340229">
        <z:itemType>book</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Murray</foaf:surname>
                        <foaf:givenname>Scott</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Interactive data visualization for the web</dc:title>
        <dcterms:abstract>Author Scott Murray teaches you the fundamental concepts and methods of D3, a JavaScript library that lets you express data visually in a web browser.</dcterms:abstract>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781449340254  1449340253  9781449340223  1449340229</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://search.ebscohost.com/login.aspx?direct=true&amp;scope=site&amp;db=nlebk&amp;db=nlabk&amp;AN=548862</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-27 10:11:23</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:1782161406">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Birmingham, UK</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Packt Pub.</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Richert</foaf:surname>
                        <foaf:givenname>Willi</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Coelho</foaf:surname>
                        <foaf:givenname>Luis Pedro</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Building machine learning systems with Python</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 1782161406</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://site.ebrary.com/id/10742638</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-27 10:11:25</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Document rdf:about="http://hortonworks.com/blog/hoya-hbase-on-yarn-application-architecture/">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog><dc:title>Hortonworks</dc:title></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Loughran</foaf:surname>
                        <foaf:givenname>Steve</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>hbase</dc:subject>
        <dc:title>Hoya (HBase on YARN) : Application Architecture</dc:title>
        <dcterms:abstract>HOYA - HBase on YARN - Application Architecture for Hadoop 2.0</dcterms:abstract>
        <dc:date>21:23:55</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://hortonworks.com/blog/hoya-hbase-on-yarn-application-architecture/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-23 21:23:55</dcterms:dateSubmitted>
        <z:shortTitle>Hoya (HBase on YARN)</z:shortTitle>
    </bib:Document>
    <bib:Document rdf:about="http://blog.empathybox.com/post/19574936361/getting-real-about-distributed-system-reliability">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog><dc:title>Jay Kreps</dc:title></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kreps</foaf:surname>
                        <foaf:givenname>Jay</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Getting Real About Distributed System Reliability</dc:title>
        <dcterms:abstract>There is a lot of hype around distributed data systems, some of it justified. It’s true that the internet has centralized a lot of computation onto services like Google, Facebook, Twitter, LinkedIn...</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://blog.empathybox.com/post/19574936361/getting-real-about-distributed-system-reliability</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 19:14:22</dcterms:dateSubmitted>
    </bib:Document>
    <bib:Data rdf:about="https://github.com/hortonworks/hoya">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Hortonworks</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>hbase</dc:subject>
        <dc:title>Hoya</dc:title>
        <dcterms:abstract>hoya - hbase for yarn
Hoya is a YARN an application that can deploy HBase cluster on YARN, monitor them and make them larger or smaller as desired.</dcterms:abstract>
        <dc:date>21:24:10</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/hortonworks/hoya</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-23 21:24:10</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Document rdf:about="http://www.chrisstucchio.com/blog/2013/hadoop_hatred.html">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Stucchio</foaf:surname>
                        <foaf:givenname>Chris</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Don't use Hadoop - your data isn't that big</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.chrisstucchio.com/blog/2013/hadoop_hatred.html</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 19:15:34</dcterms:dateSubmitted>
    </bib:Document>
    <bib:Data rdf:about="http://hbase.apache.org/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Apache Software Foundation</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>hbase</dc:subject>
        <dc:title>Apache HBase</dc:title>
        <dc:date>21:25:16</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://hbase.apache.org/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-23 21:25:16</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="http://www.kiji.org/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Kiji Project</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>hbase</dc:subject>
        <dc:title>Kiji</dc:title>
        <dcterms:abstract>Build Real-Time Scalable Data Applications on Apache HBase</dcterms:abstract>
        <dc:date>21:25:56</dc:date>
        <dc:identifier>
           <dcterms:URI><rdf:value>http://www.kiji.org/</rdf:value></dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-23 21:25:56</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Document rdf:about="http://www.poudro.com/blog/building-an-elasticsearch-index-offline-using-hadoop-pig/">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Sinton</foaf:surname>
                        <foaf:givenname>Antoine</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Building an Elasticsearch index offline using Hadoop Pig</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.poudro.com/blog/building-an-elasticsearch-index-offline-using-hadoop-pig/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
    </bib:Document>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/gwenshap/scaling-etl-with-hadoop-shapira-3">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Shapira</foaf:surname>
                        <foaf:givenname>Chen (Gwen)</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <dc:title>Scaling ETL with Hadoop</dc:title>
        <z:type>Technology</z:type>
        <dc:date>Fri Sep 13  2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/gwenshap/scaling-etl-with-hadoop-shapira-3</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 19:23:51</dcterms:dateSubmitted>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/gwenshap/data-wrangling-and-oracle-connectors-for-hadoop">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Shapira</foaf:surname>
                        <foaf:givenname>Chen (Gwen)</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <dc:title>Data Wrangling and Oracle Connectors for Hadoop</dc:title>
        <z:type>Technology</z:type>
        <dc:date>Mon Sep 30  2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/gwenshap/data-wrangling-and-oracle-connectors-for-hadoop</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 19:25:17</dcterms:dateSubmitted>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/billonahill/hadoop-summit-2012-hadoop-and-vertica-the-data-analytics-platform-at-twitter">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Graham</foaf:surname>
                        <foaf:givenname>Bill</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <bib:contributors>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Twitter</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:contributors>
        <link:link rdf:resource="#item_447"/>
        <dc:title>Hadoop and Vertica: The Data Analytics Platform at Twitter</dc:title>
        <z:type>Business &amp; Mgmt</z:type>
        <dc:date>Thu Jun 21  2012</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/billonahill/hadoop-summit-2012-hadoop-and-vertica-the-data-analytics-platform-at-twitter</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-23 21:46:34</dcterms:dateSubmitted>
        <z:shortTitle>Hadoop Summit 2012 - Hadoop and Vertica</z:shortTitle>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <z:Attachment rdf:about="#item_447">
        <z:itemType>attachment</z:itemType>
        <dc:title>Graham_2012_Hadoop_and_Vertica.zip</dc:title>
        <link:type>application/x-zip-compressed</link:type>
    </z:Attachment>
    <bib:Document rdf:about="https://blog.twitter.com/2013/dremel-made-simple-with-parquet">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog><dc:title>Twitter Blogs</dc:title></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Le Dem</foaf:surname>
                        <foaf:givenname>Julien</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Dremel made simple with Parquet</dc:title>
        <dcterms:abstract>Columnar storage is a popular technique to optimize analytical workloads in parallel RDBMs. The performance and compression benefits for storing and processing large amounts of data are well docume......</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://blog.twitter.com/2013/dremel-made-simple-with-parquet</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 19:26:53</dcterms:dateSubmitted>
    </bib:Document>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/cloudera/internals-session-5">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Soztutar</foaf:surname>
                        <foaf:givenname>Enis</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <dc:subject>hbase</dc:subject>
        <dc:title>Apache HBase and HDFS - Understanding Filesystem Usa...</dc:title>
        <dcterms:abstract>Presented by: Enis Soztutar, Hortonworks</dcterms:abstract>
        <z:type>Technology</z:type>
        <dc:date>Tue Jul 09  2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/cloudera/internals-session-5</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-23 21:50:08</dcterms:dateSubmitted>
        <z:shortTitle>HBaseCon 2013</z:shortTitle>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/cloudera/hbasecon-2013-apache-hadoop-and-apache-hbase-for-realtime-video-analytics">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Bhattacharya</foaf:surname>
                        <foaf:givenname>Dibyendu</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <link:link rdf:resource="#item_193"/>
        <dc:subject>hbase</dc:subject>
        <dc:title>Using Coprocessors to Index Columns in an Elasticsea...</dc:title>
        <dcterms:abstract>This presentation explores the design and challenges HappiestMinds faced while implementing a storage and search infrastructure for a large publisher where books/documents/artifacts related records are stored in Apache HBase. Upon bulk insert of book records into HBase, the Elasticsearch index is built offline using MapReduce code but there are certain use cases where the records need to be re-indexed in Elasticsearch using Region Observer Coprocessors.</dcterms:abstract>
        <z:type>Technology</z:type>
        <dc:date>Fri Aug 02  2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/cloudera/hbasecon-2013-apache-hadoop-and-apache-hbase-for-realtime-video-analytics</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-23 21:52:39</dcterms:dateSubmitted>
        <z:shortTitle>HBaseCon 2013</z:shortTitle>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <z:Attachment rdf:about="#item_193">
        <z:itemType>attachment</z:itemType>
        <dc:title>Bhattacharya_2013_Using_Coprocessors_to_Index_Columns_in_an_Elasticsea.pptx</dc:title>
        <link:type>application/vnd.openxmlformats-officedocument.presentationml.presentation</link:type>
    </z:Attachment>
    <bib:Document rdf:about="http://hortonworks.com/blog/orcfile-in-hdp-2-better-compression-better-performance/">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog><dc:title>Hortonworks</dc:title></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Shanklin</foaf:surname>
                        <foaf:givenname>Carter</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>ORCFile in HDP 2: Better Compression, Better Performance</dc:title>
        <dcterms:abstract>The upcoming Hive 0.12 is set to bring some great new advancements in the storage layer in the forms of higher compression and better query performance.</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://hortonworks.com/blog/orcfile-in-hdp-2-better-compression-better-performance/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 19:29:41</dcterms:dateSubmitted>
        <z:shortTitle>ORCFile in HDP 2</z:shortTitle>
    </bib:Document>
    <bib:ConferenceProceedings rdf:about="http://de.slideshare.net/uweseiler/introduction-to-thehadoopecosystemjavaserbiacodecentric">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Seiler</foaf:surname>
                        <foaf:givenname>Uwe</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <dc:title>Introduction to the Hadoop Ecosystem with Hadoop 2.0 aka YARN (Java...</dc:title>
        <dcterms:abstract>Talk held at the Java User Group on 05.09.2013 in Novi Sad, Serbia

Agenda: 
- What is Big Data &amp; Hadoop? 
- Core Hadoop 
- The Hadoop Ecosystem 
- Use Cases 
- What‘s next? Hadoop 2.0!</dcterms:abstract>
        <z:type>Business &amp; Management</z:type>
        <dc:date>Fri Sep 06  2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://de.slideshare.net/uweseiler/introduction-to-thehadoopecosystemjavaserbiacodecentric</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-17 19:31:34</dcterms:dateSubmitted>
        <dc:rights>© Alle Rechte vorbehalten</dc:rights>
    </bib:ConferenceProceedings>
    <bib:Document rdf:about="http://hci.stanford.edu/jheer/files/zoo/">
        <z:itemType>webpage</z:itemType>
        <dcterms:isPartOf>
           <z:Website></z:Website>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Heer</foaf:surname>
                        <foaf:givenname>Jeffrey</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Bostock</foaf:surname>
                        <foaf:givenname>Michael</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ogievetsky</foaf:surname>
                        <foaf:givenname>Vadim</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_44"/>
        <dc:title>A Tour Through the Visualization Zoo</dc:title>
        <dc:date>12:34:43</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://hci.stanford.edu/jheer/files/zoo/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 12:34:43</dcterms:dateSubmitted>
    </bib:Document>
    <z:Attachment rdf:about="#item_44">
        <z:itemType>attachment</z:itemType>
        <dc:title>A Tour Through the Visualizatio - Jeffrey Heer, Michael Bostock.azw3</dc:title>
        <link:type>application/octet-stream</link:type>
    </z:Attachment>
    <bib:Data rdf:about="https://github.com/znmeb/Computational-Journalism-Publishers-Workbench">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Borasky</foaf:surname>
                        <foaf:givenname>Edward</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Computational-Journalism-Publishers-Workbench</dc:title>
        <dcterms:abstract>Computational-Journalism-Publishers-Workbench - An open source workbench for independent computational journalists</dcterms:abstract>
        <dc:date>09:13:48</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://github.com/znmeb/Computational-Journalism-Publishers-Workbench</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-24 09:13:48</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/yhat/pandasql">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Yhat</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>pandasql</dc:title>
        <dcterms:abstract>pandasql - sqldf for pandas</dcterms:abstract>
        <dc:date>09:20:38</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/yhat/pandasql</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-24 09:20:38</dcterms:dateSubmitted>
    </bib:Data>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/ghelmling/helmling-june27-1100amhall1?ref=http://eventifier.co/event/hadoopsummit2013/slides">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Helmling</foaf:surname>
                        <foaf:givenname>Gary</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <link:link rdf:resource="#item_435"/>
        <dc:title>A Bird's-Eye View of Pig and Scalding with hRaven</dc:title>
        <z:type>Business &amp; Mgmt</z:type>
        <dc:date>Fri Jun 28  2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/ghelmling/helmling-june27-1100amhall1?ref=http://eventifier.co/event/hadoopsummit2013/slides</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-24 12:15:27</dcterms:dateSubmitted>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <z:Attachment rdf:about="#item_435">
        <z:itemType>attachment</z:itemType>
        <dc:title>Helmling_2013_A_Bird's-Eye_View_of_Pig_and_Scalding_with_hRaven.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Data rdf:about="https://github.com/sonalgoyal/crux">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Goyal</foaf:surname>
                        <foaf:givenname>Sonal</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Crux</dc:title>
        <dcterms:abstract>crux - Crux is a reporting application for HBase. Crux provides a simple web based graphical interface to access HBase, query data and create reports. Crux is open sourced under Apache Software Foundation License v2.0.</dcterms:abstract>
        <dc:date>00:51:45</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/sonalgoyal/crux</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-29 00:51:45</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://developers.google.com/fusiontables/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Google</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Google Fusion Tables</dc:title>
        <dc:date>12:40:34</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://developers.google.com/fusiontables/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 12:40:34</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/timjurka/RTextTools">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Jurka</foaf:surname>
                        <foaf:givenname>Tim</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>RTextTools</dc:title>
        <dcterms:abstract>RTextTools is a free, open source machine learning package for automatic text classification that makes it simple for both novice and advanced users to get started with supervised learning.</dcterms:abstract>
        <dc:date>12:42:00</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/timjurka/RTextTools</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 12:42:00</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="http://www.alchemyapi.com/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>AlchemyAPI</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>AlchemyAPI</dc:title>
        <dc:date>12:42:42</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://www.alchemyapi.com/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 12:42:42</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="http://aws.amazon.com/redshift/">
        <z:itemType>computerProgram</z:itemType>
        <dc:publisher>
            <foaf:Organization>
               <foaf:name>Amazon Web Services, Inc.</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Amazon Web Services</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Amazon Redshift</dc:title>
        <dc:date>12:44:29</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://aws.amazon.com/redshift/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 12:44:29</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/ContinuumIO/blaze">
        <z:itemType>computerProgram</z:itemType>
        <dc:publisher>
            <foaf:Organization>
               <foaf:name>Continuum Analytics, Inc.</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Continuum Analytics</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Blaze</dc:title>
        <dcterms:abstract>blaze - Blaze is the next generation of NumPy</dcterms:abstract>
        <dc:date>12:48:25</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/ContinuumIO/blaze</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 12:48:25</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/ContinuumIO/Bokeh">
        <z:itemType>computerProgram</z:itemType>
        <dc:publisher>
            <foaf:Organization>
               <foaf:name>Continuum Analytics, Inc.</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Continuum Analytics</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>d3</dc:subject>
        <dc:title>Bokeh</dc:title>
        <dcterms:abstract>Bokeh - Interactive Web Plotting for Python</dcterms:abstract>
        <dc:date>12:48:35</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/ContinuumIO/Bokeh</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 12:48:35</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://store.continuum.io/cshop/anaconda/">
        <z:itemType>computerProgram</z:itemType>
        <dc:publisher>
            <foaf:Organization>
               <foaf:name>Continuum Analytics</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Continuum Analytics</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Anaconda</dc:title>
        <dc:date>12:48:47</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://store.continuum.io/cshop/anaconda/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 12:48:47</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Document rdf:about="http://searchbusinessanalytics.techtarget.com/opinion/Analytical-modeling-is-both-science-and-art">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Eckerson</foaf:surname>
                        <foaf:givenname>Wayne</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Analytical modeling is both science and art</dc:title>
        <dc:date>12:49:54</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://searchbusinessanalytics.techtarget.com/opinion/Analytical-modeling-is-both-science-and-art</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 12:49:54</dcterms:dateSubmitted>
    </bib:Document>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/jdegoes/analytics-maturity-model">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>De Goes</foaf:surname>
                        <foaf:givenname>John</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <link:link rdf:resource="#item_379"/>
        <dc:title>Analytics Maturity Model</dc:title>
        <dcterms:abstract>Every company is at a different stage in leveraging analytics to improve their operational efficiency and product offerings. In this presentation, you will learn an analytics maturity model that companies can use to determine how far they are from the most successful analytical companies.</dcterms:abstract>
        <z:type>Technology</z:type>
        <dc:date>Tue Apr 09  2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/jdegoes/analytics-maturity-model</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 12:50:24</dcterms:dateSubmitted>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <z:Attachment rdf:about="#item_379">
        <z:itemType>attachment</z:itemType>
        <dc:title>De_Goes_2013_Analytics_Maturity_Model.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Document rdf:about="http://www.elisa-dbi.co.uk/blog/38-tools-for-beautiful-data-visualisations/">
        <z:itemType>webpage</z:itemType>
        <dcterms:isPartOf>
           <z:Website></z:Website>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Uruchurtu</foaf:surname>
                        <foaf:givenname>Linda</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_62"/>
        <dc:title>38 Tools For Beautiful Data Visualisations</dc:title>
        <dc:date>12:58:31</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.elisa-dbi.co.uk/blog/38-tools-for-beautiful-data-visualisations/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 12:58:31</dcterms:dateSubmitted>
    </bib:Document>
    <z:Attachment rdf:about="#item_62">
        <z:itemType>attachment</z:itemType>
        <dc:title>38 Tools For Beautiful Data Vis - Linda Uruchurtu.azw3</dc:title>
        <link:type>application/octet-stream</link:type>
    </z:Attachment>
    <bib:Document rdf:about="http://blogs.hbr.org/2013/03/a-data-scientists-real-job-sto/">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Bladt</foaf:surname>
                        <foaf:givenname>Jeff</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Filbin</foaf:surname>
                        <foaf:givenname>Bob</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>storytelling</dc:subject>
        <dc:title>A Data Scientist's Real Job: Storytelling</dc:title>
        <dc:date>13:00:19</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://blogs.hbr.org/2013/03/a-data-scientists-real-job-sto/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 13:00:19</dcterms:dateSubmitted>
    </bib:Document>
    <bib:Data rdf:about="https://gitorious.org/mldemos/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Noris</foaf:surname>
                        <foaf:givenname>Basilio</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>MLDemos</dc:title>
        <dc:date>13:57:09</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://gitorious.org/mldemos/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 13:57:09</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Document rdf:about="http://www.theguardian.com/news/datablog/interactive/2013/jan/14/all-our-datasets-index">
        <z:itemType>webpage</z:itemType>
        <dcterms:isPartOf>
           <z:Website></z:Website>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>theguardian.com</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>All our datasets: the complete index</dc:title>
        <dc:date>13:58:15</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.theguardian.com/news/datablog/interactive/2013/jan/14/all-our-datasets-index</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 13:58:15</dcterms:dateSubmitted>
    </bib:Document>
    <bib:Article rdf:about="http://www.polisci.ucla.edu/workshops/ap-workshop-papers/Hadley%20Wickham%20Paper-%2004-08-13.pdf">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Wickham</foaf:surname>
                        <foaf:givenname>Hadley</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_377"/>
        <dc:title>Bin-summarise-smooth: A framework for visualising large data</dc:title>
        <dc:date>14:14:18</dc:date>
        <z:shortTitle>Bin-summarise-smooth</z:shortTitle>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.polisci.ucla.edu/workshops/ap-workshop-papers/Hadley%20Wickham%20Paper-%2004-08-13.pdf</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 14:14:18</dcterms:dateSubmitted>
        <z:libraryCatalog>Google Scholar</z:libraryCatalog>
    </bib:Article>
    <z:Attachment rdf:about="#item_377">
        <z:itemType>attachment</z:itemType>
        <dc:title>Wickham_0000_Bin-summarise-smooth.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Document rdf:about="http://www.r-bloggers.com/creating-a-business-dashboard-in-r/">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Smeets</foaf:surname>
                        <foaf:givenname>Bart</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Creating a Business Dashboard in R</dc:title>
        <dc:date>14:20:32</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.r-bloggers.com/creating-a-business-dashboard-in-r/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 14:20:32</dcterms:dateSubmitted>
    </bib:Document>
    <bib:Data rdf:about="https://pypi.python.org/pypi/DAGPype">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Tavory</foaf:surname>
                        <foaf:givenname>Ami</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>DAGPype</dc:title>
        <dc:date>14:22:31</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://pypi.python.org/pypi/DAGPype</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 14:22:31</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/thinkaurelius/titan">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Aurelius</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Titan</dc:title>
        <dcterms:abstract>titan - Distributed Graph Database</dcterms:abstract>
        <dc:date>14:24:57</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/thinkaurelius/titan</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 14:24:57</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/thinkaurelius/faunus">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Aurelius</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Faunus</dc:title>
        <dcterms:abstract>faunus - Graph Analytics Engine</dcterms:abstract>
        <dc:date>14:25:07</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/thinkaurelius/faunus</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 14:25:07</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/madlib/madlib">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>MADlib Project</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>MADlib</dc:title>
        <dcterms:abstract>madlib - Open-source library for scalable in-database analytics.</dcterms:abstract>
        <dc:date>14:25:40</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/madlib/madlib</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 14:25:40</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://pypi.python.org/pypi/pymadlib/0.1.4">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ramanujam</foaf:surname>
                        <foaf:givenname>Srivatsan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>pymadlib</dc:title>
        <dc:date>14:26:03</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://pypi.python.org/pypi/pymadlib/0.1.4</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 14:26:03</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/pydata/pandas">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>The PyData Development Team</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>pandas</dc:title>
        <dcterms:abstract>pandas - Flexible and powerful data analysis / manipulation library for Python, providing labeled data structures similar to R data.frame objects, statistical functions, and much more</dcterms:abstract>
        <dc:date>14:26:56</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/pydata/pandas</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 14:26:56</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/ipython/ipython">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>IPython Development Team</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>IPython</dc:title>
        <dcterms:abstract>ipython - Official repository for IPython itself. Other repos in the IPython organization contain things like the website, documentation builds, etc.</dcterms:abstract>
        <dc:date>14:28:51</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/ipython/ipython</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 14:28:51</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://pypi.python.org/pypi/ipython-sql">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Devlin</foaf:surname>
                        <foaf:givenname>Catherine</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>ipython-sql</dc:title>
        <dc:date>14:29:32</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://pypi.python.org/pypi/ipython-sql</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 14:29:32</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/bitly/forgettable">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>bitly</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Forget-Table</dc:title>
        <dcterms:abstract>forgettable - Various implementations of the forget table: a distributional database that forgets data</dcterms:abstract>
        <dc:date>14:31:21</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/bitly/forgettable</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 14:31:21</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/bitly/dablooms">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>bitly</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>dablooms</dc:title>
        <dcterms:abstract>dablooms - scaling, counting, bloom filter library</dcterms:abstract>
        <dc:date>14:32:56</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/bitly/dablooms</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 14:32:56</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Document rdf:about="http://strata.oreilly.com/2013/03/data-science-tools-all-in-or-mix-and-match.html">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lorica</foaf:surname>
                        <foaf:givenname>Ben</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>
           <z:AutomaticTag><rdf:value>data science</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>data scientist</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>machine learning</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>machine learning products</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>R</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>SAS</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>spark</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:title>Data Science tools: Are you &quot;all in&quot; or do you &quot;mix and match&quot;?</dc:title>
        <dcterms:abstract>An integrated data stack boosts productivity As I noted in my previous post, Python programmers willing to go &quot;all in&quot;, have Python tools to cover most of data science....</dcterms:abstract>
        <dc:date>14:34:10</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://strata.oreilly.com/2013/03/data-science-tools-all-in-or-mix-and-match.html</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 14:34:10</dcterms:dateSubmitted>
        <z:shortTitle>Data Science tools</z:shortTitle>
    </bib:Document>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/kris77chan/edward-segel-interactivestorytelling">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Segel</foaf:surname>
                        <foaf:givenname>E.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <dc:title>How to tell stories with data (really)</dc:title>
        <dcterms:abstract>Presentation slides: Interactive Storytelling Edward Segel helped Bloomberg develop a datavis strategy. He also wrote a really great paper: Narrative Visualization</dcterms:abstract>
        <z:type>Technology</z:type>
        <dc:date>Sat Nov 05  2011</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/kris77chan/edward-segel-interactivestorytelling</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 14:36:00</dcterms:dateSubmitted>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <bib:Article rdf:about="http://kosara.net/publications/journal-papers.html">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf rdf:resource="urn:issn:0018-9162"/>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kosara</foaf:surname>
                        <foaf:givenname>Robert</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Mackinlay</foaf:surname>
                        <foaf:givenname>Jock</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_270"/>
        <dc:subject>
           <z:AutomaticTag><rdf:value>collaboration</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>data visualization</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>narratives</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>storytelling</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>visual communication</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>visual databases</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>visual effects</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>visualization</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:title>Storytelling: The Next Step for Visualization</dc:title>
        <dcterms:abstract>Presentation—specifically, its use of elements from storytelling—is the next logical step in visualization research and should be a focus of at least equal importance with exploration and analysis.</dcterms:abstract>
        <bib:pages>44-50</bib:pages>
        <dc:date>2013</dc:date>
        <z:shortTitle>Storytelling</z:shortTitle>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://kosara.net/publications/journal-papers.html</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <z:libraryCatalog>IEEE Computer Society</z:libraryCatalog>
    </bib:Article>
    <bib:Journal rdf:about="urn:issn:0018-9162">
        <dc:title>Computer</dc:title>
        <prism:volume>46</prism:volume>
        <prism:number>5</prism:number>
        <dc:identifier>ISSN 0018-9162</dc:identifier>
    </bib:Journal>
    <z:Attachment rdf:about="#item_270">
        <z:itemType>attachment</z:itemType>
        <dc:title>Kosara_Mackinlay_2013_Storytelling.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://www.nature.com/srep/2013/130207/srep01236/full/srep01236.html">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
                <dc:title>Scientific Reports</dc:title>
                <prism:volume>3</prism:volume>
                <dcterms:alternative>Sci. Rep.</dcterms:alternative>
                <dc:identifier>DOI 10.1038/srep01236</dc:identifier>
            </bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lum</foaf:surname>
                        <foaf:givenname>P. Y.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Singh</foaf:surname>
                        <foaf:givenname>G.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lehman</foaf:surname>
                        <foaf:givenname>A.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ishkanov</foaf:surname>
                        <foaf:givenname>T.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Vejdemo-Johansson</foaf:surname>
                        <foaf:givenname>M.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Alagappan</foaf:surname>
                        <foaf:givenname>M.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Carlsson</foaf:surname>
                        <foaf:givenname>J.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Carlsson</foaf:surname>
                        <foaf:givenname>G.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_347"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Applied mathematics</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computational science</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Scientific data</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Software</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:title>Extracting insights from the shape of complex data using topology</dc:title>
        <dcterms:abstract>This paper applies topological methods to study complex high dimensional data sets by extracting shapes (patterns) and obtaining insights about them. Our method combines the best features of existing standard methodologies such as principal component and cluster analyses to provide a geometric representation of complex data sets. Through this hybrid method, we often find subgroups in data sets that traditional methodologies fail to find. Our method also permits the analysis of individual data sets as well as the analysis of relationships between related data sets. We illustrate the use of our method by applying it to three very different kinds of data, namely gene expression from breast tumors, voting data from the United States House of Representatives and player performance data from the NBA, in each case finding stratifications of the data which are more refined than those produced by standard methods.</dcterms:abstract>
        <dc:date>February 7, 2013</dc:date>
        <z:language>en</z:language>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.nature.com/srep/2013/130207/srep01236/full/srep01236.html</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-01 12:55:59</dcterms:dateSubmitted>
        <z:libraryCatalog>www.nature.com</z:libraryCatalog>
        <dc:rights>© 2013 Macmillan Publishers Limited. All rights reserved</dc:rights>
    </bib:Article>
    <z:Attachment rdf:about="#item_347">
        <z:itemType>attachment</z:itemType>
        <dc:title>Lum_et_al_2013_Extracting_insights_from_the_shape_of_complex_data_using_topology.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/visualisingdata/andy-kirks-facebook-talk">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kirk</foaf:surname>
                        <foaf:givenname>Andy</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <dc:title>Visualisation Workflow: Finding Stories and Telling Stories</dc:title>
        <dc:date>Thu Jan 10  2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/visualisingdata/andy-kirks-facebook-talk</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 14:59:45</dcterms:dateSubmitted>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <bib:Article rdf:about="http://vis.stanford.edu/papers/narrative">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf rdf:resource="urn:issn:1077-2626"/>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Segel</foaf:surname>
                        <foaf:givenname>E.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Heer</foaf:surname>
                        <foaf:givenname>J.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_359"/>
        <dc:subject>
           <z:AutomaticTag><rdf:value>case study</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>data story</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>data visualisation</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>data visualization</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>design differences</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>design methods</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Economics</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>educational aids</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>educational media</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Engineering profession</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>humanities</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Image color analysis</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>journalism</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>journalistic storytelling</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Media</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>narrative visualization</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>online journalists</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>social data analysis</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>storytelling</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>telling story</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>visualization</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>visualization research</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:title>Narrative Visualization: Telling Stories with Data</dc:title>
        <dcterms:abstract>Data visualization is regularly promoted for its ability to reveal stories within data, yet these “data stories” differ in important ways from traditional forms of storytelling. Storytellers, especially online journalists, have increasingly been integrating visualizations into their narratives, in some cases allowing the visualization to function in place of a written story. In this paper, we systematically review the design space of this emerging class of visualizations. Drawing on case studies from news media to visualization research, we identify distinct genres of narrative visualization. We characterize these design differences, together with interactivity and messaging, in terms of the balance between the narrative flow intended by the author (imposed by graphical elements and the interface) and story discovery on the part of the reader (often through interactive exploration). Our framework suggests design strategies for narrative visualization, including promising under-explored approaches to journalistic storytelling and educational media.</dcterms:abstract>
        <bib:pages>1139-1148</bib:pages>
        <dc:date>2010</dc:date>
        <z:shortTitle>Narrative Visualization</z:shortTitle>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://vis.stanford.edu/papers/narrative</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <z:libraryCatalog>IEEE Xplore</z:libraryCatalog>
    </bib:Article>
    <bib:Journal rdf:about="urn:issn:1077-2626">
        <dc:title>IEEE Transactions on Visualization and Computer Graphics</dc:title>
        <prism:volume>16</prism:volume>
        <prism:number>6</prism:number>
        <dc:identifier>DOI 10.1109/TVCG.2010.179</dc:identifier>
        <dc:identifier>ISSN 1077-2626</dc:identifier>
    </bib:Journal>
    <z:Attachment rdf:about="#item_359">
        <z:itemType>attachment</z:itemType>
        <dc:title>Segel_Heer_2010_Narrative_Visualization.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://www.eric.ed.gov/ERICWebPortal/recordDetail?accno=EJ593526">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
                <dc:title>School Library Media Research</dc:title>
                <prism:volume>2</prism:volume>
            </bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Sturm</foaf:surname>
                        <foaf:givenname>Brian W.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_2382"/>
        <dc:title>The Enchanted Imagination: Storytelling's Power To Entrance Listeners.</dc:title>
        <dc:date>1999</dc:date>
        <z:shortTitle>The Enchanted Imagination</z:shortTitle>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.eric.ed.gov/ERICWebPortal/recordDetail?accno=EJ593526</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 15:03:07</dcterms:dateSubmitted>
        <z:libraryCatalog>Google Scholar</z:libraryCatalog>
    </bib:Article>
    <z:Attachment rdf:about="#item_2382">
        <z:itemType>attachment</z:itemType>
        <dc:title>The Enchanted Imagination_ Stor - Brian W. Sturm.azw3</dc:title>
        <link:type>application/octet-stream</link:type>
    </z:Attachment>
    <bib:Book rdf:about="urn:isbn:9780132884471%20013288447X">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>[Boston, Mass.]</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>IBM Press/Pearson Education</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Taylor</foaf:surname>
                        <foaf:givenname>James</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Decision management systems a practical guide to using business rules and predictive analytics</dc:title>
        <dc:date>2012</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9780132884471 013288447X</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.books24x7.com/marc.asp?bookid=45443</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-27 10:11:31</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Document rdf:about="http://jaibeermalik.wordpress.com/2013/03/26/elasticsearch-text-analysis-for-content-enrichment/">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
            <z:Blog>
               <dc:title>Jai's Weblog - Tech, Security &amp; Fun...</dc:title>
            </z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Malik</foaf:surname>
                        <foaf:givenname>Jaibeer</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>ElasticSearch: Text analysis for content enrichment</dc:title>
        <dcterms:abstract>Every text search solution is as powerful as the text analysis capabilities it offers. Lucene is such open source information retrieval library offering many text analysis possibilities. In this po...</dcterms:abstract>
        <dc:date>15:11:06</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://jaibeermalik.wordpress.com/2013/03/26/elasticsearch-text-analysis-for-content-enrichment/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 15:11:06</dcterms:dateSubmitted>
        <z:shortTitle>ElasticSearch</z:shortTitle>
    </bib:Document>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/psychemedia/mapping-corporate-networks-with-opencorporates?ref=http://blog.ouseful.info/2013/04/23/mapping-corporate-networks-with-opencorporates/">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Hirst</foaf:surname>
                        <foaf:givenname>Tony</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <link:link rdf:resource="#item_439"/>
        <dc:title>Mapping Corporate Networks With OpenCorporates</dc:title>
        <z:type>Technology</z:type>
        <dc:date>Tue Apr 23  2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/psychemedia/mapping-corporate-networks-with-opencorporates?ref=http://blog.ouseful.info/2013/04/23/mapping-corporate-networks-with-opencorporates/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 19:46:58</dcterms:dateSubmitted>
    </bib:ConferenceProceedings>
    <z:Attachment rdf:about="#item_439">
        <z:itemType>attachment</z:itemType>
        <dc:title>Hirst_2013_Mapping_Corporate_Networks_With_OpenCorporates.pptx</dc:title>
        <link:type>application/vnd.openxmlformats-officedocument.presentationml.presentation</link:type>
    </z:Attachment>
    <bib:Document rdf:about="http://continuum.io/blog/wakari-and-big-finance">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Zaitlen</foaf:surname>
                        <foaf:givenname>Benjamin</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Wakari and Big Finance</dc:title>
        <dc:date>22:35:42</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://continuum.io/blog/wakari-and-big-finance</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 22:35:42</dcterms:dateSubmitted>
    </bib:Document>
    <bib:Data rdf:about="https://github.com/scrapy/scrapely">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Scrapy project</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Scrapely</dc:title>
        <dcterms:abstract>scrapely - A pure-python HTML screen-scraping library</dcterms:abstract>
        <dc:date>15:19:13</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/scrapy/scrapely</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 15:19:13</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Document rdf:about="http://strata.oreilly.com/2013/04/workflow-tools-enable-the-rapid-deployment-of-models.html">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lorica</foaf:surname>
                        <foaf:givenname>Ben</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>
           <z:AutomaticTag><rdf:value>algorithm</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>algorithms</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>data engineer</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>data science</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>data scientist</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>machine learning</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>statistics</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>workflow</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:title>Simpler workflow tools enable the rapid deployment of models</dc:title>
        <dcterms:abstract>Data science often depends on data pipelines, that involve acquiring, transforming, and loading data. (If you're fortunate most of the data you need is already in usable form.) Data...</dcterms:abstract>
        <dc:date>15:21:19</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://strata.oreilly.com/2013/04/workflow-tools-enable-the-rapid-deployment-of-models.html</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 15:21:19</dcterms:dateSubmitted>
    </bib:Document>
    <bib:Document rdf:about="http://blogs.edweek.org/edweek/edtechresearcher/2013/03/small_data_and_big_data_should_be_best_friends.html?cmp=SOC-SHR-FB">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
            <z:Blog>
               <dc:title>Education Week - EdTech Researcher</dc:title>
            </z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Reich</foaf:surname>
                        <foaf:givenname>Justin</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Small Data and Big Data Should be Best Friends</dc:title>
        <dcterms:abstract>A defense of methodological pluralism.</dcterms:abstract>
        <dc:date>15:44:24</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://blogs.edweek.org/edweek/edtechresearcher/2013/03/small_data_and_big_data_should_be_best_friends.html?cmp=SOC-SHR-FB</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 15:44:24</dcterms:dateSubmitted>
    </bib:Document>
    <bib:Data rdf:about="https://github.com/maksim2042/snowwhite">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Tsvetovat</foaf:surname>
                        <foaf:givenname>Maksim</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>SnowWhite</dc:title>
        <dcterms:abstract>Contribute to snowwhite development by creating an account on GitHub.</dcterms:abstract>
        <dc:date>15:45:52</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/maksim2042/snowwhite</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 15:45:52</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Document rdf:about="http://blogs.hbr.org/2013/04/the-hidden-biases-in-big-data/">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
            <z:Blog>
               <dc:title>HBR Blog Network - Harvard Business Review</dc:title>
            </z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Crawford</foaf:surname>
                        <foaf:givenname>Kate</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>
           <z:AutomaticTag><rdf:value>accounting</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>business management articles resources</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
                <rdf:value>business resources books articles case studies</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>communication</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>entrepreneurship</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>execution</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>finance</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Harvard Business School Publishing</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>HBO</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>HBP</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>HBR</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>HBSP</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>innovation</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>international global business strategy</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>leadership</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>managing people</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>operations</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>organizational development</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>technology</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:title>The Hidden Biases in Big Data</dc:title>
        <dcterms:abstract>Blindly trusting it can lead you to the wrong conclusions.</dcterms:abstract>
        <dc:date>15:48:03</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://blogs.hbr.org/2013/04/the-hidden-biases-in-big-data/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 15:48:03</dcterms:dateSubmitted>
    </bib:Document>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/perficientinc/drive-smarter-decisions-with-big-data-using-complex-event-processing">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Roch</foaf:surname>
                        <foaf:givenname>Eric</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <bib:contributors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Perficient, Inc.</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:contributors>
        <dc:title>Drive Smarter Decisions with Big Data Using Complex Event Processing</dc:title>
        <dcterms:abstract>This webinar described what CEP is and how it has been deployed in several client organizations to provide more agile, cost-effective and real-time integration across multiple data stores including:
Analysis of large amounts of complex, unstructured and semi-structured data
Harnessing the power big data, social/mobile data stores and BI projects for real-time decision making
Predicting events before they happen based on patterns and rules</dcterms:abstract>
        <z:type>Technology</z:type>
        <dc:date>Wed Jul 17  2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/perficientinc/drive-smarter-decisions-with-big-data-using-complex-event-processing</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-26 17:30:45</dcterms:dateSubmitted>
    </bib:ConferenceProceedings>
    <bib:Manuscript rdf:about="https://github.com/hadley/adv-r/">
        <z:itemType>manuscript</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Wickham</foaf:surname>
                        <foaf:givenname>Hadley</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Advanced R Development</dc:title>
        <dcterms:abstract>This is the in-progress book site for &quot;Advanced R development&quot;. The book is designed primarily for R users who want to improve their programming skills and understanding of the language. It should also be useful for programmers coming to R from other languages, as it explains some of R's quirks and shows how some parts that seem horrible do have a positive side.</dcterms:abstract>
        <dc:date>12:56:23</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/hadley/adv-r/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-01 12:56:23</dcterms:dateSubmitted>
    </bib:Manuscript>
    <bib:Book rdf:about="urn:isbn:9781430258063%201430258063">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Berkeley, CA; New York</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Apress ; Distributed to the book trade worldwide by Springer</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Barker</foaf:surname>
                        <foaf:givenname>Tom</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_69"/>
        <dc:title>Pro Data Visualization using R and JavaScript</dc:title>
        <dcterms:abstract>Pro Data Visualization using R and JavaScript makes the R language approachable, and promotes the idea of data gathering and analysis. You'll see how to use R to interrogate and analyze your data, and then use the D3 JavaScript library to format and display that data in an elegant, informative, and interactive way. You will learn how to gather data effectively, and also how to understand the philosophy and implementation of each type of chart, so as to be able to represent the results visually. With the popularity of the R language, the art and practice of creating data visualizations is no longer the preserve of mathematicians, statisticians, or cartographers. As technology leaders, we can gather metrics around what we do and use data visualizations to communicate that information. Pro Data Visualization using R and JavaScript combines the power of the R language with the simplicity and familiarity of JavaScript to display clear and informative data visualizations. Gathering and analyzing empirical data is the key to truly understanding anything. We can track operational metrics to quantify the health of our products in production. We can track quality metrics of our projects, and even use our data to identify bad code. Visualizing this data allows anyone to read our analysis and easily get a deep understanding of the story the data tells.</dcterms:abstract>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781430258063 1430258063</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <z:Attachment rdf:about="#item_69">
        <z:itemType>attachment</z:itemType>
        <dc:title>Pro JavaScript Performance_ Monitoring a - Tom Barker.epub</dc:title>
        <link:type>application/octet-stream</link:type>
    </z:Attachment>
    <bib:Book rdf:about="urn:isbn:9781118147603%20%20111814760X%20%209781118225837%20%20111822583X%20%209781118239155%20%201118239156%20%209781118263815%20%201118263812">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Hoboken, N.J</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>John Wiley</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Minelli</foaf:surname>
                        <foaf:givenname>Michael</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Chambers</foaf:surname>
                        <foaf:givenname>Michele</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Dhiraj</foaf:surname>
                        <foaf:givenname>Ambiga</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Big data, big analytics: emerging business intelligence and analytic trends for today's businesses</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781118147603  111814760X  9781118225837  111822583X  9781118239155  1118239156  9781118263815  1118263812</dc:identifier>
        <z:shortTitle>Big data, big analytics</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Data rdf:about="https://github.com/trifacta/triflow">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Trifacta</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>triflow</dc:title>
        <dcterms:abstract>triflow is a dataflow implementation in JavaScript.</dcterms:abstract>
        <dc:date>12:56:37</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/trifacta/triflow</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-01 12:56:37</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Recording rdf:about="urn:isbn:9781449365394">
        <z:itemType>videoRecording</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>[Calif?].</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly Media</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <z:directors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Strata Conference</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:directors>
        <dc:title>Strata Conference Santa Clara 2013: Complete Video Compilation</dc:title>
        <dcterms:abstract>&quot;Didn't make it to Strata Santa Clara 2013? No problem. This complete video compilation puts you front and center at every keynote, session, and tutorial from the biggest Strata Conference to date. With more than 100 presentations from today's leading big data practitioners, you'll learn the latest approaches to data-driven business, data design, data science, new data from an increasingly connected world, and many other issues.&quot;--Resource description page.</dcterms:abstract>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781449365394</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://my.safaribooksonline.com/video/databases/9781449365394</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-27 10:11:39</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Recording>
    <bib:Book rdf:about="urn:isbn:1782169938%20%209781782169932">
        <z:itemType>book</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Rossant</foaf:surname>
                        <foaf:givenname>Cyrille</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Learning IPython for interactive computing and data visualization</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 1782169938  9781782169932</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9781849518932%201849518939%201849518920%209781849518925">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Birmingham</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Packt Pub.</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Idris</foaf:surname>
                        <foaf:givenname>Ivan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_129"/>
        <dc:title>NumPy Cookbook</dc:title>
        <dcterms:abstract>Written in Cookbook style, the code examples will take your Numpy skills to the next level. This book will take Python developers with basic Numpy skills to the next level through some practical recipes.</dcterms:abstract>
        <dc:date>2012</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781849518932 1849518939 1849518920 9781849518925</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://proquest.safaribooksonline.com/?fpi=9781849518925</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-27 10:11:47</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <z:Attachment rdf:about="#item_129">
        <z:itemType>attachment</z:itemType>
        <dc:title>NumPy Cookbook - Ivan Idris.epub</dc:title>
        <link:type>application/octet-stream</link:type>
    </z:Attachment>
    <bib:Book rdf:about="urn:isbn:9781782161332%201782161333">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Birmingham, UK</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Packt Pub.</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kuć</foaf:surname>
                        <foaf:givenname>Rafał</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Apache Solr 4 cookbook</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781782161332 1782161333</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://proquest.safaribooksonline.com/?fpi=9781782161325</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-27 10:11:53</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:1299735142%20%209781299735149">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
               <foaf:name>Packt Publishing</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Hoffman</foaf:surname>
                        <foaf:givenname>Steve</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Apache Flume: Distributed Log Collection for Hadoop</dc:title>
        <dcterms:abstract>A starter guide that covers Apache Flume in detail.Apache Flume: Distributed Log Collection for Hadoop is intended for people who are responsible for moving datasets into Hadoop in a timely and reliable manner like software engineers, database administrators, and data warehouse administrators</dcterms:abstract>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 1299735142  9781299735149</dc:identifier>
        <z:shortTitle>Apache Flume</z:shortTitle>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://lib.myilibrary.com?id=504765</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-27 10:12:01</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9781849517287%20%201849517282">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Birminham</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Packt Pub.</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Perera</foaf:surname>
                        <foaf:givenname>Srinath</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Gunarathne</foaf:surname>
                        <foaf:givenname>Thilina</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Hadoop MapReduce cookbook</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781849517287  1849517282</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Data rdf:about="https://github.com/trifacta/vega">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Trifacta</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>d3</dc:subject>
        <dc:title>Vega</dc:title>
        <dcterms:abstract>vega - A visualization grammar.</dcterms:abstract>
        <dc:date>12:56:53</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/trifacta/vega</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-01 12:56:53</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Book rdf:about="urn:isbn:9781849519120%20%201849519129">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Birmingham</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Packt Pub.</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Owens</foaf:surname>
                        <foaf:givenname>Jonathan R</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lentz</foaf:surname>
                        <foaf:givenname>Jon</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Femiano</foaf:surname>
                        <foaf:givenname>Brian</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Hadoop real-world solutions cookbook</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781849519120  1849519129</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9781449323950">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Sebastopol, CA</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:contributors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Pollack</foaf:surname>
                        <foaf:givenname>Mark</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:contributors>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Application software</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Database management</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Development</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Java (Computer program language)</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:title>Spring Data: modern data access for enterprise Java</dc:title>
        <dc:date>2013</dc:date>
        <z:numPages>288</z:numPages>
        <dc:identifier>ISBN 9781449323950</dc:identifier>
        <z:shortTitle>Spring Data</z:shortTitle>
        <z:libraryCatalog>Library of Congress ISBN</z:libraryCatalog>
        <dc:subject>
           <dcterms:LCC><rdf:value>QA76.73.J38 S737 2013</rdf:value></dcterms:LCC>
        </dc:subject>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9780745662527">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Cambridge, UK ; Malden, MA</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Polity</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Galloway</foaf:surname>
                        <foaf:givenname>Alexander R.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Digital communications</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Digital media</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Human-computer interaction</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Information society</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Philosophy</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:title>The interface effect</dc:title>
        <dc:date>2012</dc:date>
        <z:numPages>170</z:numPages>
        <dc:identifier>ISBN 9780745662527</dc:identifier>
        <z:libraryCatalog>Library of Congress ISBN</z:libraryCatalog>
        <dc:subject>
           <dcterms:LCC><rdf:value>QA76.9.H85 G35 2012</rdf:value></dcterms:LCC>
        </dc:subject>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9781849693479%201849693471%209781849693462%201849693463">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Birmingham, UK</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Packt Pub</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kirk</foaf:surname>
                        <foaf:givenname>Andy</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_135"/>
        <dc:title>Data visualization a successful design process</dc:title>
        <dcterms:abstract>a structured design approach to equip you with the knowledge of how to successfully accomplish any data visualization challenge efficiently and effectively</dcterms:abstract>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781849693479 1849693471 9781849693462 1849693463</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <z:Attachment rdf:about="#item_135">
        <z:itemType>attachment</z:itemType>
        <dc:title>Data Visualization_ A Successful Design  - Kirk Andy.epub</dc:title>
        <link:type>application/octet-stream</link:type>
    </z:Attachment>
    <bib:Book rdf:about="urn:isbn:9781449306465%20%201449306462">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Sebastopol, CA</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly Media</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Tsvetovat</foaf:surname>
                        <foaf:givenname>Maksim</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kouznetsov</foaf:surname>
                        <foaf:givenname>Alexander</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_159"/>
        <dc:title>Social network analysis for startups: [finding connections on the social web]</dc:title>
        <dc:date>2011</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781449306465  1449306462</dc:identifier>
        <z:shortTitle>Social network analysis for startups</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <z:Attachment rdf:about="#item_159">
        <z:itemType>attachment</z:itemType>
        <dc:title>Social Network Analysis for Startups_ Fi - Maksim Tsvetovat.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Book rdf:about="urn:isbn:9781449321888%20%20:%201449321887">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Beijing; Sebastopol, CA</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>McCallum</foaf:surname>
                        <foaf:givenname>Q. Ethan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_144"/>
        <dc:title>Bad data handbook</dc:title>
        <dc:date>2012</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781449321888  : 1449321887</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <z:Attachment rdf:about="#item_144">
        <z:itemType>attachment</z:itemType>
        <dc:title>Bad Data Handbook_ Cleaning Up the Data So You Can Get Back to Work - Q. Ethan McCallum.epub</dc:title>
        <link:type>application/octet-stream</link:type>
    </z:Attachment>
    <bib:Book rdf:about="urn:isbn:1849513600%209781849513609">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Birmingham [u.a.]</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Packt Publ.</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Perkins</foaf:surname>
                        <foaf:givenname>Jacob</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_149"/>
        <dc:title>Python text processing with NLTK 2.0 cookbook: over 80 practical recipes for using Python's NLTK suite of libraries to maximize your Natural Language Processing capabilities</dc:title>
        <dc:date>2010</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 1849513600 9781849513609</dc:identifier>
        <z:shortTitle>Python text processing with NLTK 2.0 cookbook</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <z:Attachment rdf:about="#item_149">
        <z:itemType>attachment</z:itemType>
        <dc:title>Python Text Processing With Nltk 2.0 Coo - Jacob Perkins.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Book rdf:about="urn:isbn:9780123944252">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Amsterdam</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Elsevier, Morgan Kaufmann</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lans</foaf:surname>
                        <foaf:givenname>Rick F. van der</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_136"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Business intelligence</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Data warehousing</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Management information systems</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Virtual computer systems</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:title>Data virtualization for business intelligence systems: revolutionizing data integration for data warehouses</dc:title>
        <dc:date>2012</dc:date>
        <z:numPages>275</z:numPages>
        <dc:identifier>ISBN 9780123944252</dc:identifier>
        <z:shortTitle>Data virtualization for business intelligence systems</z:shortTitle>
        <z:libraryCatalog>Library of Congress ISBN</z:libraryCatalog>
        <dc:subject>
           <dcterms:LCC><rdf:value>QA76.9.D37 L36 2012</rdf:value></dcterms:LCC>
        </dc:subject>
    </bib:Book>
    <z:Attachment rdf:about="#item_136">
        <z:itemType>attachment</z:itemType>
        <dc:title>Data Virtualization for Business Intelli - van der Lans, Rick.epub</dc:title>
        <link:type>application/octet-stream</link:type>
    </z:Attachment>
    <bib:Book rdf:about="urn:isbn:9781449330064">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Sebastopol, CA</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly Media</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>European Journalism Centre</foaf:surname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Open Knowledge Foundation</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <bib:contributors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Gray</foaf:surname>
                        <foaf:givenname>Jonathan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Bounegru</foaf:surname>
                        <foaf:givenname>Liliana</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Chambers</foaf:surname>
                        <foaf:givenname>Lucy</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:contributors>
        <link:link rdf:resource="#item_113"/>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Data mining</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Data processing</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Information visualization</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>journalism</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:title>The data journalism handbook</dc:title>
        <prism:edition>1st ed</prism:edition>
        <dc:date>2012</dc:date>
        <z:numPages>220</z:numPages>
        <dc:identifier>ISBN 9781449330064</dc:identifier>
        <z:libraryCatalog>Library of Congress ISBN</z:libraryCatalog>
        <dc:subject>
           <dcterms:LCC><rdf:value>PN4784.E5 D36 2012</rdf:value></dcterms:LCC>
        </dc:subject>
    </bib:Book>
    <z:Attachment rdf:about="#item_113">
        <z:itemType>attachment</z:itemType>
        <dc:title>The Data Journalism Handbook - Jonathan Gray.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Book rdf:about="urn:isbn:9781449306595">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Sebastopol, CA</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly Media</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>DuCharme</foaf:surname>
                        <foaf:givenname>Bob</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_103"/>
        <link:link rdf:resource="#item_99"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Internet searching</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Query languages (Computer science)</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Querying (Computer science)</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>RDF (Document markup language)</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:title>Learning SPARQL: querying and updating with SPARQL 1.1</dc:title>
        <prism:edition>1st ed</prism:edition>
        <dc:date>2011</dc:date>
        <z:numPages>235</z:numPages>
        <dc:identifier>ISBN 9781449306595</dc:identifier>
        <z:shortTitle>Learning SPARQL</z:shortTitle>
        <z:libraryCatalog>Library of Congress ISBN</z:libraryCatalog>
        <dc:subject>
           <dcterms:LCC><rdf:value>QA76.7 .D83 2011</rdf:value></dcterms:LCC>
        </dc:subject>
    </bib:Book>
    <z:Attachment rdf:about="#item_103">
        <z:itemType>attachment</z:itemType>
        <dc:title>Learning SPARQL - Bob DuCharme.epub</dc:title>
        <link:type>application/octet-stream</link:type>
    </z:Attachment>
    <z:Attachment rdf:about="#item_99">
        <z:itemType>attachment</z:itemType>
        <dc:title>Learning SPARQL - Bob DuCharme.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Book rdf:about="urn:isbn:9780970601919%20%200970601913%20%209780970601926%20%200970601921">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Oakland, CA</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Analytics Press</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Koomey</foaf:surname>
                        <foaf:givenname>Jon</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Turning numbers into knowledge: mastering the art of problem solving</dc:title>
        <dc:date>2008</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9780970601919  0970601913  9780970601926  0970601921</dc:identifier>
        <z:shortTitle>Turning numbers into knowledge</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:0470539399">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Hoboken, N.J.</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Wiley</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Hubbard</foaf:surname>
                        <foaf:givenname>Douglas W</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>How to measure anything finding the value of &quot;intangibles&quot; in business</dc:title>
        <dc:date>2010</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 0470539399</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://site.ebrary.com/id/10381009</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-27 10:48:08</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9780470099513">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Indianapolis, IN</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Wiley Pub</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Linoff</foaf:surname>
                        <foaf:givenname>Gordon</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_138"/>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Data mining</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Microsoft Excel (Computer file)</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Querying (Computer science)</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>SQL (Computer program language)</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:title>Data analysis using SQL and Excel</dc:title>
        <dc:date>2008</dc:date>
        <z:numPages>645</z:numPages>
        <dc:identifier>ISBN 9780470099513</dc:identifier>
        <z:libraryCatalog>Library of Congress ISBN</z:libraryCatalog>
        <dc:subject>
           <dcterms:LCC><rdf:value>QA76.73.S67 L56 2008</rdf:value></dcterms:LCC>
        </dc:subject>
    </bib:Book>
    <z:Attachment rdf:about="#item_138">
        <z:itemType>attachment</z:itemType>
        <dc:title>Data Analysis Using SQL and Excel - Gordon S. Linoff.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Book rdf:about="urn:isbn:9780393072952">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>New York</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>W.W. Norton &amp; Co</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Wong</foaf:surname>
                        <foaf:givenname>Dona M.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Business presentations</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Charts, diagrams, etc</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Graphic methods</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>visual communication</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:title>The Wall Street journal guide to information graphics: the dos and don'ts of presenting data, facts, and figures</dc:title>
        <prism:edition>1st ed</prism:edition>
        <dc:date>2010</dc:date>
        <z:numPages>157</z:numPages>
        <dc:identifier>ISBN 9780393072952</dc:identifier>
        <z:shortTitle>The Wall Street journal guide to information graphics</z:shortTitle>
        <z:libraryCatalog>Library of Congress ISBN</z:libraryCatalog>
        <dc:subject>
           <dcterms:LCC><rdf:value>HF5718.22 .W65 2010</rdf:value></dcterms:LCC>
        </dc:subject>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:0911379010">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Cambridge, Mass</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Massachusetts Institute of Technology, Center for Advanced Engineering Study</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Deming</foaf:surname>
                        <foaf:givenname>W. Edwards</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Industrial management</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Industrial productivity</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Quality of products</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>United States</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:title>Out of the crisis</dc:title>
        <dc:date>1986</dc:date>
        <z:numPages>507</z:numPages>
        <dc:identifier>ISBN 0911379010</dc:identifier>
        <z:libraryCatalog>Library of Congress ISBN</z:libraryCatalog>
        <dc:subject>
           <dcterms:LCC><rdf:value>HD70.U5 D45 1986</rdf:value></dcterms:LCC>
        </dc:subject>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9780471381976">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Hoboken, N.J</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Wiley</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Savage</foaf:surname>
                        <foaf:givenname>Sam L.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Risk</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Uncertainty</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:title>The flaw of averages: why we underestimate risk in the face of uncertainty</dc:title>
        <dc:date>2009</dc:date>
        <z:numPages>392</z:numPages>
        <dc:identifier>ISBN 9780471381976</dc:identifier>
        <z:shortTitle>The flaw of averages</z:shortTitle>
        <z:libraryCatalog>Library of Congress ISBN</z:libraryCatalog>
        <dc:subject>
           <dcterms:LCC><rdf:value>HB615 .S313 2009</rdf:value></dcterms:LCC>
        </dc:subject>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:0596100167">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Beijing ; Cambride [MA]</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Few</foaf:surname>
                        <foaf:givenname>Stephen</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Dashboards (Management information systems)</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:title>Information dashboard design: the effective visual communication of data</dc:title>
        <prism:edition>1st ed</prism:edition>
        <dc:date>2006</dc:date>
        <z:numPages>211</z:numPages>
        <dc:identifier>ISBN 0596100167</dc:identifier>
        <z:shortTitle>Information dashboard design</z:shortTitle>
        <z:libraryCatalog>Library of Congress ISBN</z:libraryCatalog>
        <dc:subject>
           <dcterms:LCC><rdf:value>HD30.213 .F49 2006</rdf:value></dcterms:LCC>
        </dc:subject>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:0596008945">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Sebastopol, CA</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Faroult</foaf:surname>
                        <foaf:givenname>Stéphane</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <bib:contributors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Robson</foaf:surname>
                        <foaf:givenname>Peter</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:contributors>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>SQL (Computer program language)</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:title>The art of SQL</dc:title>
        <prism:edition>1st ed</prism:edition>
        <dc:date>2006</dc:date>
        <z:numPages>349</z:numPages>
        <dc:identifier>ISBN 0596008945</dc:identifier>
        <z:libraryCatalog>Library of Congress ISBN</z:libraryCatalog>
        <dc:subject>
           <dcterms:LCC><rdf:value>QA76.73.S67 F376 2006</rdf:value></dcterms:LCC>
        </dc:subject>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9780970601988">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Oakland, Calif</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Analytics Press</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Few</foaf:surname>
                        <foaf:givenname>Stephen</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Datenanalyse</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Datenauswertung</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Graphische Darstellung</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Information visualization</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Quantitative research</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>statistics</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Statistik</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:title>Now you see it: simple visualization techniques for quantitative analysis</dc:title>
        <dc:date>2009</dc:date>
        <z:numPages>327</z:numPages>
        <dc:identifier>ISBN 9780970601988</dc:identifier>
        <z:shortTitle>Now you see it</z:shortTitle>
        <z:libraryCatalog>Library of Congress ISBN</z:libraryCatalog>
        <dc:subject>
           <dcterms:LCC><rdf:value>TK7882.I6 F48 2009</rdf:value></dcterms:LCC>
        </dc:subject>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:0961392126">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Cheshire, Conn</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Graphics Press</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Tufte</foaf:surname>
                        <foaf:givenname>Edward R.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>visual communication</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:title>Visual explanations: images and quantities, evidence and narrative</dc:title>
        <dc:date>1997</dc:date>
        <z:numPages>156</z:numPages>
        <dc:identifier>ISBN 0961392126</dc:identifier>
        <z:shortTitle>Visual explanations</z:shortTitle>
        <z:libraryCatalog>Library of Congress ISBN</z:libraryCatalog>
        <dc:subject>
           <dcterms:LCC><rdf:value>P93.5 .T846 1997</rdf:value></dcterms:LCC>
        </dc:subject>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9780596802356%20%200596802358">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Sebastopol, CA</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Janert</foaf:surname>
                        <foaf:givenname>Philipp K</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_131"/>
        <dc:title>Data analysis with open source tools</dc:title>
        <dcterms:abstract>Provides information on the techniques of data analysis using a variety of open source tools.</dcterms:abstract>
        <dc:date>2011</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9780596802356  0596802358</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <z:Attachment rdf:about="#item_131">
        <z:itemType>attachment</z:itemType>
        <dc:title>Data Analysis With Open Source Tools - Philipp K. Janert.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Book rdf:about="urn:isbn:9780123851260">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Burlington, MA</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Morgan Kaufmann/Elsevier</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Tupper</foaf:surname>
                        <foaf:givenname>Charles</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Data structures (Computer science)</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Software architecture</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:title>Data architecture: from zen to reality</dc:title>
        <dc:date>2011</dc:date>
        <z:numPages>417</z:numPages>
        <dc:identifier>ISBN 9780123851260</dc:identifier>
        <z:shortTitle>Data architecture</z:shortTitle>
        <z:libraryCatalog>Library of Congress ISBN</z:libraryCatalog>
        <dc:subject>
           <dcterms:LCC><rdf:value>QA76.9.D35 T85 2011</rdf:value></dcterms:LCC>
        </dc:subject>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:0195168364">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>New York</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Oxford University Press</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:contributors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lehmann</foaf:surname>
                        <foaf:givenname>Bruce Neal</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:contributors>
        <dc:subject>
           <z:AutomaticTag><rdf:value>finance</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:title>The legacy of Fischer Black</dc:title>
        <dc:date>2005</dc:date>
        <z:numPages>306</z:numPages>
        <dc:identifier>ISBN 0195168364</dc:identifier>
        <z:libraryCatalog>Library of Congress ISBN</z:libraryCatalog>
        <dc:subject>
           <dcterms:LCC><rdf:value>HG63 .L44 2005</rdf:value></dcterms:LCC>
        </dc:subject>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:0393310728">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>New York</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Norton</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Huff</foaf:surname>
                        <foaf:givenname>Darrell</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>
           <z:AutomaticTag><rdf:value>statistics</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:title>How to lie with statistics</dc:title>
        <dc:date>1993</dc:date>
        <z:numPages>142</z:numPages>
        <dc:identifier>ISBN 0393310728</dc:identifier>
        <z:libraryCatalog>Library of Congress ISBN</z:libraryCatalog>
        <dc:subject>
           <dcterms:LCC><rdf:value>HA29 .H82 1993</rdf:value></dcterms:LCC>
        </dc:subject>
    </bib:Book>
    <bib:Data rdf:about="https://github.com/hadley/lubridate">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Wickham</foaf:surname>
                        <foaf:givenname>Hadley</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>lubridate</dc:title>
        <dcterms:abstract>lubridate - Make working with dates in R just that little bit easier</dcterms:abstract>
        <dc:date>12:59:04</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/hadley/lubridate</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-01 12:59:04</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Book rdf:about="urn:isbn:9780956817204%20%200956817203">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Leeds</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Decisionone Press</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Corr</foaf:surname>
                        <foaf:givenname>Lawrence</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Stagnitto</foaf:surname>
                        <foaf:givenname>Jim</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Agile data warehouse design: collaborative dimensional modeling, from whiteboard to star schema</dc:title>
        <dc:date>2012</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9780956817204  0956817203</dc:identifier>
        <z:shortTitle>Agile data warehouse design</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Data rdf:about="https://github.com/hadley/plyr">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Wickham</foaf:surname>
                        <foaf:givenname>Hadley</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>plyr</dc:title>
        <dcterms:abstract>plyr - A R package for splitting, applying and combining large problems into simpler problems</dcterms:abstract>
        <dc:date>12:59:18</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/hadley/plyr</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-01 12:59:18</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Book rdf:about="urn:isbn:1449326269%209781449326265">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>[S.l.]</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly Media</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Jurney</foaf:surname>
                        <foaf:givenname>Russell</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Agile Data Science: Building Data Analytics Applications with Hadoop</dc:title>
        <dc:date>2012</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 1449326269 9781449326265</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Data rdf:about="http://ggplot2.org/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Wickham</foaf:surname>
                        <foaf:givenname>Hadley</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>ggplot2</dc:title>
        <dcterms:abstract>ggplot2 is a plotting system for R, based on the grammar of graphics, which tries to take the good parts of base and lattice graphics and none of the bad parts.</dcterms:abstract>
        <dc:date>12:59:38</dc:date>
        <dc:identifier>
           <dcterms:URI><rdf:value>http://ggplot2.org/</rdf:value></dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-01 12:59:38</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/o/simmetrica">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Üngür</foaf:surname>
                        <foaf:givenname>Osman</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Simmetrica</dc:title>
        <dcterms:abstract>simmetrica - Lightweight framework for collecting and aggregating event metrics as timeseries data</dcterms:abstract>
        <dc:date>11:12:53</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/o/simmetrica</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-27 11:12:53</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Document rdf:about="http://blogs.hbr.org/2013/03/the-question-all-smart-visualizations/">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
            <z:Blog>
               <dc:title>HBR Blog Network - Harvard Business Review</dc:title>
            </z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Schrage</foaf:surname>
                        <foaf:givenname>Michael</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>
           <z:AutomaticTag><rdf:value>accounting</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>business management articles resources</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
                <rdf:value>business resources books articles case studies</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>communication</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>entrepreneurship</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>execution</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>finance</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Harvard Business School Publishing</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>HBO</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>HBP</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>HBR</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>HBSP</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>innovation</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>international global business strategy</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>leadership</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>managing people</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>operations</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>organizational development</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>technology</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:title>The Question All Smart Visualizations Should Ask</dc:title>
        <dcterms:abstract>Surprisingly, it's not, &quot;What's the best and most accessible way of presenting the data?&quot;</dcterms:abstract>
        <dc:date>11:15:19</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://blogs.hbr.org/2013/03/the-question-all-smart-visualizations/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-27 11:15:19</dcterms:dateSubmitted>
    </bib:Document>
    <bib:Document rdf:about="http://blog.mashape.com/post/48074869493/list-of-40-machine-learning-apis">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog><dc:title>Mashape's Voice</dc:title></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Mashape</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>
           <z:AutomaticTag><rdf:value>analysis</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>api</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>artificial intelligence</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>processing</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>recognition</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:title>List of 40+ Machine Learning APIs</dc:title>
        <dcterms:abstract>//
Wikipedia defines Machine Learning as “a branch of artificial intelligence that deals with the construction and study of systems that can learn from data.”
(If you arrived here looking how to add...</dcterms:abstract>
        <dc:date>11:16:40</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://blog.mashape.com/post/48074869493/list-of-40-machine-learning-apis</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-27 11:16:40</dcterms:dateSubmitted>
    </bib:Document>
    <bib:Document rdf:about="http://blogs.hbr.org/2013/03/when-presenting-your-data-get/">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
            <z:Blog>
               <dc:title>HBR Blog Network - Harvard Business Review</dc:title>
            </z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Duarte</foaf:surname>
                        <foaf:givenname>Nancy</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>presentation</dc:subject>
        <dc:title>When Presenting Your Data, Get to the Point Fast</dc:title>
        <dcterms:abstract>Focus on the meaning behind the numbers.</dcterms:abstract>
        <dc:date>11:18:43</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://blogs.hbr.org/2013/03/when-presenting-your-data-get/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-27 11:18:43</dcterms:dateSubmitted>
    </bib:Document>
    <bib:Article rdf:about="http://www.forbes.com/sites/oracle/2013/04/22/why-business-leaders-must-master-data-and-analytics/">
        <z:itemType>magazineArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Periodical><dc:title>Forbes</dc:title></bib:Periodical>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Clayton</foaf:surname>
                        <foaf:givenname>Rich</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Erik Brynjolfsson</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Facebook</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Tech</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>United States</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:title>Why Business Leaders Must Master Data And Analytics</dc:title>
        <dcterms:abstract>(Photo credit: IntelFreePress) By Rich Clayton, Vice President of Business Analytics, Oracle There’s a war on talent.  The explosion of data in the digital universe is creating a skill gap and is opening up many new career opportunities in management.  A recent study from McKinsey Global Institute estimates that the United States [...]</dcterms:abstract>
        <dc:date>11:19:55</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.forbes.com/sites/oracle/2013/04/22/why-business-leaders-must-master-data-and-analytics/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-27 11:19:55</dcterms:dateSubmitted>
    </bib:Article>
    <bib:Book rdf:about="urn:isbn:0201433230%209780201433234">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Reading, Mass.</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Addison-Wesley</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Britcher</foaf:surname>
                        <foaf:givenname>Robert N</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>The limits of software: people, projects, and perspectives</dc:title>
        <dcterms:abstract>&quot;Looking at the current software development environment, The Limits of Software explores how technology changes methods and how today's market demands affect software development. This book also examines the many forces behind the current push for the development of the &quot;one great system.&quot;&quot;--BOOK JACKET. &quot;In this extraordinary book, Britcher offers a long-standing insider's perspective on the past and present of the computer industry, complete with its many foibles and achievements. He looks to the future with both optimism and trepidation, hoping that the industry can accomplish real gains while reaching for worthwhile goals.&quot;--BOOK JACKET.</dcterms:abstract>
        <dc:date>1999</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 0201433230 9780201433234</dc:identifier>
        <z:shortTitle>The limits of software</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:0321934504%209780321934505">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>[S.l.]</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Addison-Wesley</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Murthy</foaf:surname>
                        <foaf:givenname>Arun</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Apache hadoop yarn: moving beyond mapreduce and batch processing with apache</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 0321934504 9780321934505</dc:identifier>
        <z:shortTitle>Apache hadoop yarn</z:shortTitle>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://my.safaribooksonline.com/9780133441925</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:1617290394%209781617290398">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>[S.l.]</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly Media</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Wood</foaf:surname>
                        <foaf:givenname>David</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_162"/>
        <dc:title>Linked data</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 1617290394 9781617290398</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://www.manning.com/dwood/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <z:Attachment rdf:about="#item_162">
        <z:itemType>attachment</z:itemType>
        <dc:title>Linked Data - David Wood.epub</dc:title>
        <link:type>application/octet-stream</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://iopscience.iop.org/0266-5611/27/12/120201">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf rdf:resource="urn:issn:0266-5611"/>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Epstein</foaf:surname>
                        <foaf:givenname>Charles</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Carlsson</foaf:surname>
                        <foaf:givenname>Gunnar</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Edelsbrunner</foaf:surname>
                        <foaf:givenname>Herbert</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_1270"/>
        <dc:title>Topological data analysis</dc:title>
        <dcterms:abstract>Inverse problems can be defined as the area of mathematics that attempts to reconstruct a physical or mathematical object from derived data. Frequently, this means the evaluation of parameters or other numerical quantities (such as eigenvalues) that characterize or provide information about the system. There are, however, other aspects of a system that are important, but are not as readily summarized by numerical quantities. If one considers observations of diabetic patients (using metabolic quantities), one will find that the data breaks up into components, or pieces, corresponding to distinct forms of the disease. The decomposition of data sets into disjoint pieces, or clustering, is an aspect of the study of the shape of the data, albeit one that has been extensively studied. A more complex notion of shape appears in observations of a predator–prey system governed by a Lotka–Volterra equation. One would find that exact observations, consisting of (prey population, predator population) pairs, appear to lie along a simple closed curve in the plane. The fact that the data lies along such a closed curve is an important piece of information, since it suggests that the system displays recurrent behavior. If one did not know, a priori, that the system is governed by a Lotka–Volterra equation, then it would not be immediately obvious that the system is undergoing recurrent motion, and this deduction would constitute a significant insight. In this case, it is again the shape of the data, namely the fact that it lies on a simple closed curve, which is the key insight. Shape is a somewhat nebulous concept, which at first blush may be too intuitive to make precise mathematically, and describe quantitatively. Within pure mathematics, the disciplines of topology and differential geometry are designed exactly to address this problem. They provide explicit signatures which, in precise senses, quantify and describe the shape of a geometric object. In addition, they provide methods for discretizing and compressing the information present in a geometric object so as to provide a useful, small representation of the object. The articles in this special issue are concerned with the applications of topology to the analysis of data sets. The adaptation of topological techniques from pure mathematics to the study of data from real systems is a project which has been undertaken during the past two decades, and the present volume contains various contributions to that project. At the current state of development, homology and persistence are two of the most popular topological techniques used in this context. Homology goes back to the beginnings of topology in Poincaré's influential papers. It is the idea that the connectivity of a space is determined by its cycles of different dimensions, and that these cycles organize themselves into abelian groups, called homology groups. Better known than these groups are their ranks, the Betti numbers of the space, which are non-negative integers that count the number of independent cycles in each dimension. To give an example, the zeroth Betti number counts the components, and the first counts the loops. A crucial feature of homology groups is that, given a reasonably explicit description of a space, their computation is an exercise in linear algebra. Even better known than the Betti numbers is the Euler characteristic, which we know from Poincaré's work, is equal to the alternating sum of the Betti numbers, which can be computed without computing the homology groups themselves. To give evidence that these numbers have relevant practical applications, we mention that integrating the Euler characteristic over a domain with sensor information can be used to count objects in the domain. This alone would not explain the popularity of homology groups, which we see rooted in the fact that they hit a sweet-spot that offers relatively strong discriminative power, and a clear intuitive meaning, all at a surprisingly low computational cost. Even these desirable qualities would not be sufficient if it were not possible to overcome a serious shortcoming, namely the high sensitivity of homology to minor mistakes in the data collection. Because of the finite nature of most data sets, the notion of shape within data sets is inevitably stochastic. To some extent this is because of the uncertainty of what a shape in nature is, but more importantly, the available data can only be used to give an estimate for the probability of a given shape. This has led to the study of persistent homology, in which the invariants are in the form of 'persistence diagrams' or 'barcodes'. These invariants quantify the stability of geometric features with respect to perturbations that, in turn, provide a basis for discriminating between artifacts caused by noise or undersampling and real phenomena. Several papers in this volume deal with questions about these diagrams, and some deal with probabilistic issues related to the occurrence of these diagrams. Our hope is that the papers in this volume will provide exposure of these techniques to both a wider audience of mathematicians and also potential users of the techniques.</dcterms:abstract>
        <bib:pages>120201</bib:pages>
        <dc:date>2011-12-01</dc:date>
        <z:language>en</z:language>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://iopscience.iop.org/0266-5611/27/12/120201</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-01 13:00:35</dcterms:dateSubmitted>
        <z:libraryCatalog>Institute of Physics</z:libraryCatalog>
    </bib:Article>
    <bib:Journal rdf:about="urn:issn:0266-5611">
        <dc:title>Inverse Problems</dc:title>
        <prism:volume>27</prism:volume>
        <prism:number>12</prism:number>
        <dcterms:alternative>Inverse Problems</dcterms:alternative>
        <dc:identifier>DOI 10.1088/0266-5611/27/12/120201</dc:identifier>
        <dc:identifier>ISSN 0266-5611</dc:identifier>
    </bib:Journal>
    <z:Attachment rdf:about="#item_1270">
        <z:itemType>attachment</z:itemType>
        <dc:title>Epstein_et_al_2011_Topological_data_analysis2.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Data rdf:about="https://pypi.python.org/pypi/beautifulsoup4">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Richardson</foaf:surname>
                        <foaf:givenname>Leonard</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Beautiful Soup</dc:title>
        <dc:date>06:51:03</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://pypi.python.org/pypi/beautifulsoup4</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-02 06:51:03</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Article rdf:about="http://www.ams.org/journals/bull/2009-46-02/S0273-0979-09-01249-X/">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
                <dc:title>Bulletin of the American Mathematical Society</dc:title>
                <prism:volume>46</prism:volume>
                <prism:number>2</prism:number>
            </bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Carlsson</foaf:surname>
                        <foaf:givenname>Gunnar</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_203"/>
        <dc:title>Topology and data</dc:title>
        <bib:pages>255–308</bib:pages>
        <dc:date>2009</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.ams.org/journals/bull/2009-46-02/S0273-0979-09-01249-X/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-01 13:01:39</dcterms:dateSubmitted>
        <z:libraryCatalog>Google Scholar</z:libraryCatalog>
    </bib:Article>
    <z:Attachment rdf:about="#item_203">
        <z:itemType>attachment</z:itemType>
        <dc:title>Carlsson_2009_Topology_and_data.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Document rdf:about="https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers">
        <z:itemType>webpage</z:itemType>
        <dcterms:isPartOf>
           <z:Website><dc:title>GitHub</dc:title></z:Website>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Davidson-Pilon</foaf:surname>
                        <foaf:givenname>Cameron</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_34"/>
        <dc:title>Probabilistic Programming and Bayesian Methods for Hackers</dc:title>
        <dcterms:abstract>Probabilistic-Programming-and-Bayesian-Methods-for-Hackers - aka &quot;Bayesian Methods for Hackers&quot;: An introduction to Bayesian methods + probabilistic programming with a computation/understanding-first, mathematics-second point of view. All in pure Python ;)</dcterms:abstract>
        <dc:date>07:20:43</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-02 07:20:43</dcterms:dateSubmitted>
    </bib:Document>
    <z:Attachment rdf:about="#item_34">
        <z:itemType>attachment</z:itemType>
        <dc:title>Probabilistic Programming &amp; Bay - Cameron Davidson-Pilon.azw3</dc:title>
        <link:type>application/octet-stream</link:type>
    </z:Attachment>
    <bib:Document rdf:about="http://www.infoq.com/articles/cap-twelve-years-later-how-the-rules-have-changed">
        <z:itemType>webpage</z:itemType>
        <dcterms:isPartOf>
           <z:Website></z:Website>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Brewer</foaf:surname>
                        <foaf:givenname>Eric</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_30"/>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Architecture</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Architecture &amp; Design</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Availability</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>CAP Theorem</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
                <rdf:value>cap twelve years later how the rules have changed</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Consistency</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Data Partitioning</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>database</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Development</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Enterprise Architecture</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>NoSQL</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Operations &amp; Infrastructure</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Partitioning</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Performance</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Relational Databases</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Scalability</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:title>CAP Twelve Years Later: How the &quot;Rules&quot; Have Changed</dc:title>
        <dcterms:abstract>The CAP theorem asserts that any networked shared-data system can have only two of three desirable properties (Consistency, Availability and Partition Tolerance). In this IEEE article, author Eric Brewer discusses how designers can optimize consistency and availability by explicitly handling partitions, thereby achieving some trade-off of all three.</dcterms:abstract>
        <dc:date>07:23:39</dc:date>
        <z:shortTitle>CAP Twelve Years Later</z:shortTitle>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.infoq.com/articles/cap-twelve-years-later-how-the-rules-have-changed</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-02 07:23:39</dcterms:dateSubmitted>
    </bib:Document>
    <z:Attachment rdf:about="#item_30">
        <z:itemType>attachment</z:itemType>
        <dc:title>CAP Twelve Years Later_ How the - Eric Brewer.azw3</dc:title>
        <link:type>application/octet-stream</link:type>
    </z:Attachment>
    <bib:Data rdf:about="https://github.com/square/crossfilter">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Square</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Crossfilter</dc:title>
        <dcterms:abstract>crossfilter - Fast n-dimensional filtering and grouping of records.</dcterms:abstract>
        <dc:date>07:29:25</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/square/crossfilter</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-02 07:29:25</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Document rdf:about="http://blogs.hbr.org/2013/04/data-analysis-should-be-a-soci/">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog><dc:title>Harvard Business Review</dc:title></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Bayer</foaf:surname>
                        <foaf:givenname>Judy</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Taillard</foaf:surname>
                        <foaf:givenname>Marie</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>
           <z:AutomaticTag><rdf:value>accounting</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>business management articles resources</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
                <rdf:value>business resources books articles case studies</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>communication</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>entrepreneurship</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>execution</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>finance</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Harvard Business School Publishing</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>HBO</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>HBP</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>HBR</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>HBSP</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>innovation</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>international global business strategy</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>leadership</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>managing people</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>operations</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>organizational development</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>technology</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:title>Data Analysis Should Be a Social Event</dc:title>
        <dcterms:abstract>How working co-creatively can transform your businesses.</dcterms:abstract>
        <dc:date>07:33:18</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://blogs.hbr.org/2013/04/data-analysis-should-be-a-soci/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-02 07:33:18</dcterms:dateSubmitted>
    </bib:Document>
    <bib:Data rdf:about="https://github.com/tinkerpop/gremlin">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>TinkerPop</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Gremlin</dc:title>
        <dcterms:abstract>gremlin - A Graph Traversal Language</dcterms:abstract>
        <dc:date>14:30:37</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/tinkerpop/gremlin</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-02 14:30:37</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Document rdf:about="http://strata.oreilly.com/2013/04/datas-missing-ingredient-rhetoric.html">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Shron</foaf:surname>
                        <foaf:givenname>Max</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>
           <z:AutomaticTag><rdf:value>data</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>data science</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>data scientists</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:title>Data's missing ingredient? Rhetoric. - Strata</dc:title>
        <dcterms:abstract>Data is key to decision making. Yet we are rarely faced with a situation where things can be put in to such a clear logical form that we have...</dcterms:abstract>
        <dc:date>07:39:42</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://strata.oreilly.com/2013/04/datas-missing-ingredient-rhetoric.html</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-02 07:39:42</dcterms:dateSubmitted>
        <z:shortTitle>Data’s missing ingredient?</z:shortTitle>
    </bib:Document>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/amywtang/building-a-realtime-data-pipeline-apache-kafka-at-linked-in">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Koshy</foaf:surname>
                        <foaf:givenname>Joel</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <dc:title>Building a Real-Time Data Pipeline: Apache Kafka at LinkedIn</dc:title>
        <dcterms:abstract>This talk was given by Joel Koshy (Senior Software Engineer at LinkedIn) at the Hadoop Summit (June 2013).</dcterms:abstract>
        <z:type>Technology</z:type>
        <dc:date>Tue Jul 02  2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/amywtang/building-a-realtime-data-pipeline-apache-kafka-at-linked-in</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-28 00:39:26</dcterms:dateSubmitted>
        <z:shortTitle>Building a Real-Time Data Pipeline</z:shortTitle>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <bib:Data rdf:about="http://www.neo4j.org/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Neo Technology</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Neo4j</dc:title>
        <dc:date>14:31:40</dc:date>
        <dc:identifier>
           <dcterms:URI><rdf:value>http://www.neo4j.org/</rdf:value></dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-02 14:31:40</dcterms:dateSubmitted>
    </bib:Data>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/amywtang/webscale-analyticsfb-24031929">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Rao</foaf:surname>
                        <foaf:givenname>Jun</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Shah</foaf:surname>
                        <foaf:givenname>Sam</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <dc:title>Data Infrastructure at LinkedIn</dc:title>
        <dcterms:abstract>This talk was given by Jun Rao (Staff Software Engineer at LinkedIn) and Sam Shah (Senior Engineering Manager at LinkedIn) at the Analytics@Webscale Technical Conference (June 2013).</dcterms:abstract>
        <z:type>Technology</z:type>
        <dc:date>Mon Jul 08  2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/amywtang/webscale-analyticsfb-24031929</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-28 00:40:24</dcterms:dateSubmitted>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/dtunkelang/find-and-be-found-information-retrieval-at-linked-in">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Daniel Tunkelang</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <link:link rdf:resource="#item_371"/>
        <dc:title>Find and be Found: Information Retrieval at LinkedIn</dc:title>
        <dcterms:abstract>Find and Be Found: Information Retrieval at LinkedIn

SIGIR 2013 Industry Track Presentation
http://sigir2013.ie/industry_track.html

LinkedIn has a unique data collection: the 200M+ members who use LinkedIn are also the most valuable entities in our corpus, which consists of people, companies, jobs, and a rich content ecosystem. Our members use LinkedIn to satisfy a diverse set of navigational and exploratory information needs, which we address by leveraging semi-structured and social content to understanding their query intent and deliver a personalized search experience. In this talk, we will discuss some of the unique challenges we face in building the LinkedIn search platform, the solutions we've developed so far, and the open problems we see ahead of us.

Shakti Sinha heads LinkedIn's search relevance team, and has been making key contributions to LinkedIn's search products since 2010. He previously worked at Google as both a research intern and a software engineer. He has an MS in Computer Science from Stanford, as well as a BS degree from College of Engineering, Pune.

Daniel Tunkelang leads LinkedIn's efforts around query understanding. Before that, he led LinkedIn's product data science team. He previously led a local search quality team at Google and was a founding employee of Endeca (acquired by Oracle in 2011). He has written a textbook on faceted search, and is a recognized advocate of human-computer interaction and information retrieval (HCIR). He has a PhD in Computer Science from CMU, as well as BS and MS degrees from MIT.</dcterms:abstract>
        <z:type>Technology</z:type>
        <dc:date>Wed Jul 31  2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/dtunkelang/find-and-be-found-information-retrieval-at-linked-in</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-02 14:56:17</dcterms:dateSubmitted>
        <z:shortTitle>Find and be Found</z:shortTitle>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <z:Attachment rdf:about="#item_371">
        <z:itemType>attachment</z:itemType>
        <dc:title>Daniel_Tunkelang_2013_Find_and_be_Found.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Data rdf:about="https://github.com/linkedin/databus">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>LinkedIn</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Databus</dc:title>
        <dcterms:abstract>databus - Source-agnostic distributed change data capture system</dcterms:abstract>
        <dc:date>00:42:03</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/linkedin/databus</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-28 00:42:03</dcterms:dateSubmitted>
    </bib:Data>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/amywtang/helix-socc-v10final-16247096">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Gopalakrishna</foaf:surname>
                        <foaf:givenname>Kishore</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <link:link rdf:resource="#item_422"/>
        <dc:title>Untangling Cluster Management with Helix</dc:title>
        <dcterms:abstract>This talk was given by Kishore Gopalakrishna (Staff Software Engineer @ LinkedIn) at the 3rd ACM Symposium on Cloud Computing (SOCC 2012).</dcterms:abstract>
        <dc:date>Tue Jan 29  2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/amywtang/helix-socc-v10final-16247096</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-09-28 00:58:30</dcterms:dateSubmitted>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <z:Attachment rdf:about="#item_422">
        <z:itemType>attachment</z:itemType>
        <dc:title>Gopalakrishna_2013_Untangling_Cluster_Management_with_Helix.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Document rdf:about="http://corsoftlimited.blogspot.co.uk/2013/02/complex-event-processing-made-easy.html">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Milne</foaf:surname>
                        <foaf:givenname>Adrian</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>dispatches from the codeface: Complex Event Processing Made Easy (using Esper)</dc:title>
        <dc:date>20:57:20</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://corsoftlimited.blogspot.co.uk/2013/02/complex-event-processing-made-easy.html</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-03 20:57:20</dcterms:dateSubmitted>
    </bib:Document>
    <rdf:Description rdf:about="http://dl.acm.org/citation.cfm?id=2463707">
        <z:itemType>conferencePaper</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Sumbaly</foaf:surname>
                        <foaf:givenname>Roshan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kreps</foaf:surname>
                        <foaf:givenname>Jay</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Shah</foaf:surname>
                        <foaf:givenname>Sam</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_227"/>
        <dc:title>The big data ecosystem at LinkedIn</dc:title>
        <dc:date>2013</dc:date>
        <bib:pages>1125–1134</bib:pages>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://dl.acm.org/citation.cfm?id=2463707</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-02 14:59:25</dcterms:dateSubmitted>
        <z:libraryCatalog>Google Scholar</z:libraryCatalog>
    </rdf:Description>
    <z:Attachment rdf:about="#item_227">
        <z:itemType>attachment</z:itemType>
        <dc:title>Sumbaly_et_al_2013_The_big_data_ecosystem_at_LinkedIn.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Book rdf:about="urn:isbn:9780071808170">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
               <foaf:name>McGraw Hill Professional</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Zikopoulos</foaf:surname>
                        <foaf:givenname>Paul</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>deRoos</foaf:surname>
                        <foaf:givenname>Dirk</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Parasuraman</foaf:surname>
                        <foaf:givenname>Krishnan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Deutsch</foaf:surname>
                        <foaf:givenname>Thomas</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Giles</foaf:surname>
                        <foaf:givenname>James</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Corrigan</foaf:surname>
                        <foaf:givenname>David</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computers / Databases / Data Warehousing</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:title>Harness the Power of Big Data The IBM Big Data Platform</dc:title>
        <dcterms:abstract>Boost your Big Data IQ! Gain insight into how to govern and consume IBM’s unique in-motion and at-rest Big Data analytic capabilities Big Data represents a new era of computing—an inflection point of opportunity where data in any format may be explored and utilized for breakthrough insights—whether that data is in-place, in-motion, or at-rest. IBM is uniquely positioned to help clients navigate this transformation. This book reveals how IBM is infusing open source Big Data technologies with IBM innovation that manifest in a platform capable of &quot;changing the game.&quot; The four defining characteristics of Big Data—volume, variety, velocity, and veracity—are discussed. You’ll understand how IBM is fully committed to Hadoop and integrating it into the enterprise. Hear about how organizations are taking inventories of their existing Big Data assets, with search capabilities that help organizations discover what they could already know, and extend their reach into new data territories for unprecedented model accuracy and discovery. In this book you will also learn not just about the technologies that make up the IBM Big Data platform, but when to leverage its purpose-built engines for analytics on data in-motion and data at-rest. And you’ll gain an understanding of how and when to govern Big Data, and how IBM’s industry-leading InfoSphere integration and governance portfolio helps you understand, govern, and effectively utilize Big Data. Industry use cases are also included in this practical guide.</dcterms:abstract>
        <dc:date>2012-10-18</dc:date>
        <z:numPages>282</z:numPages>
        <z:language>en</z:language>
        <dc:identifier>ISBN 9780071808170</dc:identifier>
        <z:libraryCatalog>Google Books</z:libraryCatalog>
    </bib:Book>
    <bib:Data rdf:about="https://github.com/kaigai/pg_strom">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kohei</foaf:surname>
                        <foaf:givenname>KaiGai</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>pg_strom</dc:title>
        <dcterms:abstract>pg_strom - FDW module of PostgreSQL using GPU for Asynchronous Super-Parallel Query Execution</dcterms:abstract>
        <dc:date>16:29:15</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/kaigai/pg_strom</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 16:29:15</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/cloudera/hue">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Cloudera</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Hue</dc:title>
        <dcterms:abstract>hue - Hue is a Web application for interacting with Apache Hadoop. It supports a file browser, job tracker interface, Hive, Pig, Impala, Oozie, HBase, Solr, Sqoop2, ZooKeeper and more.</dcterms:abstract>
        <dc:date>16:36:31</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/cloudera/hue</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 16:36:31</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/scikit-learn/scikit-learn">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Mueller</foaf:surname>
                        <foaf:givenname>Andreas</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>scikit-learn</dc:title>
        <dcterms:abstract>scikit-learn: machine learning in Python</dcterms:abstract>
        <dc:date>16:38:52</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/scikit-learn/scikit-learn</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 16:38:52</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/precog/platform">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>SlamData</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>scala</dc:subject>
        <dc:title>Precog Platform</dc:title>
        <dcterms:abstract>platform - Advanced Analytics Engine for NoSQL Data</dcterms:abstract>
        <dc:date>16:43:01</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/precog/platform</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 16:43:01</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/vertica/Vertica-Extension-Packages">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Vertica</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Vertica Avro Parser</dc:title>
        <dcterms:abstract>Vertica-Extension-Packages - User Defined Extensions to the Vertica Analytic Database</dcterms:abstract>
        <dc:date>17:05:31</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://github.com/vertica/Vertica-Extension-Packages</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 17:05:31</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Document rdf:about="http://www.bnosac.be/index.php/blog/26-massive-online-data-stream-mining-with-r">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>BNOSAC</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Massive online data stream mining with R</dc:title>
        <dc:date>19:49:04</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.bnosac.be/index.php/blog/26-massive-online-data-stream-mining-with-r</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 19:49:04</dcterms:dateSubmitted>
    </bib:Document>
    <bib:Document rdf:about="http://db-engines.com/en/ranking">
        <z:itemType>webpage</z:itemType>
        <dcterms:isPartOf>
           <z:Website></z:Website>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Solid IT</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>DB-Engines Ranking</dc:title>
        <dcterms:abstract>popularity ranking of database management systems</dcterms:abstract>
        <dc:date>17:25:54</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://db-engines.com/en/ranking</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 17:25:54</dcterms:dateSubmitted>
    </bib:Document>
    <bib:Data rdf:about="https://github.com/strathausen/dracula">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Strathausen</foaf:surname>
                        <foaf:givenname>Johann Philipp</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Graph Dracula</dc:title>
        <dcterms:abstract>dracula - JavaScript browser based layout and representation of connected graphs.</dcterms:abstract>
        <dc:date>17:41:23</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/strathausen/dracula</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 17:41:23</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Document rdf:about="http://metamarkets.com/2012/fast-cheap-and-98-right-cardinality-estimation-for-big-data/">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog><dc:title>Metamarkets</dc:title></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Yang</foaf:surname>
                        <foaf:givenname>Fangjin</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>approximation algorithms</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>cardinality estimation</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>druid</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:title>Fast, Cheap, and 98% Right: Cardinality Estimation for Big Data</dc:title>
        <dcterms:abstract>The nascent era of big data brings new challenges, which in turn require new tools and algorithms. At Metamarkets, one such challenge focuses on cardinality estimation: efficiently determining the number of distinct elements within a dimension of a large-scale data set. Cardinality estimations have a wide range of applications from monitoring network traffic to data mining. If leveraged correctly, these algorithms can also be used to provide insights into user engagement and growth, via metrics such as “daily active users.” The HyperLogLog Algorithm:  Every Bit is Great It is well known that the cardinality of a large data set can be precisely calculated if the storage complexity is proportional to the number of elements in the data set. However, given the scale and complexity of some Druid data sets (with record counts routinely in the billions), the data ensemble is often far too large to be kept in core memory. Furthermore, because Druid data sets can [...]</dcterms:abstract>
        <dc:date>17:50:04</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://metamarkets.com/2012/fast-cheap-and-98-right-cardinality-estimation-for-big-data/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 17:50:04</dcterms:dateSubmitted>
        <z:shortTitle>Fast, Cheap, and 98% Right</z:shortTitle>
    </bib:Document>
    <rdf:Description rdf:about="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5693297">
        <z:itemType>conferencePaper</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Neumeyer</foaf:surname>
                        <foaf:givenname>Leonardo</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Robbins</foaf:surname>
                        <foaf:givenname>Bruce</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Nair</foaf:surname>
                        <foaf:givenname>Anish</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kesari</foaf:surname>
                        <foaf:givenname>Anand</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_177"/>
        <dc:title>S4: Distributed stream computing platform</dc:title>
        <dc:date>2010</dc:date>
        <bib:pages>170–177</bib:pages>
        <z:shortTitle>S4</z:shortTitle>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5693297</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 17:57:39</dcterms:dateSubmitted>
        <z:libraryCatalog>Google Scholar</z:libraryCatalog>
    </rdf:Description>
    <z:Attachment rdf:about="#item_177">
        <z:itemType>attachment</z:itemType>
        <dc:title>Neumeyer_et_al_2010_S4.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Data rdf:about="http://incubator.apache.org/s4/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Apache Software Foundation</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Apache S4</dc:title>
        <dcterms:abstract>Distributed stream computing platform</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://incubator.apache.org/s4/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/Netflix/genie">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Netflix</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Genie</dc:title>
        <dcterms:abstract>genie - Hadoop Platform as a Service</dcterms:abstract>
        <dc:date>18:16:09</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/Netflix/genie</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 18:16:09</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/discoproject/disco">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Disco Project</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Disco</dc:title>
        <dcterms:abstract>disco - a Map/Reduce framework for distributed computing</dcterms:abstract>
        <dc:date>18:30:30</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/discoproject/disco</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 18:30:30</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Document rdf:about="http://mechanicalscribe.com/notes/binify-d3-topojson-tutorial/">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Wilson</foaf:surname>
                        <foaf:givenname>Chris</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>d3</dc:subject>
        <dc:title>Binify + D3 = Gorgeous honeycomb maps</dc:title>
        <dc:date>19:50:23</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://mechanicalscribe.com/notes/binify-d3-topojson-tutorial/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 19:50:23</dcterms:dateSubmitted>
    </bib:Document>
    <bib:Data rdf:about="https://github.com/msgpack/msgpack">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Furuhashi</foaf:surname>
                        <foaf:givenname>Sadayuki</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>MessagePack</dc:title>
        <dcterms:abstract>This issue continues the discussion that started in this issue, which has grown interminably long.

Here is the link to @frsyuki's proposed spec circa Feb. 24, 2013
Here is to a fruitful, invigorating, productive thread! Hooray chums!</dcterms:abstract>
        <dc:date>19:52:05</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/msgpack/msgpack</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 19:52:05</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/msgpack/msgpack-hadoop">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Furuhashi</foaf:surname>
                        <foaf:givenname>Sadayuki</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>MessagePack-Hadoop</dc:title>
        <dcterms:abstract>msgpack-hadoop - MessagePack-Hadoop integration provides an efficient schema-free data representation for Hadoop and Hive.</dcterms:abstract>
        <dc:date>19:52:42</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/msgpack/msgpack-hadoop</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 19:52:42</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Book rdf:about="urn:isbn:9781449358624%20%201449358624">
        <z:itemType>book</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Hamstra</foaf:surname>
                        <foaf:givenname>Mark</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Zaharia</foaf:surname>
                        <foaf:givenname>Matei</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Learning Spark: lightning-fast big data analytics</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781449358624  1449358624</dc:identifier>
        <z:shortTitle>Learning Spark</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Data rdf:about="https://github.com/mozilla-metrics/akela">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Mozilla Foundation</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Akela</dc:title>
        <dcterms:abstract>akela - A bunch of utility classes for Java, Hadoop, HBase, Pig, etc.</dcterms:abstract>
        <dc:date>20:06:03</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/mozilla-metrics/akela</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 20:06:03</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/twitter/ambrose">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Twitter</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Ambrose</dc:title>
        <dcterms:abstract>ambrose - A platform for visualization and real-time monitoring of data workflows</dcterms:abstract>
        <dc:date>20:22:28</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/twitter/ambrose</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 20:22:28</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/twitter/elephant-twin">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Twitter</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Elephant Twin</dc:title>
        <dcterms:abstract>elephant-twin - Elephant Twin is a framework for creating indexes in Hadoop</dcterms:abstract>
        <dc:date>20:33:56</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/twitter/elephant-twin</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 20:33:56</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/twitter/hdfs-du">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Twitter</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>d3</dc:subject>
        <dc:title>HDFS-DU</dc:title>
        <dcterms:abstract>hdfs-du - Visualize your HDFS cluster usage</dcterms:abstract>
        <dc:date>20:34:54</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/twitter/hdfs-du</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 20:34:54</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/PatMartin/DexCharts">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Martin</foaf:surname>
                        <foaf:givenname>Patrick</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>d3</dc:subject>
        <dc:title>DexCharts</dc:title>
        <dcterms:abstract>DexCharts - A reusable charting library for D3JS.</dcterms:abstract>
        <dc:date>20:42:14</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/PatMartin/DexCharts</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 20:42:14</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/shutterstock/rickshaw">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Shutterstock</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>d3</dc:subject>
        <dc:title>Rickshaw</dc:title>
        <dcterms:abstract>rickshaw -  JavaScript toolkit for creating interactive real-time graphs</dcterms:abstract>
        <dc:date>20:55:12</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/shutterstock/rickshaw</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 20:55:12</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/projectblacklight/blacklight">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Project Blacklight</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Blacklight</dc:title>
        <dcterms:abstract>blacklight - Blacklight provides a discovery interface for any Solr (http://lucene.apache.org/solr) index.</dcterms:abstract>
        <dc:date>20:57:17</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://github.com/projectblacklight/blacklight</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 20:57:17</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/pymc-devs/pymc">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Fonnesbeck</foaf:surname>
                        <foaf:givenname>Chris</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Patil</foaf:surname>
                        <foaf:givenname>Anand</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Salvatier</foaf:surname>
                        <foaf:givenname>John</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>PyMC</dc:title>
        <dcterms:abstract>pymc - Bayesian inference in Python</dcterms:abstract>
        <dc:date>20:59:34</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/pymc-devs/pymc</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 20:59:34</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Document rdf:about="http://www.r-bloggers.com/python-compliments-rs-shortcomings/">
        <z:itemType>webpage</z:itemType>
        <dcterms:isPartOf>
           <z:Website><dc:title>R-bloggers</dc:title></z:Website>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lemoine</foaf:surname>
                        <foaf:givenname>Nathan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Python Complements R's Shortcomings</dc:title>
        <dcterms:abstract>I’m a big fan of open-source software for research. For example, R-statistics, Qgis, and Grass GIS are awesome programs. R can do any statistical tests and numerical modeling you can imagine; if there’s not a built-in function you can write … Continue reading →</dcterms:abstract>
        <dc:date>21:01:12</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.r-bloggers.com/python-compliments-rs-shortcomings/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 21:01:12</dcterms:dateSubmitted>
    </bib:Document>
    <bib:Data rdf:about="https://github.com/lballabio/quantlib">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ballabio</foaf:surname>
                        <foaf:givenname>Luigi</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>QuantLib</dc:title>
        <dcterms:abstract>quantlib - The QuantLib C++ library and extensions</dcterms:abstract>
        <dc:date>21:03:53</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/lballabio/quantlib</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 21:03:53</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/pentaho/big-data-plugin">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Pentaho</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Pentaho Big Data Plugin</dc:title>
        <dcterms:abstract>big-data-plugin - Kettle plugin that provides support for interacting within many &quot;big data&quot; projects including Hadoop, Hive, HBase, Cassandra, MongoDB, and others.</dcterms:abstract>
        <dc:date>21:06:06</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/pentaho/big-data-plugin</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-04 21:06:06</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Book rdf:about="urn:isbn:9780321573513%20%20032157351X">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Upper Saddle River, NJ</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Addison-Wesley</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Sedgewick</foaf:surname>
                        <foaf:givenname>Robert</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Wayne</foaf:surname>
                        <foaf:givenname>Kevin Daniel</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Algorithms</dc:title>
        <dc:date>2011</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9780321573513  032157351X</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9780071799669%20%200071799664">
        <z:itemType>book</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Fung</foaf:surname>
                        <foaf:givenname>Kaiser</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Numbersense: how to use big data to your advantage</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9780071799669  0071799664</dc:identifier>
        <z:shortTitle>Numbersense</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9781583477182%20%201583477187%20%209781604868074%20%201604868074%20%209781583477465%20%201583477462">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Boise</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>MC Press</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Soares</foaf:surname>
                        <foaf:givenname>Sunil</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Big data governance an emerging imperative</dc:title>
        <dcterms:abstract>Written by a leading expert in the field, this guide focuses on the convergence of two major trends in information managementbig data and information governanceby taking a strategic approach oriented around business cases and industry imperatives. With the advent of new technologies, enterprises are expanding and handling very large volumes of data; this book, nontechnical in nature and geared toward business audiences, encourages the practice of establishing appropriate governance over big data initiatives and addresses how to manage and govern big data, highlighting the relevant processes, procedures, and policies. It teaches readers to understand how big data fits within an overall information governance program; quantify the business value of big data; apply information governance concepts such as stewardship, metadata, and organization structures to big data; appreciate the wide-ranging business benefits for various industries and job functions; sell the value of big data governance to businesses; and establish step-by-step processes to implement big data governance.</dcterms:abstract>
        <dc:date>2012</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781583477182  1583477187  9781604868074  1604868074  9781583477465  1583477462</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://site.ebrary.com/id/10621576</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 11:17:30</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9781466565791%20%201466565799">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Boca Raton, FL</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>CRC Press</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Liebowitz</foaf:surname>
                        <foaf:givenname>Jay</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Big data and business analytics</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781466565791  1466565799</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://search.ebscohost.com/login.aspx?direct=true&amp;scope=site&amp;db=nlebk&amp;db=nlabk&amp;AN=562870</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 11:17:40</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9780124173194%200124173195">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
               <foaf:name>Morgan Kaufmann Pub</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Loshin</foaf:surname>
                        <foaf:givenname>David</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Big Data Analytics From Strategic Planning to Enterprise Integration With Tools, Techniques, Nosql, and Graph.</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9780124173194 0124173195</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:1118589777">
        <z:itemType>book</z:itemType>
        <dc:publisher>
           <foaf:Organization><foaf:name>Wiley</foaf:name></foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Menguy</foaf:surname>
                        <foaf:givenname>Charles</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Hadoop Programming - Pushing the Limit (Pushing the Limits)</dc:title>
        <prism:edition>1 edition</prism:edition>
        <dc:date>March 31, 2014</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 1118589777</dc:identifier>
        <z:libraryCatalog>Amazon.com</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:1449363628%209781449363628">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>[S.l.]</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly Media</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Schmidt</foaf:surname>
                        <foaf:givenname>Kevin</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Programming elastic mapreduce: using aws services to build an end-to-end application.</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 1449363628 9781449363628</dc:identifier>
        <z:shortTitle>Programming elastic mapreduce</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Document rdf:about="http://www.technologyreview.com/review/511176/the-problem-with-our-data-obsession/">
        <z:itemType>webpage</z:itemType>
        <dcterms:isPartOf>
           <z:Website><dc:title>MIT Technology Review</dc:title></z:Website>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Bergstein</foaf:surname>
                        <foaf:givenname>Brian</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_28"/>
        <dc:title>Review: The Problem with Our Data Obsession</dc:title>
        <dcterms:abstract>The quest to gather ever more information can make us value the wrong things and grow overconfident about what we know.</dcterms:abstract>
        <dc:date>22:49:47</dc:date>
        <z:shortTitle>Review</z:shortTitle>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.technologyreview.com/review/511176/the-problem-with-our-data-obsession/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 22:49:47</dcterms:dateSubmitted>
    </bib:Document>
    <z:Attachment rdf:about="#item_28">
        <z:itemType>attachment</z:itemType>
        <dc:title>Review_ The Problem with Our Da - Brian Bergstein.azw3</dc:title>
        <link:type>application/octet-stream</link:type>
    </z:Attachment>
    <bib:Book rdf:about="urn:isbn:9781449356224%20%201449356222">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Sebastopol, Calif.</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly Media</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Robinson</foaf:surname>
                        <foaf:givenname>Ian</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Webber</foaf:surname>
                        <foaf:givenname>James</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Efrem</foaf:surname>
                        <foaf:givenname>Emil</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Graph databases</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781449356224  1449356222</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://search.ebscohost.com/login.aspx?direct=true&amp;scope=site&amp;db=nlebk&amp;db=nlabk&amp;AN=611703</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 11:18:31</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9781422187258%20%20142218725X">
        <z:itemType>book</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Davenport</foaf:surname>
                        <foaf:givenname>Thomas H</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kim</foaf:surname>
                        <foaf:givenname>Jinho</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Keeping up with the quants: your guide to understanding and using analytics</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781422187258  142218725X</dc:identifier>
        <z:shortTitle>Keeping up with the quants</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9781118593745%20%20111859374X">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Hoboken, N.J.</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Wiley</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ledolter</foaf:surname>
                        <foaf:givenname>Johannes</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Data Mining and Business Analytics with R</dc:title>
        <dcterms:abstract>Collecting, analyzing, and extracting valuable information from a large amount of data requires easily accessible, robust, computational and analytical tools. Data Mining and Business Analytics with R utilizes the open source software R for the analysis, exploration, and simplification of large high-dimensional data sets. As a result, readers are provided with the needed guidance to model and interpret complicated data and become adept at building powerful models for prediction and classification.  Highlighting both underlying concepts and practical computational skills, Data Mining and Business Analytics with R begins with coverage of standard linear regression and the importance of parsimony in statistical modeling. The book includes important topics such as penalty-based variable selection (LASSO); logistic regression; regression and classification trees; clustering; principal components and partial least squares; and the analysis of text and network data. In addition, the book presents:  * A thorough discussion and extensive demonstration of the theory behind the most useful data mining tools  * Illustrations of how to use the outlined concepts in real-world situations  * Readily available additional data sets and related R code allowing readers to apply their own analyses to the discussed materials  * Numerous exercises to help readers with computing skills and deepen their understanding of the material.  Data Mining and Business Analytics with R is an excellent graduate-level textbook for courses on data mining and business analytics. The book is also a valuable reference for practitioners who collect and analyze data in the fields of finance, operations management, marketing, and the information sciences.</dcterms:abstract>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781118593745  111859374X</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://UCM.eblib.com/patron/FullRecord.aspx?p=1204741</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 11:18:52</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:1461468485%209781461468486">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>New York, NY</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Springer</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kuhn</foaf:surname>
                        <foaf:givenname>Max</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Johnson</foaf:surname>
                        <foaf:givenname>Kjell</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Applied predictive modeling</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 1461468485 9781461468486</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9781935504337%20%201935504339%20%209781935504344%20%201935504347">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Bradley Beach, NJ</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Technics Publications</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Inmon</foaf:surname>
                        <foaf:givenname>William H</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Krishnan</foaf:surname>
                        <foaf:givenname>Krish</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Building the unstructured data warehouse</dc:title>
        <dc:date>2011</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781935504337  1935504339  9781935504344  1935504347</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://proquest.safaribooksonline.com/?fpi=9781935504047</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 11:19:22</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:1449361323%20%209781449361327">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Sebastopol, Calif.</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Provost</foaf:surname>
                        <foaf:givenname>Foster</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Fawcett</foaf:surname>
                        <foaf:givenname>Tom</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Data science for business: [what you need to know about data mining and data-analytic thinking]</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 1449361323  9781449361327</dc:identifier>
        <z:shortTitle>Data science for business</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:0071827269%20%209780071827263">
        <z:itemType>book</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Plunkett</foaf:surname>
                        <foaf:givenname>Tom</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Macdonald</foaf:surname>
                        <foaf:givenname>Brian</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Nelson</foaf:surname>
                        <foaf:givenname>Bruce</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Sun</foaf:surname>
                        <foaf:givenname>Helen</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Hornick</foaf:surname>
                        <foaf:givenname>Mark F</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname></foaf:surname>
                        <foaf:givenname>Laker</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Mohiuddin</foaf:surname>
                        <foaf:givenname>Khader</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Harding</foaf:surname>
                        <foaf:givenname>Debra L</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname></foaf:surname>
                        <foaf:givenname>Segleau</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Mishra</foaf:surname>
                        <foaf:givenname>Gokula</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Stackowiak</foaf:surname>
                        <foaf:givenname>Robert</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Oracle big data handbook</dc:title>
        <dcterms:abstract>&quot;Cowritten by members of Oracle's big data team, [this book] provides complete coverage of Oracle's comprehensive, integrated set of products for acquiring, organizing, analyzing, and leveraging unstructured data. The book discusses the strategies and technologies essential for a successful big data implementation, including Apache Hadoop, Oracle Big Data Appliance, Oracle Big Data Connectors, Oracle NoSQL Database, Oracle Endeca, Oracle Advanced Analytics, and Oracle's open source R offerings&quot;--Page 4 of cover.</dcterms:abstract>
        <dc:date>2014</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 0071827269  9780071827263</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:1782177981">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
               <foaf:name>Packt Publishing</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Sarkar</foaf:surname>
                        <foaf:givenname>Debarchan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Microsoft SQL Server 2012 with Hadoop</dc:title>
        <dc:date>August 26, 2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 1782177981</dc:identifier>
        <z:libraryCatalog>Amazon.com</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:1600490069%209781600490064">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>[United States]</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>AMLBook.com</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Abu-Mostafa</foaf:surname>
                        <foaf:givenname>Yaser S</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname></foaf:surname>
                        <foaf:givenname>Magdon-Ismail</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lin</foaf:surname>
                        <foaf:givenname>Hsuan-Tien</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Learning from data: a short course</dc:title>
        <dc:date>2012</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 1600490069 9781600490064</dc:identifier>
        <z:shortTitle>Learning from data</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:1449358659%209781449358655">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>[S.l.]</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly Media</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>O'Neil</foaf:surname>
                        <foaf:givenname>Cathy</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Doing data science.</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 1449358659 9781449358655</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9781118417089%20%201118417089%20%209781118420515%20%201118420519%20%209781118434284%20%201118434285">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Hoboken, N.J.</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>John Wiley &amp; Sons</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Isson</foaf:surname>
                        <foaf:givenname>Jean Paul</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Harriott</foaf:surname>
                        <foaf:givenname>Jesse</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Win with advanced business analytics creating business value from your data</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781118417089  1118417089  9781118420515  1118420519  9781118434284  1118434285</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://proxy.uqtr.ca/login.cgi?action=login&amp;u=uqtr&amp;db=books24x7&amp;ezproxy=1&amp;ezurl=http://library.books24x7.com/library.asp?%5EB&amp;bookid=46732</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 11:20:22</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9780133412932%200133412938">
        <z:itemType>book</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Miller</foaf:surname>
                        <foaf:givenname>Thomas W</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Modeling techniques in predictive analytics: business problems and solutions with R</dc:title>
        <dc:date>2014</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9780133412932 0133412938</dc:identifier>
        <z:shortTitle>Modeling techniques in predictive analytics</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Report rdf:about="http://strata.oreilly.com/2013/09/big-data-culture-gap-technology-advancing-more-quickly-than-people-and-processes.html#more-59859">
        <z:itemType>report</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Barlow</foaf:surname>
                        <foaf:givenname>Mike</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>
           <z:AutomaticTag><rdf:value>big data</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>the culture of big data</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:title>Big Data Culture Gap: Technology Advancing More Quickly Than People and Processes - Strata</dc:title>
        <dcterms:abstract>Way back in October 2012, mere days before Hurricane Sandy filled our basement with five feet of water, the nice editors at O’Reilly Media asked me to write...</dcterms:abstract>
        <dc:date>08:05:14</dc:date>
        <z:shortTitle>Big Data Culture Gap</z:shortTitle>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://strata.oreilly.com/2013/09/big-data-culture-gap-technology-advancing-more-quickly-than-people-and-processes.html#more-59859</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 08:05:14</dcterms:dateSubmitted>
    </bib:Report>
    <bib:Book rdf:about="urn:isbn:9781118356852%20%201118356853">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Hoboken, N.J.</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Wiley</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Siegel</foaf:surname>
                        <foaf:givenname>Eric</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Predictive analytics: the power to predict who will click, buy, lie, or die</dc:title>
        <dcterms:abstract>You have been predicted -- by companies, governments, law enforcement, hospitals, and universities. Their computers say, &quot;I knew you were going to do that!&quot; These institutions are seizing upon the power to predict whether you're going to click, buy, lie, or die. Why? For good reason: predicting human behavior combats financial risk, fortifies healthcare, conquers spam, toughens crime fighting, and boosts sales. How? Prediction is powered by the world's most potent, booming unnatural resource: data. Accumulated in large part as the by-product of routine tasks, data is the unsalted, flavorless residue deposited en masse as organizations churn away. Surprise! This heap of refuse is a gold mine. Big data embodies an extraordinary wealth of experience from which to learn. Predictive analytics unleashes the power of data. With this technology, the computer literally learns from data how to predict the future behavior of individuals. Perfect prediction is not possible, but putting odds on the future -- lifting a bit of the fog off our hazy view of tomorrow -- means pay dirt. In this rich, entertaining primer, former Columbia University professor and Predictive Analytics World founder Eric Siegel reveals the power and perils of prediction: What type of mortgage risk Chase Bank predicted before the recession. Predicting which people will drop out of school, cancel a subscription, or get divorced before they are even aware of it themselves. Why early retirement decreases life expectancy and vegetarians miss fewer flights. Five reasons why organizations predict death, including one health insurance company. How U.S. Bank, European wireless carrier Telenor, and Obama's 2012 campaign calculated the way to most strongly influence each individual. How IBM's Watson computer used predictive modeling to answer questions and beat the human champs on TV's Jeopardy! How companies ascertain untold, private truths -- how Target figures out you're pregnant and Hewlett-Packard deduces you're about to quit your job. How judges and parole boards rely on crime-predicting computers to decide who stays in prison and who goes free. What's predicted by the BBC, Citibank, ConEd, Facebook, Ford, Google, IBM, the IRS, Match.com, MTV, Netflix, Pandora, PayPal, Pfizer, and Wikipedia. A truly omnipresent science, predictive analytics affects everyone, every day. Although largely unseen, it drives millions of decisions, determining whom to call, mail, investigate, incarcerate, set up on a date, or medicate. Predictive analytics transcends human perception. This book's final chapter answers the riddle: What often happens to you that cannot be witnessed, and that you can't even be sure has happened afterward -- but that can be predicted in advance? Whether you are a consumer of it -- or consumed by it -- get a handle on the power of Predictive Analytics.</dcterms:abstract>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781118356852  1118356853</dc:identifier>
        <z:shortTitle>Predictive analytics</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:1783280158">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Olton Birmingham [England]</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Packt Pub. Ltd.</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Bejeck</foaf:surname>
                        <foaf:givenname>Bill</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Getting started with Google Guava write better, more efficient Java, and have fun doing so</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 1783280158</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://site.ebrary.com/id/10747042</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 11:21:10</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:129967402X%20%209781299674028">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
               <foaf:name>Packt Publishing</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Bauer</foaf:surname>
                        <foaf:givenname>Stefan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Getting Started With Amazon Redshift</dc:title>
        <dcterms:abstract>Getting Started With Amazon Redshift is a step-by-step, practical guide to the world of Redshift. Learn to load, manage, and query data on Redshift.This book is for CIOs, enterprise architects, developers, and anyone else who needs to get familiar with RedShift. The CIO will gain an understanding of what their technical staff is working on; the technical implementation personnel will get an in-depth view of the technology, and what it will take to implement their own solutions.</dcterms:abstract>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 129967402X  9781299674028</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://www.myilibrary.com?id=498652</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 11:21:35</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9781439877302%20%201439877300">
        <z:itemType>book</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Raghunathan</foaf:surname>
                        <foaf:givenname>Balaji</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>The complete book of data anonymization: from planning to implementation</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781439877302  1439877300</dc:identifier>
        <z:shortTitle>The complete book of data anonymization</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Report rdf:about="http://amzn.com/B007US6CIO">
        <z:itemType>report</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Services</foaf:surname>
                        <foaf:givenname>Amazon Web</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Amazon Elastic MapReduce Developer Guide</dc:title>
        <z:language>English</z:language>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://amzn.com/B007US6CIO</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <z:libraryCatalog>Amazon.com</z:libraryCatalog>
    </bib:Report>
    <bib:Book rdf:about="urn:isbn:9780071824385%200071824383">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>New York</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Mcgraw-Hill</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Hornick</foaf:surname>
                        <foaf:givenname>Mark</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Plunkett</foaf:surname>
                        <foaf:givenname>Tom</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Using R to unlock the value of big data: big data anylytics with Oracle R Enterprise and Oracle R Connector for hadoop</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9780071824385 0071824383</dc:identifier>
        <z:shortTitle>Using R to unlock the value of big data</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:0124158293">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Waltham, Mass.</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Morgan Kaufmann</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ladley</foaf:surname>
                        <foaf:givenname>John</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Data governance how to design, deploy, and sustain an effective data governance program</dc:title>
        <dc:date>2012</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 0124158293</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:0124059201%20%209780124059207%20%201299591914%20%209781299591912">
        <z:itemType>book</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Krishnan</foaf:surname>
                        <foaf:givenname>Krish</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Data warehousing in the age of big data</dc:title>
        <dcterms:abstract>&quot;In conclusion as you come to the end of this book, the concept of a Data Warehouse and its primary goal of serving the enterprise version of truth, and being the single platform for all the source of information will continue to remain intact and valid for many years to come. As we have discussed across many chapters and in many case studies, the limitations that existed with the infrastructures to create, manage and deploy Data Warehouses have been largely eliminated with the availability of Big Data technologies and infrastructure platforms, making the goal of the single version of truth a feasible reality. Integrating and extending Big Data into the Data Warehouse, and creating a larger decision support platform will benefit businesses for years to come. This book has touched upon governance and information lifecycle management aspects of Big Data in the larger program, however you can reuse all the current program management techniques that you follow for the Data Warehouse for this program and even implement agile approaches to integrating and managing data in the Data Warehouse. Technologies will continue to evolve in this spectrum and there will be more additions of solutions, which can be integrated if you follow the modular integration approaches to building and managing the Data Warehouse. The Appendix sections contain many more case studies and a special section on Healthcare Information Factory based on Big Data approaches. These are more guiding posts to help you align your thoughts and goals to building and integrating Big Data in your Data Warehouse&quot;--</dcterms:abstract>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 0124059201  9780124059207  1299591914  9781299591912</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://lib.myilibrary.com?id=490441</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 11:28:20</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9780137035717%200137035713">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Upper Saddle River, NJ</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>IBM Press, Pearson</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Godinez</foaf:surname>
                        <foaf:givenname>Mario</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>The art of enterprise information architecture: a systems-based approach for unlocking business insight</dc:title>
        <dc:date>2010</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9780137035717 0137035713</dc:identifier>
        <z:shortTitle>The art of enterprise information architecture</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9780123971678%200123971675">
        <z:itemType>book</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Reeve</foaf:surname>
                        <foaf:givenname>April</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Data integration (Computer science)</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:title>Managing data in motion: data integration, best practice techniques and technologies</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9780123971678 0123971675</dc:identifier>
        <z:shortTitle>Managing data in motion</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:1477258000%209781477258002">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>[S.l.]</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Authorhouse</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Bernard</foaf:surname>
                        <foaf:givenname>Scott A</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Introduction to enterprise architecture: third edition.</dc:title>
        <dc:date>2012</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 1477258000 9781477258002</dc:identifier>
        <z:shortTitle>Introduction to enterprise architecture</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:1449314597%209781449314590">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Sebastopol, CA</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Warden</foaf:surname>
                        <foaf:givenname>Pete</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_160"/>
        <dc:title>Big data glossary</dc:title>
        <dcterms:abstract>Annotation</dcterms:abstract>
        <dc:date>2011</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 1449314597 9781449314590</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://proquest.safaribooksonline.com/9781449315085</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 11:28:44</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <z:Attachment rdf:about="#item_160">
        <z:itemType>attachment</z:itemType>
        <dc:title>Big Data Glossary - Pete Warden.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Book rdf:about="urn:isbn:1449329705">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Sebastopol, CA</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly Media</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Massie</foaf:surname>
                        <foaf:givenname>Matt</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Monitoring with Ganglia</dc:title>
        <dc:date>2012</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 1449329705</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://proquest.safaribooksonline.com/?fpi=9781449330637</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 11:28:50</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9781608453436%20%20160845343X">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>[San Rafael, Calif.]</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Morgan &amp; Claypool Publishers</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lin</foaf:surname>
                        <foaf:givenname>Jimmy</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Dyer</foaf:surname>
                        <foaf:givenname>Chris</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Data-intensive text processing with MapReduce</dc:title>
        <dcterms:abstract>Our world is being revolutionized by data-driven methods: access to large amounts of data has generated new insights and opened exciting new opportunities in commerce, science, and computing applications. Processing the enormous quantities of data necessary for these advances requires large clusters, making distributed computing paradigms more crucial than ever. MapReduce is a programming model for expressing distributed computations on massive datasets and an execution framework for large-scale data processing on clusters of commodity servers. The programming model provides an easy-to-understand abstraction for designing scalable algorithms, while the execution framework transparently handles many system-level details, ranging from scheduling to synchronization to fault tolerance. This book focuses on MapReduce algorithm design, with an emphasis on text processing algorithms common in natural language processing, information retrieval, and machine learning. We introduce the notion of MapReduce design patterns, which represent general reusable solutions to commonly occurring problems across a variety of problem domains. This book not only intends to help the reader &quot;think in MapReduce&quot;, but also discusses limitations of the programming model as well.</dcterms:abstract>
        <dc:date>2010</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781608453436  160845343X</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.morganclaypool.com/doi/abs/10.2200/S00274ED1V01Y201006HLT007</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 11:28:55</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:0735675430%209780735675438">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Redmond, Wash.</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Microsoft</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Warren</foaf:surname>
                        <foaf:givenname>Norman P</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Neto</foaf:surname>
                        <foaf:givenname>Mariano Teixeira</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Misner</foaf:surname>
                        <foaf:givenname>Stacia</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Sanders</foaf:surname>
                        <foaf:givenname>Ivan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Helmers</foaf:surname>
                        <foaf:givenname>Scott A</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Business intelligence in Microsoft SharePoint 2013</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 0735675430 9780735675438</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9781118388037%201118388038">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Indianapolis, IN</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>John Wiley &amp; Sons, Inc.</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Stacey</foaf:surname>
                        <foaf:givenname>Mark</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Salvatore</foaf:surname>
                        <foaf:givenname>Joe</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Jorgensen</foaf:surname>
                        <foaf:givenname>Adam</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Visual intelligence: Microsoft tools and techniques for visualizing data</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781118388037 1118388038</dc:identifier>
        <z:shortTitle>Visual intelligence</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9781118225820%20%201118225821%20%209781118239049%20%201118239040">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Hoboken, N.J.</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Wiley</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ohlhorst</foaf:surname>
                        <foaf:givenname>Frank</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Big data analytics turning big data into big money</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781118225820  1118225821  9781118239049  1118239040</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://search.ebscohost.com/login.aspx?direct=true&amp;scope=site&amp;db=nlebk&amp;db=nlabk&amp;AN=503336</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 11:29:20</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9781849693288%20%201849693285">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Birmingham</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Packt Pub.</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Bumgarner</foaf:surname>
                        <foaf:givenname>Vincent</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Implementing Splunk: big data reporting and development for operational intelligence</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781849693288  1849693285</dc:identifier>
        <z:shortTitle>Implementing Splunk</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9781449370787%201449370780">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
               <foaf:name>Oreilly &amp; Associates Inc</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Downey</foaf:surname>
                        <foaf:givenname>Allen B.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Think Bayes.</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781449370787 1449370780</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:0486678709%209780486678702">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>New York</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Dover Pub.</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Trudeau</foaf:surname>
                        <foaf:givenname>Richard J</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Trudeau</foaf:surname>
                        <foaf:givenname>Richard J</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Introduction to graph theory</dc:title>
        <dc:date>1993</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 0486678709 9780486678702</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9780133150933%200133150933">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Indianapolis, Ind.</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Que</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Hemann</foaf:surname>
                        <foaf:givenname>Chuck</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Burbary</foaf:surname>
                        <foaf:givenname>Ken</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Digital marketing analytics making sense of consumer data in a digital world</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9780133150933 0133150933</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://proquest.safaribooksonline.com/?fpi=9780133150933</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 11:29:47</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Data rdf:about="https://github.com/saddle/saddle">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>The Saddle Development Team</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>SADDLE</dc:title>
        <dcterms:abstract>saddle - SADDLE: Scala Data Library</dcterms:abstract>
        <dc:date>22:51:09</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/saddle/saddle</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 22:51:09</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Book rdf:about="urn:isbn:9780071807593%20%200071807594">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>New York</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>McGraw-Hill</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Bartlett</foaf:surname>
                        <foaf:givenname>Randy</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>A practitioner's guide to business analytics: using data analysis tools to improve your organization's decision making and strategy</dc:title>
        <dcterms:abstract>&quot;The real tragedy of a company failing while using analytics is the fact that its leaders will have the data to explain the failure, but they won't have the capabilities in place to filter the data and convert it into actionable business insights. One implication of Big Data is that we need to adapt ... quickly. A Practitioner's Guide to Business Analytics integrates powerful strategies for leveraging analytics inside a business with a how-to playbook of tactics to make it happen. The case for competing based on analytics is clear, but until now, there hasn't been authoritative guidance for inciting a corporate community to evolve into a thriving, analytics-driven environment. This hands-on book gives you the tools, knowledge, and strategies to capture the level of organizational commitment you need to get business analytics up and running in your company. It helps you define what business analytics is, quantify the exponential value it brings to an organization, and show others how to harness its power to gain advantage over competitors.&quot;--Solapa anterior.</dcterms:abstract>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9780071807593  0071807594</dc:identifier>
        <z:shortTitle>A practitioner's guide to business analytics</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:1430260556%209781430260554">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Berkeley</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Apress</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Sarkar</foaf:surname>
                        <foaf:givenname>D</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Pro micosoft hdinsight: hadoop on windows.</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 1430260556 9781430260554</dc:identifier>
        <z:shortTitle>Pro micosoft hdinsight</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:1454908270%20%209781454908272">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Sausalito, Calif.</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Against All Odds Productions</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Smolan</foaf:surname>
                        <foaf:givenname>Rick</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Erwitt</foaf:surname>
                        <foaf:givenname>Jennifer</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>The human face of big data</dc:title>
        <dcterms:abstract>The authors invited more than 100 journalists worldwide to use photographs, charts and essays to explore the world of big data and its growing influence on our lives and society.</dcterms:abstract>
        <dc:date>2012</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 1454908270  9781454908272</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Data rdf:about="https://github.com/scraperwiki/scraperwiki-python">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>ScraperWiki</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>ScraperWiki</dc:title>
        <dcterms:abstract>scraperwiki-python - ScraperWiki Python library for scraping and saving data</dcterms:abstract>
        <dc:date>22:55:16</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://github.com/scraperwiki/scraperwiki-python</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 22:55:16</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/scraperwiki/custard">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>ScraperWiki</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>custard</dc:title>
        <dcterms:abstract>custard - A platform for tools that do stuff with data</dcterms:abstract>
        <dc:date>22:55:40</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/scraperwiki/custard</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 22:55:40</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/seatgeek/fuzzywuzzy">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>SeatGeek</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>FuzzyWuzzy</dc:title>
        <dcterms:abstract>fuzzywuzzy - Fuzzy String Matching in Python</dcterms:abstract>
        <dc:date>22:56:53</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/seatgeek/fuzzywuzzy</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 22:56:53</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Book rdf:about="urn:isbn:9781118341971%20%20111834197X">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Hoboken, N.J</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Wiley</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Katz</foaf:surname>
                        <foaf:givenname>Joel</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Designing information: human factors and common sense in information design</dc:title>
        <dc:date>2012</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781118341971  111834197X</dc:identifier>
        <z:shortTitle>Designing information</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9783836528795%203836528797">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Köln</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Taschen</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Rendgen</foaf:surname>
                        <foaf:givenname>Sandra</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Wiedemann</foaf:surname>
                        <foaf:givenname>Julius</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ciuccarelli</foaf:surname>
                        <foaf:givenname>Paolo</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Wurman</foaf:surname>
                        <foaf:givenname>Richard Saul</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Rogers</foaf:surname>
                        <foaf:givenname>Simon</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Holmes</foaf:surname>
                        <foaf:givenname>Nigel</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Information graphics</dc:title>
        <dcterms:abstract>&quot;Our everyday lives are filled with a massive flow of information that we must interpret in order to understand the world we live in. Considering this complex variety of data floating around us, sometimes the best -- or even only -- way to communicate is visually. This unique book presents a fascinating perspective on the subject, highlighting the work of the masters of the profession who have created a number of breakthroughs that have changed the way we communicate. Information Graphics has been conceived and designed not just for graphics professionals, but for anyone interested in the history and practice of communicating visually. The in-depth introductory section, illustrated with over 60 images (each accompanied by an explanatory caption), features essays by Sandra Rendgen, Paolo Ciuccarelli, Richard Saul Wurman, and Simon Rogers; looking back all the way to primitive cave paintings as a means of communication, this introductory section gives readers an excellent overview of the subject. The second part of the book is entirely dedicated to contemporary works by today's most renowned professionals, presenting 200 graphics projects, with over 400 examples -- each with a fact sheet and an explanation of methods and objectives -- divided into chapters by the subjects Location, Time, Category, and Hierarchy.&quot;--Publisher description.</dcterms:abstract>
        <dc:date>2012</dc:date>
        <z:language>Text in English, French, and German.</z:language>
        <dc:identifier>ISBN 9783836528795 3836528797</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:1477432264%209781477432266">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Seattle, WA</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Freakalytics, LLC</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>McDaniel</foaf:surname>
                        <foaf:givenname>Eileen</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>McDaniel</foaf:surname>
                        <foaf:givenname>Stephen</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>The accidental analyst: show your data who's boss</dc:title>
        <dc:date>2012</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 1477432264 9781477432266</dc:identifier>
        <z:shortTitle>The accidental analyst</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9780133158342%200133158349">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Upper Saddle River, N.J.</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>FT Press</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Waber</foaf:surname>
                        <foaf:givenname>Ben</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>People analytics how social sensing technology will transform business and what it tells us about the future of work</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9780133158342 0133158349</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://proquest.safaribooksonline.com/?fpi=9780133158342</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 11:35:09</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9780062088420%20%200062088424">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>New York</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>HarperBusiness</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Nussbaum</foaf:surname>
                        <foaf:givenname>Bruce</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Creative intelligence: harnessing the power to create, connect, and inspire</dc:title>
        <dcterms:abstract>Explores how people and organizations are learning to be more creative in work and life, and reveals how to boost creative capacity, build creative confidence, and connect creativity with capitalism in a new form.</dcterms:abstract>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9780062088420  0062088424</dc:identifier>
        <z:shortTitle>Creative intelligence</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:1449358721%209781449358723">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>[S.l.]</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly Media</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Nathan</foaf:surname>
                        <foaf:givenname>Paco</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Enterprise data workflows with cascading.</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 1449358721 9781449358723</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9781118739570%201118739574">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
               <foaf:name>John Wiley &amp; Sons Inc</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Schmarzo</foaf:surname>
                        <foaf:givenname>Bill</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Big Data Understanding How Data Powers Big Business.</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781118739570 1118739574</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:3659155160">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
               <foaf:name>LAP LAMBERT Academic Publishing</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Jian</foaf:surname>
                        <foaf:givenname>Li</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Large scale data processing in Hadoop MapReduce scenario: Time estimation and computation models</dc:title>
        <dc:date>July 11, 2012</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 3659155160</dc:identifier>
        <z:shortTitle>Large scale data processing in Hadoop MapReduce scenario</z:shortTitle>
        <z:libraryCatalog>Amazon.com</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9780321898654%20%200321898656">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Harlow</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Addison-Wesley</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Manoochehri</foaf:surname>
                        <foaf:givenname>Michael</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Data just right: practical big data analytics</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9780321898654  0321898656</dc:identifier>
        <z:shortTitle>Data just right</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9781118559215%201118559215">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
               <foaf:name>John Wiley &amp; Sons Inc</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ottenheimer</foaf:surname>
                        <foaf:givenname>Davi</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Big Data Security.</dc:title>
        <dc:date>2014</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781118559215 1118559215</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:1449335969%209781449335960">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>[S.l.]</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly Media</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kromer</foaf:surname>
                        <foaf:givenname>Philip</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Big data for chimps.</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 1449335969 9781449335960</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:0596529325%209780596529321">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                        <vcard:locality>Beijing; Sebastapol [Calif.]</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Segaran</foaf:surname>
                        <foaf:givenname>Toby</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Programming collective intelligence: building smart web 2.0 applications</dc:title>
        <dcterms:abstract>Provides information on building Web 2.0 applications that have the capability to mine data created by Internet applications.</dcterms:abstract>
        <dc:date>2007</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 0596529325 9780596529321</dc:identifier>
        <z:shortTitle>Programming collective intelligence</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9781449305468%20%201449305466">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Farnham</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Bressert</foaf:surname>
                        <foaf:givenname>Eli</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>SciPy and NumPy</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781449305468  1449305466</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9780521493369%20%200521493366">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>New York</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Cambridge University Press</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Jannach</foaf:surname>
                        <foaf:givenname>Dietmar</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Recommender systems: an introduction</dc:title>
        <dc:date>2011</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9780521493369  0521493366</dc:identifier>
        <z:shortTitle>Recommender systems</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9781139572972%20%201139572970%20%209780511973000%20%200511973004">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Cambridge</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Cambridge University Press</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Flach</foaf:surname>
                        <foaf:givenname>Peter A</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Machine learning the art and science of algorithms that make sense of data</dc:title>
        <dc:date>2012</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781139572972  1139572970  9780511973000  0511973004</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://dx.doi.org/10.1017/CBO9780511973000</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 11:39:31</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9780596159795%20%20059615979X">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Sebastopol, CA</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Farmer</foaf:surname>
                        <foaf:givenname>F. Randall</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Glass</foaf:surname>
                        <foaf:givenname>Bryce</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Building Web reputation systems</dc:title>
        <dc:date>2010</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9780596159795  059615979X</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9780596153816%200596153813">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Beijing; Sebastopol, CA</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Segaran</foaf:surname>
                        <foaf:givenname>Toby</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Taylor</foaf:surname>
                        <foaf:givenname>Jamie</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Programming the Semantic Web</dc:title>
        <dcterms:abstract>Provides information on using the programming techniques of the Semantic Web to create, enrich, and simplify Web applications.</dcterms:abstract>
        <dc:date>2009</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9780596153816 0596153813</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9780735673809">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
               <foaf:name>Microsoft Press</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Chauhan</foaf:surname>
                        <foaf:givenname>Avkash</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Fontama</foaf:surname>
                        <foaf:givenname>Valentine</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Hart</foaf:surname>
                        <foaf:givenname>Michele</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Tok</foaf:surname>
                        <foaf:givenname>Wee-Hyong</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lee</foaf:surname>
                        <foaf:givenname>Denny Guang-Yeu</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computers / Data Modeling &amp; Design</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computers / Databases / Data Mining</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computers / Programming / Microsoft</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:title>Simplifying Big Data With Microsoft Hdinsight</dc:title>
        <dcterms:abstract>Unlock new insights from enterprise data with this solution builder's guide to HDInsight. Whether you're a developer or data analyst, BI professional or IT professional, you'll learn how to build Hadoop-compatible Big Data applications for the cloud or on premises.Written by key members of the Microsoft teams focused on Big Data Gets you up and running quickly with HDInsight, which provides 100% Apache Hadoop compatibility Shares developer insights on using HDInsight and other Microsoft tools to process and analyze large datasets, including structured and unstructured data Explains how to build, deploy, and manage Hadoop clusters through Windows Server and Windows Azure Topics includes: Working with the console, streaming data, predictive analytics, Pig, Hive, Sqoop, HDFS, Hbase, management, and troubleshooting, plus real-world examples</dcterms:abstract>
        <dc:date>2013-08-22</dc:date>
        <z:numPages>416</z:numPages>
        <z:language>en</z:language>
        <dc:identifier>ISBN 9780735673809</dc:identifier>
        <z:libraryCatalog>Google Books</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9781118659557%20%201118659554">
        <z:itemType>book</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Chan</foaf:surname>
                        <foaf:givenname>Ernest P</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Algorithmic trading: winning strategies and their rationale</dc:title>
        <dcterms:abstract>Praise for Algorithmic Trading  &quot;Algorithmic Trading is an insightful book on quantitative trading written by a seasoned practitioner. What sets this book apart from many others in the space is the emphasis on real examples as opposed to just theory. Concepts are not only described, they are brought to life with actual trading strategies, which give the reader insight into how and why each strategy was developed, how it was implemented, and even how it was coded. This book is a valuable resource for anyone looking to create their own systematic trading strategies and those involved in manager selection, where the knowledge contained in this book will lead to a more informed and nuanced conversation with managers.&quot;   ---DAREN SMITH, CFA, CAIA, FSA, Managing Director, Manager Selection &amp; Portfolio Construction, University of Toronto Asset Management   &quot;Using an excellent selection of mean reversion and momentum strategies, Ernie explains the rationale behind each one, shows how to test it, how to improve it, and discusses implementation issues. His book is a careful, detailed exposition of the scientific method applied to strategy development. For serious retail traders, I know of no other book that provides this range of examples and level of detail. His discussions of how regime changes affect strategies, and of risk management, are invaluable bonuses.&quot;   ---Roger Hunter, Mathematician and Algorithmic Trader</dcterms:abstract>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781118659557  1118659554</dc:identifier>
        <z:shortTitle>Algorithmic trading</z:shortTitle>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://search.ebscohost.com/login.aspx?direct=true&amp;scope=site&amp;db=nlebk&amp;db=nlabk&amp;AN=587988</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 11:39:49</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9780521865715%20%200521865719">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>New York</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Cambridge University Press</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Manning</foaf:surname>
                        <foaf:givenname>Christopher D</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Raghavan</foaf:surname>
                        <foaf:givenname>Prabhakar</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Schütze</foaf:surname>
                        <foaf:givenname>Hinrich</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Introduction to information retrieval</dc:title>
        <dcterms:abstract>&quot;Class-tested and coherent, this textbook teaches classical and web information retrieval, including web search and the related areas of text classification and text clustering from basic concepts. It gives an up-to-date treatment of all aspects of the design and implementation of systems for gathering, indexing, and searching documents; methods for evaluating systems; and an introduction to the use of machine learning methods on text collections. All the important ideas are explained using examples and figures, making it perfect for introductory courses in information retrieval for advanced undergraduates and graduate students in computer science. Based on feedback from extensive classroom experience, the book has been carefully structured in order to make teaching more natural and effective. Slides and additional exercises (with solutions for lecturers) are also available through the book's supporting website to help course instructors prepare their lectures.&quot; -- Publisher's description.</dcterms:abstract>
        <dc:date>2008</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9780521865715  0521865719</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9781782162650%20%201782162658">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>[S.l.]</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Packt Publishing Limited</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Capriolo</foaf:surname>
                        <foaf:givenname>Edward</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Clojure data analysis cookbook</dc:title>
        <dcterms:abstract>Full of practical tips, the &quot;&quot;Clojure Data Analysis Cookbook&quot;&quot; will help you fully utilize your data through a series of step-by-step, real world recipes covering every aspect of data analysis.Prior experience with Clojure and data analysis techniques and workflows will be beneficial, but not essential.</dcterms:abstract>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781782162650  1782162658</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://lib.myilibrary.com?id=475335</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 11:39:59</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Report rdf:about="http://papers.ssrn.com/abstract=1926431">
        <z:itemType>report</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Rochester, NY</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Social Science Research Network</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Boyd</foaf:surname>
                        <foaf:givenname>Danah</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Crawford</foaf:surname>
                        <foaf:givenname>Kate</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_1261"/>
        <dc:subject>
           <z:AutomaticTag><rdf:value>analysis</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>big data</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>methodology</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>sociology</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:title>Six Provocations for Big Data</dc:title>
        <dcterms:abstract>The era of Big Data has begun. Computer scientists, physicists, economists, mathematicians, political scientists, bio-informaticists, sociologists, and many others are clamoring for access to the massive quantities of information produced by and about people, things, and their interactions. Diverse groups argue about the potential benefits and costs of analyzing information from Twitter, Google, Verizon, 23andMe, Facebook, Wikipedia, and every space where large groups of people leave digital traces and deposit data. Significant questions emerge. Will large-scale analysis of DNA help cure diseases? Or will it usher in a new wave of medical inequality? Will data analytics help make people’s access to information more efficient and effective? Or will it be used to track protesters in the streets of major cities? Will it transform how we study human communication and culture, or narrow the palette of research options and alter what ‘research’ means? Some or all of the above?This essay offers six provocations that we hope can spark conversations about the issues of Big Data. Given the rise of Big Data as both a phenomenon and a methodological persuasion, we believe that it is time to start critically interrogating this phenomenon, its assumptions, and its biases.(This paper was presented at Oxford Internet Institute’s “A Decade in Internet Time: Symposium on the Dynamics of the Internet and Society” on September 21, 2011.)</dcterms:abstract>
        <prism:number>ID 1926431</prism:number>
        <z:type>SSRN Scholarly Paper</z:type>
        <dc:date>2011/09/21</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://papers.ssrn.com/abstract=1926431</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 23:01:58</dcterms:dateSubmitted>
        <z:libraryCatalog>papers.ssrn.com</z:libraryCatalog>
    </bib:Report>
    <z:Attachment rdf:about="#item_1261">
        <z:itemType>attachment</z:itemType>
        <dc:title>Boyd_Crawford_2011_Six_Provocations_for_Big_Data.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Book rdf:about="urn:isbn:9781449388348%20%201449388345">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Sebastopol, CA</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Russell</foaf:surname>
                        <foaf:givenname>Matthew A</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Mining the social web</dc:title>
        <dcterms:abstract>Facebook, Twitter, and LinkedIn generate a tremendous amount of valuable social data, but how can you find out who's making connections with social media, what they're talking about, or where they're located? This book shows you how to answer these questions and more. Each chapter introduces techniques for mining data in different areas of the social web, including blogs and email.</dcterms:abstract>
        <dc:date>2011</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781449388348  1449388345</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9781608458844%20%201608458849%20%209781608458851%20%201608458857">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>San Rafael, Calif</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Morgan &amp; Claypool</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Liu</foaf:surname>
                        <foaf:givenname>Bing</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Sentiment analysis and opinion mining</dc:title>
        <dc:date>2012</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781608458844  1608458849  9781608458851  1608458857</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9781449315153%201449315151">
        <z:itemType>book</z:itemType>
        <dc:publisher>
           <foaf:Organization><foaf:name>O'Reilly</foaf:name></foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Chang</foaf:surname>
                        <foaf:givenname>Sau Sheong</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Exploring everythings with R and Ruby.</dc:title>
        <dc:date>2012</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781449315153 1449315151</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9781449304096%20%201449304095%20%209781449303853%20%201449303854">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Sebastopol, Calif.</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly Media</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Russell</foaf:surname>
                        <foaf:givenname>Matthew A</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>21 recipes for mining Twitter</dc:title>
        <dcterms:abstract>Millions of public Twitter streams harbor a wealth of data, and once you mine them, you can gain some valuable insights. This short and concise book offers a collection of recipes to help you extract nuggets of Twitter information using easy-to-learn Python tools. Each recipe offers a discussion of how and why the solution works, so you can quickly adapt it to fit your particular needs. The recipes include techniques to: Use OAuth to access Twitter data; Create and analyze graphs of retweet relationships; Use the streaming API to harvest tweets in realtime; Harvest and analyze friends and followers; Discover friendship cliques; and Summarize webpages from short URLs.</dcterms:abstract>
        <dc:date>2011</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781449304096  1449304095  9781449303853  1449303854</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://proquest.safaribooksonline.com/9781449303624</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 11:40:36</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9781583476208%20%201583476202%20%209781892147295%20%201892147297%20%209781583477243%20%201583477241">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Boise</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>MC Press</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Sathi</foaf:surname>
                        <foaf:givenname>Arvind</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Big data analytics</dc:title>
        <dcterms:abstract>Bringing a practitioner's view to big data analytics, this work examines the drivers behind big data, postulates a set of use cases, identifies sets of solution components, and recommends various implementation approaches. This work also addresses and thoroughly answers key questions on this emerging topic, including What is big data and how is it being used? How can strategic plans for big data analytics be generated? and How does big data change analytics architecture? The author, who has more than 20 years of experience in information management architecture and delivery, has drawn the material from a large breadth of workshops and interviews with business and information technology leaders, providing readers with the latest in evolutionary, revolutionary, and hybrid methodologies of moving forward to the brave new world of big data.</dcterms:abstract>
        <dc:date>2012</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781583476208  1583476202  9781892147295  1892147297  9781583477243  1583477241</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://site.ebrary.com/id/10621581</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 11:40:41</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:143025761X%20%209781430257615">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>[New York, N.Y.]</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Apress</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Zadrozny</foaf:surname>
                        <foaf:givenname>Peter</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Big data analytics using Splunk</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 143025761X  9781430257615</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9781849515139%20%201849515131%20%201849515123%209781849515122">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Birmingham, UK</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Packt Pub.</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Capriolo</foaf:surname>
                        <foaf:givenname>Edward</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_81"/>
        <dc:title>Cassandra high performance cookbook</dc:title>
        <dcterms:abstract>Annotation</dcterms:abstract>
        <dc:date>2011</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781849515139  1849515131  1849515123 9781849515122</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://proquest.safaribooksonline.com/?fpi=9781849515122</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 11:40:53</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <z:Attachment rdf:about="#item_81">
        <z:itemType>attachment</z:itemType>
        <dc:title>Cassandra High Performance Cookbook - Edward Capriolo.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Book rdf:about="urn:isbn:9781782160601%201782160604">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Birmingham</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Packt Publishing</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Loo</foaf:surname>
                        <foaf:givenname>Mark P.J. van der</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Learning RStudio for R Statistical Computing: learn to effectively perform R development, statistical analysis, and reporting with the most popular R IDE</dc:title>
        <dc:date>2012</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781782160601 1782160604</dc:identifier>
        <z:shortTitle>Learning RStudio for R Statistical Computing</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9781449363116%20%201449363113">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Sebastopol, CA</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly Media</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Chang</foaf:surname>
                        <foaf:givenname>Winston</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>R graphics cookbook</dc:title>
        <dc:date>2012</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781449363116  1449363113</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://proquest.safaribooksonline.com/?fpi=9781449363086</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 11:45:04</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9781118611937%20%201118611934">
        <z:itemType>book</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lublinsky</foaf:surname>
                        <foaf:givenname>Boris</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Smith</foaf:surname>
                        <foaf:givenname>Kevin T</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname></foaf:surname>
                        <foaf:givenname>Yakubovich</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Professional Hadoop solutions</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781118611937  1118611934</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Document rdf:about="http://www.visualisingdata.com/index.php/resources/">
        <z:itemType>webpage</z:itemType>
        <dcterms:isPartOf>
           <z:Website></z:Website>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kirk</foaf:surname>
                        <foaf:givenname>Andy</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Essential Collection of Visualisation Resources</dc:title>
        <dc:date>11:26:00</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.visualisingdata.com/index.php/resources/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-08 11:26:00</dcterms:dateSubmitted>
    </bib:Document>
    <bib:Book rdf:about="urn:isbn:9781430219439%201430219432">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Berkeley, CA</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Apress</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Venner</foaf:surname>
                        <foaf:givenname>Jason</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computers / Programming / Open Source</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:title>Pro Hadoop</dc:title>
        <dcterms:abstract>&quot;You learn the ins and outs of MapReduce; how to structure a cluster, design, and implement the Hadoop file system; and how to structure your first cloud--computing tasks using Hadoop. Learn how to let Hadoop take care of distributing and parallelizing your software--you just focus on the code, Hadoop takes care of the rest&quot;--Resource description p.</dcterms:abstract>
        <dc:date>2009</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781430219439 1430219432</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://public.eblib.com/EBLPublic/PublicView.do?ptiID=478209</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 11:45:42</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9781449315771%20%201449315771">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Sebastopol, CA</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>George</foaf:surname>
                        <foaf:givenname>Lars</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>HBase the definitive guide</dc:title>
        <dcterms:abstract>&quot;If you're looking for a scalable storage solution to accommodate a virtually endless amount of data, this book shows you how Apache HBase can fulfill your needs. As the open source implementation of Google's BigTable architecture, HBase scales to billions of rows and millions of columns, while ensuring that write and read performance remain constant. Many IT executives are asking pointed questions about HBase. This book provides meaningful answers, whether you're evaluating this non-relational database or planning to put it into practice right away&quot;--Provided by publisher.</dcterms:abstract>
        <dc:date>2011</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781449315771  1449315771</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://proquest.safaribooksonline.com/9781449314682</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 11:45:58</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Data rdf:about="http://www.python.org/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Python Software Foundation</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Python</dc:title>
        <dc:date>09:17:16</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://www.python.org/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-09 09:17:16</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Book rdf:about="urn:isbn:9780470944882%200470944889%209786613177582%20661317758X%209781118140253%201118140257%209781118140260%201118140265">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Indianapolis, Ind</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Wiley</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Yau</foaf:surname>
                        <foaf:givenname>Nathan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Visualize this: the FlowingData guide to design, visualization, and statistics</dc:title>
        <dc:date>2011</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9780470944882 0470944889 9786613177582 661317758X 9781118140253 1118140257 9781118140260 1118140265</dc:identifier>
        <z:shortTitle>Visualize this</z:shortTitle>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://www.myilibrary.com?id=317758</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 11:46:27</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9780982544204%20%200982544200">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Redmond, Wash.</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Microsoft Research</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Hey</foaf:surname>
                        <foaf:givenname>Tony</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Tolle</foaf:surname>
                        <foaf:givenname>Kristin</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>The fourth paradigm data-intensive scientific discovery</dc:title>
        <dcterms:abstract>A collection of essays expanding on the vision of pioneering computer scientist Jim Gray for a new, fourth paradigm of discovery based on data-intensive science.</dcterms:abstract>
        <dc:date>2009</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9780982544204  0982544200</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:1617290343%209781617290343">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>[S.l.]</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly Media</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Marz</foaf:surname>
                        <foaf:givenname>Nathan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_142"/>
        <dc:title>Big data: principles and best practices of scalable realtime data systems.</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 1617290343 9781617290343</dc:identifier>
        <z:shortTitle>Big data</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <z:Attachment rdf:about="#item_142">
        <z:itemType>attachment</z:itemType>
        <dc:title>Big Data - Nathan Marz.epub</dc:title>
        <link:type>application/octet-stream</link:type>
    </z:Attachment>
    <bib:Book rdf:about="urn:isbn:9781939902023">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
               <foaf:name>Bleeding Edge Press</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Dunn</foaf:surname>
                        <foaf:givenname>Roland</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Hobbelt</foaf:surname>
                        <foaf:givenname>Ger</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Thornton</foaf:surname>
                        <foaf:givenname>Andrew</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Viau</foaf:surname>
                        <foaf:givenname>Chris</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Mott</foaf:surname>
                        <foaf:givenname>Troy</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_109"/>
        <dc:title>Developing a D3.js Edge</dc:title>
        <dc:date>June 25, 2013</dc:date>
        <z:numPages>107</z:numPages>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781939902023</dc:identifier>
        <z:libraryCatalog>Amazon.com</z:libraryCatalog>
    </bib:Book>
    <z:Attachment rdf:about="#item_109">
        <z:itemType>attachment</z:itemType>
        <dc:title>Developing a D3.js Edge - Roland Dunn.epub</dc:title>
        <link:type>application/octet-stream</link:type>
    </z:Attachment>
    <bib:Data rdf:about="http://sympy.org">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>SymPy Development Team</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>SymPy</dc:title>
        <dcterms:abstract>A Python library for symbolic mathematics.</dcterms:abstract>
        <dc:date>09:26:18</dc:date>
        <dc:identifier>
           <dcterms:URI><rdf:value>http://sympy.org</rdf:value></dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-09 09:26:18</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Book rdf:about="urn:isbn:1617290769%209781617290763">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>[S.l.]</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly Media</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Partner</foaf:surname>
                        <foaf:givenname>Jonas</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Neo4j in action.</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 1617290769 9781617290763</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Data rdf:about="http://tez.incubator.apache.org/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Apache Software Foundation</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Apache Tez</dc:title>
        <dcterms:abstract>The Apache Tez project is aimed at building an application framework which allows for a complex directed-acyclic-graph of tasks for processing data. It is currently built atop Apache Hadoop YARN</dcterms:abstract>
        <dc:date>09:37:54</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://tez.incubator.apache.org/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-09 09:37:54</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Apache Software Foundation</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Apache Hadoop YARN</dc:title>
        <dcterms:abstract>The fundamental idea of MRv2 is to split up the two major functionalities of the JobTracker, resource management and job scheduling/monitoring, into separate daemons. The idea is to have a global ResourceManager (RM) and per-application ApplicationMaster (AM). An application is either a single job in the classical sense of Map-Reduce jobs or a DAG of jobs.</dcterms:abstract>
        <dc:date>09:39:12</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-09 09:39:12</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Book rdf:about="urn:isbn:9780071745321%20%200071745327">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>New York</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>McGraw-Hill</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Laberge</foaf:surname>
                        <foaf:givenname>Robert</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>The data warehouse mentor: practical data warehouse and business intelligence insights</dc:title>
        <dcterms:abstract>&quot;Proven strategies for implementing the right data warehouse and business intelligence solutions for current and future business needs In The Data Warehouse Mentor: Practical Data Warehouse and Business Intelligence Insights, business intelligence and data warehousing expert Robert Laberge explains the components and different alternatives in building a data warehouse and describes pros and cons for choosing one path over another. Building a data warehouse is unique for each organization but can be guided by the author's years of knowledge obtained from working on many differing data warehouse and business intelligence environments in organizations around the world.The book covers practical and technical aspects of current data warehouse and business intelligence issues with views on realistic solutions within the management and technical arenas. Data warehousing topics are first presented from a high-level overview to ensure the terminology and context is understood, and are then covered in deeper detail to clarify the specifics. These topics all pertain to data warehousing, business intelligence, and performance management.The Data Warehouse Mentor Explains the proper implementation of the many available technologies and practices Shares the author's nearly 30 years of data warehouse and business intelligence experience in more than 20 countries worldwide Mentors you to success in determining and deploying the most effective data warehouse and business intelligence solutions for your business Helps you anticipate future data requirements and usage to ensure the design and build environment for your solution is flexible and open to change Complete coverage: Data Warehouse and Business Intelligence Overview; Data in the Organization; Reasons for Building; Business Intelligence and Data Warehouse Strategy - The Plan; Project Resources - Roles and Insights; Write it Up - Overview; Business Intelligence: Data Marts &amp; Usage; Enterprise Data Models; Data Warehouse Architecture; ETL and Data Quality; Project Planning; Working Scenarios - Hands On; Data Governance; Post Project Review&quot;-- &quot;Empower your users and drive better decision making across your enterprise with detailed instructions and best practices from an expert developer and trainer. The Data Warehouse Mentor: Practical Data Warehouse and Business Intelligence Insights shows how to plan, design, construct, and administer an integrated end-to-end DW/BI solution. Learn how to choose appropriate components, build an enterprise data model, configure data marts and data warehouses, establish data flow, and mitigate risk. Change management, data governance, and security are also covered in this comprehensive guide&quot;--</dcterms:abstract>
        <dc:date>2011</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9780071745321  0071745327</dc:identifier>
        <z:shortTitle>The data warehouse mentor</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:1937785335%209781937785338">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Dallas, TX</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Pragmatic Programmers</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Chu-Carroll</foaf:surname>
                        <foaf:givenname>Mark C</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Good math: a geek's guide to the beauty of numbers, logic, and computation</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 1937785335 9781937785338</dc:identifier>
        <z:shortTitle>Good math</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Data rdf:about="https://www.ruby-lang.org">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Matsumoto</foaf:surname>
                        <foaf:givenname>Yukihiro</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Ruby</dc:title>
        <dc:date>09:58:04</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://www.ruby-lang.org</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-09 09:58:04</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="http://graphchi.org">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kyrola</foaf:surname>
                        <foaf:givenname>Aapo</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>GraphLab</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>GraphChi</dc:title>
        <dc:identifier>
           <dcterms:URI><rdf:value>http://graphchi.org</rdf:value></dcterms:URI>
        </dc:identifier>
    </bib:Data>
    <bib:Book rdf:about="urn:isbn:9781617290183%20%201617290181">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Shelter Island, N.Y.</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Manning Publications Co.</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Harrington</foaf:surname>
                        <foaf:givenname>Peter</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Machine learning in action</dc:title>
        <dc:date>2012</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781617290183  1617290181</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9781449330545%20%201449330541%20%209781449330538%20%201449330533">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Sebastopol, CA</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Conway</foaf:surname>
                        <foaf:givenname>Drew</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>White</foaf:surname>
                        <foaf:givenname>John Myles</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Machine learning for hackers</dc:title>
        <dcterms:abstract>If you're an experienced programmer interested in crunching data, this book will get you started with machine learning--a toolkit of algorithms that enables computers to train themselves to automate useful tasks. Authors Drew Conway and John Myles White help you understand machine learning and statistics tools through a series of hands-on case studies, instead of a traditional math-heavy presentation. Each chapter focuses on a specific problem in machine learning, such as classification, prediction, optimization, and recommendation. Using the R programming language, you'll learn how to analyze s.</dcterms:abstract>
        <dc:date>2012</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781449330545  1449330541  9781449330538  1449330533</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://search.ebscohost.com/login.aspx?direct=true&amp;scope=site&amp;db=nlebk&amp;db=nlabk&amp;AN=436647</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 11:51:54</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:0262011530">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                        <vcard:locality>Cambridge, Mass. : New York</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>MIT Press ; McGraw-Hill</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Abelson</foaf:surname>
                        <foaf:givenname>Harold</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <bib:contributors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Sussman</foaf:surname>
                        <foaf:givenname>Gerald Jay</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Sussman</foaf:surname>
                        <foaf:givenname>Julie</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:contributors>
        <link:link rdf:resource="#item_67"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer programming</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>LISP (Computer program language)</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:title>Structure and interpretation of computer programs</dc:title>
        <prism:edition>2nd ed</prism:edition>
        <dc:date>1996</dc:date>
        <z:numPages>657</z:numPages>
        <dc:identifier>ISBN 0262011530</dc:identifier>
        <z:libraryCatalog>Library of Congress ISBN</z:libraryCatalog>
        <dc:subject>
           <dcterms:LCC><rdf:value>QA76.6 .A255 1996</rdf:value></dcterms:LCC>
        </dc:subject>
    </bib:Book>
    <z:Attachment rdf:about="#item_67">
        <z:itemType>attachment</z:itemType>
        <dc:title>Structure and Interpretation of Computer Programs - Harold Abelson.epub</dc:title>
        <link:type>application/octet-stream</link:type>
    </z:Attachment>
    <bib:Book rdf:about="urn:isbn:9780262305242%20%200262305240">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Cambridge, Mass.</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>MIT Press</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Murphy</foaf:surname>
                        <foaf:givenname>Kevin P</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Machine learning a probabilistic perspective</dc:title>
        <dcterms:abstract>&quot;This textbook offers a comprehensive and self-contained introduction to the field of machine learning, based on a unified, probabilistic approach. The coverage combines breadth and depth, offering necessary background material on such topics as probability, optimization, and linear algebra as well as discussion of recent developments in the field, including conditional random fields, L1 regularization, and deep learning. The book is written in an informal, accessible style, complete with pseudo-code for the most important algorithms. All topics are copiously illustrated with color images and worked examples drawn from such application domains as biology, text processing, computer vision, and robotics. Rather than providing a cookbook of different heuristic methods, the book stresses a principled model-based approach, often using the language of graphical models to specify models in a concise and intuitive way. Almost all the models described have been implemented in a MATLAB software package--PMTK (probabilistic modeling toolkit)--that is freely available online&quot;--Back cover.</dcterms:abstract>
        <dc:date>2012</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9780262305242  0262305240</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://search.ebscohost.com/login.aspx?direct=true&amp;scope=site&amp;db=nlebk&amp;db=nlabk&amp;AN=480968</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 11:52:07</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9780262305662%20%200262305666">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Cambridge, MA</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>MIT Press</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Mohri</foaf:surname>
                        <foaf:givenname>Mehryar</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Rostamizadeh</foaf:surname>
                        <foaf:givenname>Afshin</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Talwalkar</foaf:surname>
                        <foaf:givenname>Ameet</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Foundations of machine learning</dc:title>
        <dc:date>2012</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9780262305662  0262305666</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://search.ebscohost.com/login.aspx?direct=true&amp;scope=site&amp;db=nlebk&amp;db=nlabk&amp;AN=478737</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 11:52:34</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9781461422990%20%20146142299X">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>New York</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Springer</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Højsgaard</foaf:surname>
                        <foaf:givenname>Søren</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Edwards</foaf:surname>
                        <foaf:givenname>David</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lauritzen</foaf:surname>
                        <foaf:givenname>Steffen L</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Graphical models with R</dc:title>
        <dc:date>2012</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781461422990  146142299X</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://dx.doi.org/10.1007/978-1-4614-2299-0</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 11:53:07</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:0387310738%20%209780387310732">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>New York, NY</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Springer</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Bishop</foaf:surname>
                        <foaf:givenname>Christopher M</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Pattern recognition and machine learning</dc:title>
        <dc:date>2009</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 0387310738  9780387310732</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9781107422223%201107422221">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Cambridge</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>CAMBRIDGE UNIVERSITY PRESS</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Flach</foaf:surname>
                        <foaf:givenname>Peter</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Machine Learning</dc:title>
        <dc:date>2012</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781107422223 1107422221</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:1938377001%209781938377006">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Burlingame, CA</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Analytics Press</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Few</foaf:surname>
                        <foaf:givenname>Stephen</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Information dashboard design: displaying data for at-a-glance monitoring</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 1938377001 9781938377006</dc:identifier>
        <z:shortTitle>Information dashboard design</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9781782179740%201782179747">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Birmingham</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Packt Publishing</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Redmond</foaf:surname>
                        <foaf:givenname>Stephen</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>QlikView for Developers Cookbook</dc:title>
        <dcterms:abstract>The recipes in this Cookbook provide a concise yet practical guide on how to become an excellent QlikView developer. The book begins with intermediate level recipes and then moves on to more complex recipes in an incremental manner. This book is for anyone who has either attended QlikView Developer training or has taught themselves QlikView from books or online sources. You might be working for a QlikView customer, partner, or even QlikView themselves (or want to!) and want to improve your QlikView skills.</dcterms:abstract>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781782179740 1782179747</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://public.eblib.com/EBLPublic/PublicView.do?ptiID=1192682</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 11:53:48</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9781107015357%20%201107015359">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>New York, N.Y.; Cambridge</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Cambridge University Press</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Rajaraman</foaf:surname>
                        <foaf:givenname>Anand</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ullman</foaf:surname>
                        <foaf:givenname>Jeffrey D</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_154"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computers / Databases / Data Mining</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computers / Databases / General</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
                <rdf:value>Computers / Intelligence (AI) &amp; Semantics</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computers / Programming / Algorithms</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:title>Mining of massive datasets</dc:title>
        <dc:date>2012</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781107015357  1107015359</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <z:Attachment rdf:about="#item_154">
        <z:itemType>attachment</z:itemType>
        <dc:title>Rajaraman_Ullman_2012_Mining_of_massive_datasets.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Book rdf:about="urn:isbn:9781933988313%20%201933988312">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Greenwich, Conn.</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Manning</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Alag</foaf:surname>
                        <foaf:givenname>Satnam</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Collective intelligence in action</dc:title>
        <dc:date>2008</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781933988313  1933988312</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9781849518444%201849518440">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Birmingham [u.a.]</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Packt Publ.</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kuć</foaf:surname>
                        <foaf:givenname>Rafał</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Rogoziński</foaf:surname>
                        <foaf:givenname>Marek</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Elasticsearch server: create a fast, scalable, and flexible search solution with the emerging open source search server, ElasticSearch</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781849518444 1849518440</dc:identifier>
        <z:shortTitle>Elasticsearch server</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:0596514557">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
               <foaf:name>O'Reilly Media</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Fry</foaf:surname>
                        <foaf:givenname>Ben</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Visualizing Data: Exploring and Explaining Data with the Processing Environment</dc:title>
        <prism:edition>1 edition</prism:edition>
        <dc:date>January 11, 2008</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 0596514557</dc:identifier>
        <z:shortTitle>Visualizing Data</z:shortTitle>
        <z:libraryCatalog>Amazon.com</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:0387759360%209780387759364">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>New York; London</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Springer</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Chambers</foaf:surname>
                        <foaf:givenname>John M</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Software for data analysis programming with R</dc:title>
        <dc:date>2008</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 0387759360 9780387759364</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://dx.doi.org/10.1007/978-0-387-75936-4</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 11:57:08</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9780321834737%200321834739">
        <z:itemType>book</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Cairo</foaf:surname>
                        <foaf:givenname>Alberto</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>The functional art: an introduction to information graphics and visualization</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9780321834737 0321834739</dc:identifier>
        <z:shortTitle>The functional art</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9781933988665%20%201933988665">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Greenwich, Conn.</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Manning</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Marmanis</foaf:surname>
                        <foaf:givenname>Haralambos</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Babenko</foaf:surname>
                        <foaf:givenname>Dmitry</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Algorithms of the intelligent Web</dc:title>
        <dc:date>2009</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781933988665  1933988665</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:1782161627%209781782161622">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>[S.l.]</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Packt Publishing Limited</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Silva</foaf:surname>
                        <foaf:givenname>Francisco Javier Blanco</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Learning scipy for numerical and scientific computing.</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 1782161627 9781782161622</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9780387848570%200387848576">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>New York</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Springer</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Hastie</foaf:surname>
                        <foaf:givenname>Trevor</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Tibshirani</foaf:surname>
                        <foaf:givenname>Robert</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Friedman</foaf:surname>
                        <foaf:givenname>J. H</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_121"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Supervised learning (Machine learning)</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:title>The elements of statistical learning: data mining, inference, and prediction</dc:title>
        <dcterms:abstract>&quot;During the past decade there has been an explosion in computation and information technology. With it have come vast amounts of data in a variety of fields such as medicine, biology, finance, and marketing. The challenge of understanding these data has led to the development of new tools in the field of statistics, and spawned new areas such as data mining, machine learning, and bioinformatics. Many of these tools have common underpinnings but are often expressed with different terminology. This book describes the important ideas in these areas in a common conceptual framework. While the approach is statistical, the emphasis is on concepts rather than mathematics. Many examples are given, with a liberal use of color graphics&quot;--Jacket.</dcterms:abstract>
        <dc:date>2009</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9780387848570 0387848576</dc:identifier>
        <z:shortTitle>The elements of statistical learning</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <z:Attachment rdf:about="#item_121">
        <z:itemType>attachment</z:itemType>
        <dc:title>The Elements of Statistical Learning_ Data Mining, Inference, and Prediction - Trevor Hastie.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Book rdf:about="urn:isbn:1847197906%209781847197900">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Birmingham [u.a.]</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Packt Publ.</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Tosi</foaf:surname>
                        <foaf:givenname>Sandro</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Matplotlib for Python developers: build remarkable publication quality plots the easy way</dc:title>
        <dc:date>2009</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 1847197906 9781847197900</dc:identifier>
        <z:shortTitle>Matplotlib for Python developers</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9780521518147%200521518148">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Cambridge; New York</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Cambridge University Press</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Barber</foaf:surname>
                        <foaf:givenname>David</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Bayesian reasoning and machine learning</dc:title>
        <dcterms:abstract>&quot;Machine learning methods extract value from vast data sets quickly and with modest resources. They are established tools in a wide range of industrial applications, including search engines, DNA sequencing, stock market analysis, and robot locomotion, and their use is spreading rapidly. People who know the methods have their choice of rewarding jobs. This hands-on text opens these opportunities to computer science students with modest mathematical backgrounds. It is designed for final-year undergraduates and master's students with limited background in linear algebra and calculus. Comprehensive and coherent, it develops everything from basic reasoning to advanced techniques within the framework of graphical models. Students learn more than a menu of techniques, they develop analytical and problem-solving skills that equip them for the real world. Numerous examples and exercises, both computer based and theoretical, are included in every chapter. Resources for students and instructors, including a MATLAB toolbox, are available online&quot;-- &quot;Vast amounts of data present amajor challenge to all thoseworking in computer science, and its many related fields, who need to process and extract value from such data. Machine learning technology is already used to help with this task in a wide range of industrial applications, including search engines, DNA sequencing, stock market analysis and robot locomotion. As its usage becomes more widespread, no student should be without the skills taught in this book. Designed for final-year undergraduate and graduate students, this gentle introduction is ideally suited to readers without a solid background in linear algebra and calculus. It covers everything from basic reasoning to advanced techniques in machine learning, and rucially enables students to construct their own models for real-world problems by teaching them what lies behind the methods. Numerous examples and exercises are included in the text. Comprehensive resources for students and instructors are available online&quot;--</dcterms:abstract>
        <dc:date>2011</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9780521518147 0521518148</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <rdf:Description rdf:about="https://www.usenix.org/system/files/conference/osdi12/osdi12-final-126.pdf">
        <z:itemType>conferencePaper</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kyrola</foaf:surname>
                        <foaf:givenname>Aapo</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Blelloch</foaf:surname>
                        <foaf:givenname>Guy</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Guestrin</foaf:surname>
                        <foaf:givenname>Carlos</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_246"/>
        <dc:title>GraphChi: Large-scale graph computation on just a PC</dc:title>
        <dc:date>2012</dc:date>
        <bib:pages>31–46</bib:pages>
        <z:shortTitle>GraphChi</z:shortTitle>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://www.usenix.org/system/files/conference/osdi12/osdi12-final-126.pdf</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-09 10:07:27</dcterms:dateSubmitted>
        <z:libraryCatalog>Google Scholar</z:libraryCatalog>
    </rdf:Description>
    <z:Attachment rdf:about="#item_246">
        <z:itemType>attachment</z:itemType>
        <dc:title>Kyrola_et_al_2012_GraphChi.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Book rdf:about="urn:isbn:9780596516499">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                        <vcard:locality>Beijing ; Cambridge [Mass.]</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Bird</foaf:surname>
                        <foaf:givenname>Steven</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <bib:contributors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Klein</foaf:surname>
                        <foaf:givenname>Ewan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Loper</foaf:surname>
                        <foaf:givenname>Edward</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:contributors>
        <link:link rdf:resource="#item_75"/>
        <dc:subject>
            <z:AutomaticTag>
                <rdf:value>Natural language processing (Computer science)</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Python (Computer program language)</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Python &lt;Programmiersprache></rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Sprachverarbeitung</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:title>Natural language processing with Python</dc:title>
        <prism:edition>1st ed</prism:edition>
        <dc:date>2009</dc:date>
        <z:numPages>479</z:numPages>
        <dc:identifier>ISBN 9780596516499</dc:identifier>
        <z:libraryCatalog>Library of Congress ISBN</z:libraryCatalog>
        <dc:subject>
           <dcterms:LCC><rdf:value>QA76.73.P98 B57 2009</rdf:value></dcterms:LCC>
        </dc:subject>
    </bib:Book>
    <z:Attachment rdf:about="#item_75">
        <z:itemType>attachment</z:itemType>
        <dc:title>Natural Language Processing With Python - Steven Bird.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Book rdf:about="urn:isbn:9781449317126">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
               <foaf:name>O'Reilly Media, Inc.</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Loukides</foaf:surname>
                        <foaf:givenname>Mike</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_140"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computers / Data Modeling &amp; Design</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computers / Data Processing</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computers / Databases / Data Mining</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:title>The Evolution of Data Products</dc:title>
        <dcterms:abstract>This report examines the important shifts in data products. Drawing from diverse examples, including iTunes, Google's self-driving car, and patient monitoring, author Mike Loukides explores the &quot;disappearance&quot; of data, the power of combining data, and the difference between discovery and recommendation. Looking ahead, the analysis finds the real changes in our lives will come from products and companies that reveal data results, not the data itself.</dcterms:abstract>
        <dc:date>2011-09-14</dc:date>
        <z:numPages>16</z:numPages>
        <z:language>en</z:language>
        <dc:identifier>ISBN 9781449317126</dc:identifier>
        <z:libraryCatalog>Google Books</z:libraryCatalog>
    </bib:Book>
    <z:Attachment rdf:about="#item_140">
        <z:itemType>attachment</z:itemType>
        <dc:title>The Evolution of Data Products - Mike Loukides.azw3</dc:title>
        <link:type>application/octet-stream</link:type>
    </z:Attachment>
    <bib:Data rdf:about="https://pypi.python.org/pypi/QuantLib-Python">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ballabio</foaf:surname>
                        <foaf:givenname>Luigi</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>QuantLib-Python</dc:title>
        <dc:date>17:44:29</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://pypi.python.org/pypi/QuantLib-Python</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-09 17:44:29</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Document rdf:about="http://software-carpentry.org/blog/2013/05/rational-computing-process.html">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Wilson</foaf:surname>
                        <foaf:givenname>Greg</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Software Carpentry: A Rational Computing Process: How and Why to Fake It</dc:title>
        <dc:date>23:04:03</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://software-carpentry.org/blog/2013/05/rational-computing-process.html</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 23:04:03</dcterms:dateSubmitted>
    </bib:Document>
    <bib:Document rdf:about="http://wiki.apache.org/solr/SolrEcosystem">
        <z:itemType>webpage</z:itemType>
        <dcterms:isPartOf>
           <z:Website></z:Website>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Apache Software Foundation</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_20"/>
        <dc:title>SolrEcosystem</dc:title>
        <dc:date>23:05:31</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://wiki.apache.org/solr/SolrEcosystem</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 23:05:31</dcterms:dateSubmitted>
    </bib:Document>
    <z:Attachment rdf:about="#item_20">
        <z:itemType>attachment</z:itemType>
        <dc:title>SolrEcosystem - Solr Wiki - Apache Software Foundation.azw3</dc:title>
        <link:type>application/octet-stream</link:type>
    </z:Attachment>
    <bib:Document rdf:about="http://www.orzota.com/step-by-step-mapreduce-programming/">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Meru</foaf:surname>
                        <foaf:givenname>Varad</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Step-by-step MapReduce Programming</dc:title>
        <dc:date>23:22:08</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.orzota.com/step-by-step-mapreduce-programming/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 23:22:08</dcterms:dateSubmitted>
    </bib:Document>
    <bib:Data rdf:about="https://github.com/yahoo/storm-yarn">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Yahoo</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Storm-yarn</dc:title>
        <dcterms:abstract>Storm-yarn enables Storm clusters to be deployed into machines managed by Hadoop YARN.</dcterms:abstract>
        <dc:date>10:10:02</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/yahoo/storm-yarn</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-09 10:10:02</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="http://docs.lucidworks.com/display/bigdata/System+Architecture">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>LucidWorks</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>LucidWorks Big Data</dc:title>
        <dc:date>23:22:51</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://docs.lucidworks.com/display/bigdata/System+Architecture</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 23:22:51</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/jpatanooga/KnittingBoar">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Patterson</foaf:surname>
                        <foaf:givenname>Josh</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Knitting Boar</dc:title>
        <dcterms:abstract>Knitting Boar is an experimental machine learning application which parallelizes Mahout's Stochastic Gradient Descent on top of a new YARN based framework for Hadoop called Iterative Reduce</dcterms:abstract>
        <dc:date>10:12:22</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/jpatanooga/KnittingBoar</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-09 10:12:22</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="http://falcon.incubator.apache.org/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Apache Software Foundation</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Apache Falcon</dc:title>
        <dcterms:abstract>Apache Falcon is a data processing and management solution for Hadoop designed for data motion, coordination of data pipelines, lifecycle management, and data discovery. Falcon enables end consumers to quickly onboard their data and its associated processing and management tasks on Hadoop clusters.</dcterms:abstract>
        <dc:date>10:17:04</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://falcon.incubator.apache.org/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-09 10:17:04</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Document rdf:about="http://agbeat.com/tech-news/visualizing-the-differences-between-ux-and-ui/">
        <z:itemType>webpage</z:itemType>
        <dcterms:isPartOf>
           <z:Website></z:Website>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>AGBeat</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_5"/>
        <dc:title>Visualizing the differences between UX and UI</dc:title>
        <dc:date>23:24:08</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://agbeat.com/tech-news/visualizing-the-differences-between-ux-and-ui/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 23:24:08</dcterms:dateSubmitted>
    </bib:Document>
    <z:Attachment rdf:about="#item_5">
        <z:itemType>attachment</z:itemType>
        <dc:title>Visualizing the differences bet - agbeat.com.azw3</dc:title>
        <link:type>application/octet-stream</link:type>
    </z:Attachment>
    <bib:Book rdf:about="urn:isbn:9781449361303">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
               <foaf:name>O'Reilly Media, Incorporated</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Junqueira</foaf:surname>
                        <foaf:givenname>Flavio</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Reed</foaf:surname>
                        <foaf:givenname>Benjamin</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computers / Data Processing</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computers / Programming / Parallel</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computers / Programming Languages / General</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:title>Zookeeper: Distributed Process Coordination</dc:title>
        <dcterms:abstract>If you're involved in large Hadoop projects, this book shows you how ZooKeeper simplifies the task of implementing a distributed system. Implementing coordination tasks with ZooKeeper is not entirely trivial. There are still subtle points and caveats to watch out for. With this book, ZooKeeper contributors Flavio Junqueira and Benjamin Reed provide good practices for building systems with this Apache software tool.This book also: Introduces a master-worker architecture as a running example Includes examples of coordination primitives in the master-worker architecture, in addition to examples of real systems with those requirements Presents information on handling events and changes in the system, specifically dealing with disconnected events and session expirations Shows you how to download and install a Zookeeper release, including how to choose a cluster configuration</dcterms:abstract>
        <dc:date>2013-12-22</dc:date>
        <z:numPages>225</z:numPages>
        <z:language>en</z:language>
        <dc:identifier>ISBN 9781449361303</dc:identifier>
        <z:shortTitle>Zookeeper</z:shortTitle>
        <z:libraryCatalog>Google Books</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9781849689786">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
               <foaf:name>Packt Publishing, Limited</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Nandeshwar</foaf:surname>
                        <foaf:givenname>Ashutosh</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Tableau Data Visualization Cookbook</dc:title>
        <dc:date>2013-06-30</dc:date>
        <z:numPages>200</z:numPages>
        <z:language>en</z:language>
        <dc:identifier>ISBN 9781849689786</dc:identifier>
        <z:libraryCatalog>Google Books</z:libraryCatalog>
    </bib:Book>
    <bib:Document rdf:about="http://notes.mindprince.in/2013/06/07/sparse-matrix-multiplication-using-sql.html">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Agarwal</foaf:surname>
                        <foaf:givenname>Rohit</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>sql</dc:subject>
        <dc:title>Sparse matrix multiplication using SQL</dc:title>
        <dc:date>23:48:56</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://notes.mindprince.in/2013/06/07/sparse-matrix-multiplication-using-sql.html</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 23:48:56</dcterms:dateSubmitted>
    </bib:Document>
    <bib:Document rdf:about="http://techblog.netflix.com/2013/03/system-architectures-for.html">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Xavier</foaf:surname>
                        <foaf:givenname>Amatriain</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Basilico</foaf:surname>
                        <foaf:givenname>Justin</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>The Netflix Tech Blog: System Architectures for Personalization and Recommendation</dc:title>
        <dc:date>23:52:37</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://techblog.netflix.com/2013/03/system-architectures-for.html</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 23:52:37</dcterms:dateSubmitted>
    </bib:Document>
    <bib:Document rdf:about="http://wikibon.org/w/index.php?title=Big_Data_Vendor_Revenue_and_Market_Forecast_2012-2017&amp;printable=yes">
        <z:itemType>webpage</z:itemType>
        <dcterms:isPartOf>
           <z:Website></z:Website>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kelly</foaf:surname>
                        <foaf:givenname>Jeff</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_47"/>
        <dc:title>Big Data Vendor Revenue and Market Forecast 2012-2017</dc:title>
        <dc:date>23:56:31</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://wikibon.org/w/index.php?title=Big_Data_Vendor_Revenue_and_Market_Forecast_2012-2017&amp;printable=yes</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-05 23:56:31</dcterms:dateSubmitted>
    </bib:Document>
    <z:Attachment rdf:about="#item_47">
        <z:itemType>attachment</z:itemType>
        <dc:title>Big Data Vendor Revenue and Mar - Jeff Kelly.azw3</dc:title>
        <link:type>application/octet-stream</link:type>
    </z:Attachment>
    <bib:Book rdf:about="urn:isbn:9780672329784">
        <z:itemType>book</z:itemType>
        <dcterms:isPartOf>
           <bib:Series><dc:title>Developer's library</dc:title></bib:Series>
        </dcterms:isPartOf>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Upper Saddle River, NJ</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Addison-Wesley</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Beazley</foaf:surname>
                        <foaf:givenname>David M</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_70"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Python (Computer program language)</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:title>Python essential reference</dc:title>
        <prism:edition>4th ed</prism:edition>
        <dc:date>2009</dc:date>
        <z:numPages>717</z:numPages>
        <dc:identifier>ISBN 9780672329784</dc:identifier>
        <z:libraryCatalog>Library of Congress ISBN</z:libraryCatalog>
        <dc:subject>
           <dcterms:LCC><rdf:value>QA76.73.P98 B43 2009</rdf:value></dcterms:LCC>
        </dc:subject>
    </bib:Book>
    <z:Attachment rdf:about="#item_70">
        <z:itemType>attachment</z:itemType>
        <dc:title>Python Essential Reference - David Beazley.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Book rdf:about="urn:isbn:9780596809157">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Beijing ; Sebastopol, CA</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Teetor</foaf:surname>
                        <foaf:givenname>Paul</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_158"/>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Data processing</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Graphic methods Data processing</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Mathematical statistics</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Multiple comparisons (Statistics)</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>R (Computer program language)</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>statistics</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:title>R cookbook</dc:title>
        <prism:edition>1st ed</prism:edition>
        <dc:date>2011</dc:date>
        <z:numPages>413</z:numPages>
        <dc:identifier>ISBN 9780596809157</dc:identifier>
        <z:libraryCatalog>Library of Congress ISBN</z:libraryCatalog>
        <dc:subject>
           <dcterms:LCC><rdf:value>QA276.45.R3 T44 2011</rdf:value></dcterms:LCC>
        </dc:subject>
    </bib:Book>
    <z:Attachment rdf:about="#item_158">
        <z:itemType>attachment</z:itemType>
        <dc:title>R Cookbook - Paul Teetor.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Data rdf:about="https://github.com/rcongiu/Hive-JSON-Serde">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Congiu</foaf:surname>
                        <foaf:givenname>Roberto</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Hive-JSON-Serde</dc:title>
        <dcterms:abstract>Hive-JSON-Serde - Read - Write JSON SerDe for Apache Hive.</dcterms:abstract>
        <dc:date>10:18:48</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/rcongiu/Hive-JSON-Serde</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-09 10:18:48</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Book rdf:about="urn:isbn:9781430245544%20%201430245549">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>New York</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Apress : Distributed to the book trade worldwide by Springer Science+Business Media</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Pace</foaf:surname>
                        <foaf:givenname>Larry</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Beginning R: an introduction to statistical programming</dc:title>
        <dcterms:abstract>&quot;Beginning R: An Introduction to Statistical Programming shows you how to use this open-source language and take advantage of its extensive statistical and graphing capabilities. Indeed, R has become the de facto standard for doing, teaching, and learning computational statistics. With this book, you'll learn the language by using it right from the start--an approach giving valuable, firsthand experience&quot;--P. [4] of cover.</dcterms:abstract>
        <dc:date>2012</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781430245544  1430245549</dc:identifier>
        <z:shortTitle>Beginning R</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9781449307110">
        <z:itemType>book</z:itemType>
        <dcterms:isPartOf>
            <bib:Series>
               <dc:title>Probability and statistics for programmers</dc:title>
            </bib:Series>
        </dcterms:isPartOf>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Sebastopol, CA</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly Media</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Downey</foaf:surname>
                        <foaf:givenname>Allen</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_94"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer programs</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>statistics</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Study and teaching</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:title>Think stats</dc:title>
        <prism:edition>1st ed</prism:edition>
        <dc:date>2011</dc:date>
        <z:numPages>119</z:numPages>
        <dc:identifier>ISBN 9781449307110</dc:identifier>
        <z:libraryCatalog>Library of Congress ISBN</z:libraryCatalog>
        <dc:subject>
           <dcterms:LCC><rdf:value>QA276.4 .D69 2011</rdf:value></dcterms:LCC>
        </dc:subject>
    </bib:Book>
    <z:Attachment rdf:about="#item_94">
        <z:itemType>attachment</z:itemType>
        <dc:title>Think Stats - Allen B. Downey.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Book rdf:about="urn:isbn:9781449303143">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                        <vcard:locality>Sebastopol, CA ; Beijing [China]</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Warden</foaf:surname>
                        <foaf:givenname>Pete</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Application software</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer software</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Development</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Web services</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Web site development</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:title>Data source handbook</dc:title>
        <prism:edition>1st ed</prism:edition>
        <dc:date>2011</dc:date>
        <z:numPages>32</z:numPages>
        <dc:identifier>ISBN 9781449303143</dc:identifier>
        <z:libraryCatalog>Library of Congress ISBN</z:libraryCatalog>
        <dc:subject>
           <dcterms:LCC><rdf:value>TK5105.88813 W27 2011</rdf:value></dcterms:LCC>
        </dc:subject>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9781449314637%20%201449314635">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Bejing [etc.]</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Downey</foaf:surname>
                        <foaf:givenname>Allen B</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_97"/>
        <dc:title>Think complexity</dc:title>
        <dc:date>2012</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781449314637  1449314635</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <z:Attachment rdf:about="#item_97">
        <z:itemType>attachment</z:itemType>
        <dc:title>Think Complexity_ Complexity Science and - Allen B. Downey.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Book rdf:about="urn:isbn:9781449320492%20%20144932049X">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Sebastopol, CA</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Garnaat</foaf:surname>
                        <foaf:givenname>Mitch</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_116"/>
        <dc:title>Python and AWS cookbook</dc:title>
        <dcterms:abstract>&quot;If you intend to use Amazon Web Services (AWS) for remote computing and storage, Python is an ideal programming language for developing applications and controlling your cloud-based infrastructure. This cookbook gets you started with more than two dozen recipes for using Python with AWS, based on the author's boto library&quot;--Provided by publisher.</dcterms:abstract>
        <dc:date>2012</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781449320492  144932049X</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://proquest.safaribooksonline.com/9781449308100</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 07:55:53</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <z:Attachment rdf:about="#item_116">
        <z:itemType>attachment</z:itemType>
        <dc:title>Python and AWS Cookbook - Mitch Garnaat.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Book rdf:about="urn:isbn:9781449305000%201449305008">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Sebastopol, CA</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Craig</foaf:surname>
                        <foaf:givenname>Terence</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ludloff</foaf:surname>
                        <foaf:givenname>Mary E</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_88"/>
        <dc:title>Privacy and big data</dc:title>
        <dc:date>2011</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781449305000 1449305008</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <z:Attachment rdf:about="#item_88">
        <z:itemType>attachment</z:itemType>
        <dc:title>Privacy and Big Data - Terence Craig.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://sites.google.com/site/atlediadema/training-documents/Google%20Technical%20Report%20-%20dapper,%202010.pdf">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal><dc:title>Google research</dc:title></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Sigelman</foaf:surname>
                        <foaf:givenname>Benjamin H.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Barroso</foaf:surname>
                        <foaf:givenname>Luiz Andre</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Burrows</foaf:surname>
                        <foaf:givenname>Mike</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Stephenson</foaf:surname>
                        <foaf:givenname>Pat</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Plakal</foaf:surname>
                        <foaf:givenname>Manoj</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Beaver</foaf:surname>
                        <foaf:givenname>Donald</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Jaspan</foaf:surname>
                        <foaf:givenname>Saul</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Shanbhag</foaf:surname>
                        <foaf:givenname>Chandan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_363"/>
        <dc:title>Dapper, a large-scale distributed systems tracing infrastructure</dc:title>
        <dc:date>2010</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://sites.google.com/site/atlediadema/training-documents/Google%20Technical%20Report%20-%20dapper,%202010.pdf</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 12:50:42</dcterms:dateSubmitted>
        <z:libraryCatalog>Google Scholar</z:libraryCatalog>
    </bib:Article>
    <z:Attachment rdf:about="#item_363">
        <z:itemType>attachment</z:itemType>
        <dc:title>Sigelman_et_al_2010_Dapper,_a_large-scale_distributed_systems_tracing_infrastructure.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Book rdf:about="urn:isbn:9781449344979%20%201449344976">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Sebastopol, CA</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly Media</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>O'Reilly</foaf:surname>
                        <foaf:givenname>Tim</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_148"/>
        <dc:title>How data science is transforming health care</dc:title>
        <dc:date>2012</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781449344979  1449344976</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://search.ebscohost.com/login.aspx?direct=true&amp;scope=site&amp;db=nlebk&amp;db=nlabk&amp;AN=537815</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 07:56:19</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <z:Attachment rdf:about="#item_148">
        <z:itemType>attachment</z:itemType>
        <dc:title>How Data Science Is Transforming Health  - Tim O'Reilly.azw3</dc:title>
        <link:type>application/octet-stream</link:type>
    </z:Attachment>
    <bib:Data rdf:about="https://github.com/voldemort/voldemort">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Voldemort Development Team</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Voldemort</dc:title>
        <dcterms:abstract>An open source clone of Amazon's Dynamo.</dcterms:abstract>
        <dc:date>10:22:32</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/voldemort/voldemort</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-09 10:22:32</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Book rdf:about="urn:isbn:9781449323622%20%201449323626%20%209781449323615%20%201449323618%20%201449319793%209781449319793">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Sebastopol, CA</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly Media</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>McKinney</foaf:surname>
                        <foaf:givenname>Wes</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_146"/>
        <dc:title>Python for data analysis</dc:title>
        <dc:date>2012</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781449323622  1449323626  9781449323615  1449323618  1449319793 9781449319793</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://proquest.safaribooksonline.com/?fpi=9781449323592</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 07:56:25</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <z:Attachment rdf:about="#item_146">
        <z:itemType>attachment</z:itemType>
        <dc:title>Python for Data Analysis - Wes McKinney.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Book rdf:about="urn:isbn:1449340377%20%209781449340377">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Beijing</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Beazley</foaf:surname>
                        <foaf:givenname>David M</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_72"/>
        <dc:title>Python cookbook</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 1449340377  9781449340377</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <z:Attachment rdf:about="#item_72">
        <z:itemType>attachment</z:itemType>
        <dc:title>Python Cookbook - David Beazley.epub</dc:title>
        <link:type>application/octet-stream</link:type>
    </z:Attachment>
    <bib:Book rdf:about="urn:isbn:9781449332037%20%20144933203X%20%209781449332020%20%201449332021">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Sebastopol, CA</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Downey</foaf:surname>
                        <foaf:givenname>Allen</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_95"/>
        <dc:title>Think Python</dc:title>
        <dc:date>2012</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781449332037  144933203X  9781449332020  1449332021</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.contentreserve.com/TitleInfo.asp?ID={8BDDEF5E-F64A-4212-A868-9B60E742EC40}&amp;Format=50</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 07:56:31</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <z:Attachment rdf:about="#item_95">
        <z:itemType>attachment</z:itemType>
        <dc:title>Think Python - Allen B. Downey.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/wesm/intro-to-python-for-financial-data-analysis">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>McKinney</foaf:surname>
                        <foaf:givenname>Wes</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <dc:title>Intro to Python for Financial Data Analysis</dc:title>
        <z:type>Technology</z:type>
        <dc:date>Fri Jun 22  2012</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/wesm/intro-to-python-for-financial-data-analysis</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 08:30:12</dcterms:dateSubmitted>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <bib:Data rdf:about="http://aws.amazon.com/dynamodb/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Amazon Web Services</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Amazon DynamoDB</dc:title>
        <dc:date>10:25:15</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://aws.amazon.com/dynamodb/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-09 10:25:15</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Book rdf:about="urn:isbn:9781615472123%20%201615472126%20%209781615473328%20%201615473327%20%209781615471126%20%20161547112X">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Uniontown, Ohio</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Holy Macro! Books</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Collie</foaf:surname>
                        <foaf:givenname>Rob</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_86"/>
        <dc:title>DAX formulas for PowerPivot</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781615472123  1615472126  9781615473328  1615473327  9781615471126  161547112X</dc:identifier>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.books24x7.com/marc.asp?bookid=50324</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 07:57:21</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <z:Attachment rdf:about="#item_86">
        <z:itemType>attachment</z:itemType>
        <dc:title>DAX Formulas for PowerPivot_ The Excel P - Rob Collie.mobi</dc:title>
        <link:type>application/octet-stream</link:type>
    </z:Attachment>
    <bib:Data rdf:about="https://github.com/mher/chartkick.py">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Movsisyan</foaf:surname>
                        <foaf:givenname>Mher</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Chartkick.py</dc:title>
        <dcterms:abstract>chartkick.py - Create beautiful Javascript charts with minimal code</dcterms:abstract>
        <dc:date>08:32:06</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/mher/chartkick.py</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 08:32:06</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/ankane/chartkick">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kane</foaf:surname>
                        <foaf:givenname>Andrew</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Chartkick</dc:title>
        <dcterms:abstract>chartkick - Create beautiful Javascript charts with one line of Ruby</dcterms:abstract>
        <dc:date>08:32:42</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/ankane/chartkick</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 08:32:42</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="http://azkaban.github.io/azkaban2/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>LinkedIn</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Azkaban</dc:title>
        <dcterms:abstract>Azkaban is a batch workflow job scheduler</dcterms:abstract>
        <dc:date>10:27:43</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://azkaban.github.io/azkaban2/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-09 10:27:43</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/wrobstory/vincent">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Story</foaf:surname>
                        <foaf:givenname>Rob</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>d3</dc:subject>
        <dc:title>Vincent</dc:title>
        <dcterms:abstract>vincent - A Python to Vega translator</dcterms:abstract>
        <dc:date>08:34:28</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/wrobstory/vincent</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 08:34:28</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Book rdf:about="urn:isbn:9781849686068%20%201849686068">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Birmingham</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Packt Pub.</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>García</foaf:surname>
                        <foaf:givenname>Miguel</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Harmsen</foaf:surname>
                        <foaf:givenname>Barry</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_115"/>
        <dc:title>QlikView 11 for developers: develop business intelligence applications with QlikView 11</dc:title>
        <dc:date>2012</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781849686068  1849686068</dc:identifier>
        <z:shortTitle>QlikView 11 for developers</z:shortTitle>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <z:Attachment rdf:about="#item_115">
        <z:itemType>attachment</z:itemType>
        <dc:title>QlikView 11 for Developers - Barry Harmsen.epub</dc:title>
        <link:type>application/octet-stream</link:type>
    </z:Attachment>
    <bib:Book rdf:about="urn:isbn:9781849517959%20%201849517959">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Birmingham</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Packt Pub.</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Vantomme</foaf:surname>
                        <foaf:givenname>Jan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Processing 2 creative programming cookbook: over 90 highly-effective recipes to unleash your creativity with interactive art, graphics, computer vision, 3D, and more</dc:title>
        <dc:date>2012</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781849517959  1849517959</dc:identifier>
        <z:shortTitle>Processing 2 creative programming cookbook</z:shortTitle>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://search.ebscohost.com/login.aspx?direct=true&amp;scope=site&amp;db=nlebk&amp;db=nlabk&amp;AN=492090</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 07:58:52</dcterms:dateSubmitted>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Book rdf:about="urn:isbn:9781849517249%20184951724X">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Birmingham</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Packt Publishing, Limited</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Phillips</foaf:surname>
                        <foaf:givenname>Lee</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>ebrary</foaf:surname>
                        <foaf:givenname>Inc</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Gnuplot Cookbook.</dc:title>
        <dcterms:abstract>Annotation.</dcterms:abstract>
        <dc:date>2012</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781849517249 184951724X</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Data rdf:about="https://github.com/wrobstory/bearcart">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Story</foaf:surname>
                        <foaf:givenname>Rob</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Bearcart</dc:title>
        <dcterms:abstract>bearcart - Creating Rickshaw.js visualizations with Python Pandas</dcterms:abstract>
        <dc:date>08:35:13</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/wrobstory/bearcart</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 08:35:13</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Book rdf:about="urn:isbn:9781935182399">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Shelter Island, NY</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Manning</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kabacoff</foaf:surname>
                        <foaf:givenname>Robert</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_133"/>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Data processing</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>Graphic methods</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>R (Computer program language)</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>statistics</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:title>R in action: data analysis and graphics with R</dc:title>
        <dc:date>2011</dc:date>
        <z:numPages>447</z:numPages>
        <dc:identifier>ISBN 9781935182399</dc:identifier>
        <z:shortTitle>R in action</z:shortTitle>
        <z:libraryCatalog>Library of Congress ISBN</z:libraryCatalog>
        <dc:subject>
           <dcterms:LCC><rdf:value>QA276.45.R3 K33 2011</rdf:value></dcterms:LCC>
        </dc:subject>
    </bib:Book>
    <z:Attachment rdf:about="#item_133">
        <z:itemType>attachment</z:itemType>
        <dc:title>R in Action - Robert Kabacoff.epub</dc:title>
        <link:type>application/octet-stream</link:type>
    </z:Attachment>
    <bib:Data rdf:about="https://github.com/twitter/zipkin">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Twitter</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Zipkin</dc:title>
        <dcterms:abstract>zipkin - Zipkin is a distributed tracing system</dcterms:abstract>
        <dc:date>12:51:39</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/twitter/zipkin</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 12:51:39</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Report rdf:about="http://daoudclarke.github.io/guide.pdf">
        <z:itemType>report</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Clarke</foaf:surname>
                        <foaf:givenname>Daoud</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Seven steps to success: machine learning in practice</dc:title>
        <dcterms:abstract>This guide will help you apply machine learning effectively to solve practical problems within your organisation. I’ll talk about issues that I’ve encountered applying machine learning in industry.</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://daoudclarke.github.io/guide.pdf</rdf:value>
            </dcterms:URI>
        </dc:identifier>
    </bib:Report>
    <bib:Data rdf:about="https://github.com/infochimps-labs/wonderdog">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Infochimps</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Wonderdog</dc:title>
        <dcterms:abstract>wonderdog - Bulk loading for elastic search</dcterms:abstract>
        <dc:date>10:30:31</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/infochimps-labs/wonderdog</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-09 10:30:31</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/amplab/shark">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>AMPLab at UC Berkeley</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Shark</dc:title>
        <dcterms:abstract>shark - Hive on Spark</dcterms:abstract>
        <dc:date>08:52:11</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/amplab/shark</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 08:52:11</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Article rdf:about="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.226.772">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lin</foaf:surname>
                        <foaf:givenname>Liang</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lychagina</foaf:surname>
                        <foaf:givenname>Vera</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Liu</foaf:surname>
                        <foaf:givenname>Weiran</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kwon</foaf:surname>
                        <foaf:givenname>Younghee</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Mittal</foaf:surname>
                        <foaf:givenname>Sagar</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Wong</foaf:surname>
                        <foaf:givenname>Michael</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_318"/>
        <dc:title>Tenzing a sql implementation on the mapreduce framework</dc:title>
        <dc:date>2011</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.226.772</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 08:57:19</dcterms:dateSubmitted>
        <z:libraryCatalog>Google Scholar</z:libraryCatalog>
    </bib:Article>
    <z:Attachment rdf:about="#item_318">
        <z:itemType>attachment</z:itemType>
        <dc:title>Lin_et_al_2011_Tenzing_a_sql_implementation_on_the_mapreduce_framework.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Data rdf:about="https://github.com/cloudera/htrace">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Cloudera</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>HTrace</dc:title>
        <dcterms:abstract>Contribute to htrace development by creating an account on GitHub.</dcterms:abstract>
        <dc:date>12:52:47</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/cloudera/htrace</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 12:52:47</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/mattb/pig-redis">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Biddulph</foaf:surname>
                        <foaf:givenname>Matt</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Pig RedisStorer</dc:title>
        <dcterms:abstract>pig-redis - Redis bulk-loader for Apache Pig</dcterms:abstract>
        <dc:date>10:31:28</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/mattb/pig-redis</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-09 10:31:28</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="http://www.vertica.com/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Hewlett-Packard</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Vertica</dc:title>
        <dc:date>09:00:24</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://www.vertica.com/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 09:00:24</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Article rdf:about="http://dl.acm.org/citation.cfm?id=2350259">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
                <dc:title>Proceedings of the VLDB Endowment</dc:title>
                <prism:volume>5</prism:volume>
                <prism:number>11</prism:number>
            </bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Hall</foaf:surname>
                        <foaf:givenname>Alexander</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Bachmann</foaf:surname>
                        <foaf:givenname>Olaf</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Büssow</foaf:surname>
                        <foaf:givenname>Robert</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>G\uanceanu</foaf:surname>
                        <foaf:givenname>Silviu</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Nunkesser</foaf:surname>
                        <foaf:givenname>Marc</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_249"/>
        <dc:title>Processing a trillion cells per mouse click</dc:title>
        <bib:pages>1436–1446</bib:pages>
        <dc:date>2012</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://dl.acm.org/citation.cfm?id=2350259</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 09:01:48</dcterms:dateSubmitted>
        <z:libraryCatalog>Google Scholar</z:libraryCatalog>
    </bib:Article>
    <z:Attachment rdf:about="#item_249">
        <z:itemType>attachment</z:itemType>
        <dc:title>Hall_et_al_2012_Processing_a_trillion_cells_per_mouse_click.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Data rdf:about="https://code.google.com/p/javamelody/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Vernat</foaf:surname>
                        <foaf:givenname>Emeric</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>JavaMelody</dc:title>
        <dcterms:abstract>monitoring of JavaEE applications - Google Project Hosting</dcterms:abstract>
        <dc:date>12:53:37</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://code.google.com/p/javamelody/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 12:53:37</dcterms:dateSubmitted>
    </bib:Data>
    <rdf:Description rdf:about="http://dl.acm.org/citation.cfm?id=2452456">
        <z:itemType>conferencePaper</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Heule</foaf:surname>
                        <foaf:givenname>Stefan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Nunkesser</foaf:surname>
                        <foaf:givenname>Marc</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Hall</foaf:surname>
                        <foaf:givenname>Alexander</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_239"/>
        <dc:title>HyperLogLog in practice: algorithmic engineering of a state of the art cardinality estimation algorithm</dc:title>
        <dc:date>2013</dc:date>
        <bib:pages>683–692</bib:pages>
        <z:shortTitle>HyperLogLog in practice</z:shortTitle>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://dl.acm.org/citation.cfm?id=2452456</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 09:01:48</dcterms:dateSubmitted>
        <z:libraryCatalog>Google Scholar</z:libraryCatalog>
    </rdf:Description>
    <z:Attachment rdf:about="#item_239">
        <z:itemType>attachment</z:itemType>
        <dc:title>Heule_et_al_2013_HyperLogLog_in_practice.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://sites.computer.org/debull/A12june/A12JUN-CD.pdf#page=35">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
                <dc:title>IEEE Data Eng. Bull.</dc:title>
                <prism:volume>35</prism:volume>
                <prism:number>2</prism:number>
            </bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Goodhope</foaf:surname>
                        <foaf:givenname>Ken</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Koshy</foaf:surname>
                        <foaf:givenname>Joel</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kreps</foaf:surname>
                        <foaf:givenname>Jay</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Narkhede</foaf:surname>
                        <foaf:givenname>Neha</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Park</foaf:surname>
                        <foaf:givenname>Richard</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Rao</foaf:surname>
                        <foaf:givenname>Jun</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ye</foaf:surname>
                        <foaf:givenname>Victor Yang</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_236"/>
        <dc:title>Building LinkedIn's Real-time Activity Data Pipeline.</dc:title>
        <bib:pages>33–45</bib:pages>
        <dc:date>2012</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://sites.computer.org/debull/A12june/A12JUN-CD.pdf#page=35</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 09:01:48</dcterms:dateSubmitted>
        <z:libraryCatalog>Google Scholar</z:libraryCatalog>
    </bib:Article>
    <z:Attachment rdf:about="#item_236">
        <z:itemType>attachment</z:itemType>
        <dc:title>Goodhope_et_al_2012_Building_LinkedIn's_Real-time_Activity_Data_Pipeline.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://arxiv.org/abs/1211.6176">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
               <dc:title>arXiv preprint arXiv:1211.6176</dc:title>
            </bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Xin</foaf:surname>
                        <foaf:givenname>Reynold</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Rosen</foaf:surname>
                        <foaf:givenname>Josh</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Zaharia</foaf:surname>
                        <foaf:givenname>Matei</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Franklin</foaf:surname>
                        <foaf:givenname>Michael J.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Shenker</foaf:surname>
                        <foaf:givenname>Scott</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Stoica</foaf:surname>
                        <foaf:givenname>Ion</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_387"/>
        <dc:title>Shark: SQL and rich analytics at scale</dc:title>
        <dc:date>2012</dc:date>
        <z:shortTitle>Shark</z:shortTitle>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://arxiv.org/abs/1211.6176</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 09:01:48</dcterms:dateSubmitted>
        <z:libraryCatalog>Google Scholar</z:libraryCatalog>
    </bib:Article>
    <z:Attachment rdf:about="#item_387">
        <z:itemType>attachment</z:itemType>
        <dc:title>Xin_et_al_2012_Shark.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Data rdf:about="https://github.com/rhuss/jolokia">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Huß</foaf:surname>
                        <foaf:givenname>Roland</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Jolokia</dc:title>
        <dcterms:abstract>jolokia - JMX on Capsaicin</dcterms:abstract>
        <dc:date>12:58:01</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/rhuss/jolokia</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 12:58:01</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="http://samza.incubator.apache.org/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Apache Software Foundation</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Apache Samza</dc:title>
        <dcterms:abstract>Apache Samza is a distributed stream processing framework. It uses Apache Kafka for messaging, and Apache Hadoop YARN to provide fault tolerance, processor isolation, security, and resource management.</dcterms:abstract>
        <dc:date>10:42:52</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://samza.incubator.apache.org/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-09 10:42:52</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/mbostock/topojson">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Bostock</foaf:surname>
                        <foaf:givenname>Michael</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>d3</dc:subject>
        <dc:title>topojson</dc:title>
        <dcterms:abstract>topojson - An extension to GeoJSON that encodes topology.</dcterms:abstract>
        <dc:date>10:51:59</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/mbostock/topojson</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-09 10:51:59</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="http://www.cloudera.com/content/cloudera/en/products/cdh/impala.html">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Cloudera</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Impala</dc:title>
        <dc:date>09:02:47</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.cloudera.com/content/cloudera/en/products/cdh/impala.html</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 09:02:47</dcterms:dateSubmitted>
    </bib:Data>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/spark-project/deep-divewithsparkstreaming-tathagatadassparkmeetup20130617">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>spark-project</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <dc:title>Deep Dive with Spark Streaming - Tathagata  Das - Spark Meetup 2013...</dc:title>
        <dcterms:abstract>Slides from Tathagata Das's talk at the Spark Meetup entitled &quot;Deep Dive with Spark Streaming&quot; on June 17, 2013 in Sunnyvale California at Plug and Play. Tathagata Das is the lead developer on Spark Streaming and a PhD student in computer science in the UC Berkeley AMPLab.</dcterms:abstract>
        <dc:date>Sun Jun 23  2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/spark-project/deep-divewithsparkstreaming-tathagatadassparkmeetup20130617</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 09:04:34</dcterms:dateSubmitted>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <bib:Data rdf:about="http://zeromq.org/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>iMatix</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>ZeroMQ</dc:title>
        <dc:date>09:05:54</dc:date>
        <dc:identifier>
           <dcterms:URI><rdf:value>http://zeromq.org/</rdf:value></dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 09:05:54</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Book rdf:about="urn:isbn:9781449334062%20%201449334067%20%209781449334031%20%201449334032">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Beijing</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>O'Reilly</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Hintjens</foaf:surname>
                        <foaf:givenname>Pieter</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computers / Programming Languages / C</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:title>ZeroMQ</dc:title>
        <dc:date>2013</dc:date>
        <z:language>English</z:language>
        <dc:identifier>ISBN 9781449334062  1449334067  9781449334031  1449334032</dc:identifier>
        <z:libraryCatalog>Open WorldCat</z:libraryCatalog>
    </bib:Book>
    <bib:Data rdf:about="http://mahout.apache.org/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Apache Software Foundation</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Apache Mahout</dc:title>
        <dcterms:abstract>Scalable machine learning and data mining</dcterms:abstract>
        <dc:date>09:12:48</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://mahout.apache.org/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 09:12:48</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="http://oozie.apache.org/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Apache Software Foundation</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Apache Oozie</dc:title>
        <dcterms:abstract>Workflow Scheduler for Hadoop</dcterms:abstract>
        <dc:date>09:13:35</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://oozie.apache.org/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 09:13:35</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="http://zookeeper.apache.org/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Apache Software Foundation</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Apache ZooKeeper</dc:title>
        <dc:date>09:14:27</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://zookeeper.apache.org/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 09:14:27</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="http://lucene.apache.org/solr/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Apache Software Foundation</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Apache Solr</dc:title>
        <dc:date>09:15:23</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://lucene.apache.org/solr/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 09:15:23</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="http://lucene.apache.org/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Apache Software Foundation</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Apache Lucene</dc:title>
        <dc:date>09:15:57</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://lucene.apache.org/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 09:15:57</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="http://www.r-project.org/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>The R Foundation</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>The R Project</dc:title>
        <dc:date>09:16:32</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://www.r-project.org/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 09:16:32</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/RevolutionAnalytics/RHadoop">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Revolution Analytics</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>RHadoop</dc:title>
        <dcterms:abstract>RHadoop - rhadoop@revolutionanalytics.com</dcterms:abstract>
        <dc:date>09:19:01</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://github.com/RevolutionAnalytics/RHadoop</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 09:19:01</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/RevolutionAnalytics/rhbase">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Revolution Analytics</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>rhbase</dc:title>
        <dcterms:abstract>rhbase - A package that allows R developers to use Hadoop HBase</dcterms:abstract>
        <dc:date>09:20:00</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://github.com/RevolutionAnalytics/rhbase</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 09:20:00</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/RevolutionAnalytics/rhdfs">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Revolution Analytics</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>rhdfs</dc:title>
        <dcterms:abstract>rhdfs - A package that allows R developers to use Hadoop HDFS</dcterms:abstract>
        <dc:date>09:20:19</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/RevolutionAnalytics/rhdfs</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 09:20:19</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/RevolutionAnalytics/rmr2">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Revolution Analytics</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>rmr2</dc:title>
        <dcterms:abstract>rmr2 - A package that allows R developer to use Hadoop MapReduce</dcterms:abstract>
        <dc:date>09:20:34</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/RevolutionAnalytics/rmr2</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 09:20:34</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="http://www.datadr.org/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Guha</foaf:surname>
                        <foaf:givenname>Saptarshi</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <bib:contributors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Purdue University Department of Statistics</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:contributors>
        <dc:title>RHIPE</dc:title>
        <dc:date>09:23:09</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://www.datadr.org/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 09:23:09</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/hafen/trelliscope">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Hafen</foaf:surname>
                        <foaf:givenname>Ryan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Trelliscope</dc:title>
        <dcterms:abstract>trelliscope - Detailed Visualization of Large Complex Data in R</dcterms:abstract>
        <dc:date>09:24:30</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/hafen/trelliscope</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 09:24:30</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Article rdf:about="http://onlinelibrary.wiley.com/doi/10.1002/sta4.7/full">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
                <dc:title>Stat</dc:title>
                <prism:volume>1</prism:volume>
                <prism:number>1</prism:number>
            </bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Guha</foaf:surname>
                        <foaf:givenname>Saptarshi</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Hafen</foaf:surname>
                        <foaf:givenname>Ryan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Rounds</foaf:surname>
                        <foaf:givenname>Jeremiah</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Xia</foaf:surname>
                        <foaf:givenname>Jin</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Li</foaf:surname>
                        <foaf:givenname>Jianfu</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Xi</foaf:surname>
                        <foaf:givenname>Bowei</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Cleveland</foaf:surname>
                        <foaf:givenname>William S.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_258"/>
        <dc:title>Large complex data: divide and recombine (D&amp;R) with RHIPE</dc:title>
        <bib:pages>53–67</bib:pages>
        <dc:date>2012</dc:date>
        <z:shortTitle>Large complex data</z:shortTitle>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://onlinelibrary.wiley.com/doi/10.1002/sta4.7/full</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 09:25:29</dcterms:dateSubmitted>
        <z:libraryCatalog>Google Scholar</z:libraryCatalog>
    </bib:Article>
    <z:Attachment rdf:about="#item_258">
        <z:itemType>attachment</z:itemType>
        <dc:title>Guha_et_al_2012_Large_complex_data.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <rdf:Description rdf:about="http://machinelearning.wustl.edu/mlpapers/paper_files/AISTATS09_GuhaKHC.pdf">
        <z:itemType>conferencePaper</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Guha</foaf:surname>
                        <foaf:givenname>Saptarshi</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kidwell</foaf:surname>
                        <foaf:givenname>Paul</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Hafen</foaf:surname>
                        <foaf:givenname>Ryan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Cleveland</foaf:surname>
                        <foaf:givenname>William S.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_190"/>
        <dc:title>Visualization databases for the analysis of large complex datasets</dc:title>
        <dc:date>2009</dc:date>
        <bib:pages>193–200</bib:pages>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://machinelearning.wustl.edu/mlpapers/paper_files/AISTATS09_GuhaKHC.pdf</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 09:26:11</dcterms:dateSubmitted>
        <z:libraryCatalog>Google Scholar</z:libraryCatalog>
    </rdf:Description>
    <z:Attachment rdf:about="#item_190">
        <z:itemType>attachment</z:itemType>
        <dc:title>Guha_et_al_2009_Visualization_databases_for_the_analysis_of_large_complex_datasets.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Data rdf:about="http://www.qlikview.com/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>QlikTech</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>QlikView</dc:title>
        <dc:date>10:55:49</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://www.qlikview.com/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-09 10:55:49</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/hafen/datadr">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Hafen</foaf:surname>
                        <foaf:givenname>Ryan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>datadr</dc:title>
        <dcterms:abstract>datadr - Divide and Recombine</dcterms:abstract>
        <dc:date>09:26:50</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/hafen/datadr</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 09:26:50</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="http://opentsdb.net/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>The OpenTSDB Authors</foaf:surname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Sigoure</foaf:surname>
                        <foaf:givenname>Benoit</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Anderson</foaf:surname>
                        <foaf:givenname>Geoffrey</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Savin</foaf:surname>
                        <foaf:givenname>Ion</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Moss</foaf:surname>
                        <foaf:givenname>Will</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <bib:contributors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Arista Networks</foaf:surname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Betfair Group</foaf:surname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                   <foaf:Person><foaf:surname>Box</foaf:surname></foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Bump Technologies</foaf:surname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>StumbleUpon</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:contributors>
        <dc:title>OpenTSDB</dc:title>
        <dc:date>09:32:28</dc:date>
        <dc:identifier>
           <dcterms:URI><rdf:value>http://opentsdb.net/</rdf:value></dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 09:32:28</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/OpenTSDB/asynchbase">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Sigoure</foaf:surname>
                        <foaf:givenname>Benoit</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Bajaria</foaf:surname>
                        <foaf:givenname>Viral</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <bib:contributors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>StumbleUpon</foaf:surname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Arista Networks</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:contributors>
        <dc:title>AsyncHBase</dc:title>
        <dcterms:abstract>asynchbase - A fully asynchronous, non-blocking, thread-safe, high-performance HBase client.</dcterms:abstract>
        <dc:date>09:34:33</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/OpenTSDB/asynchbase</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 09:34:33</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="http://akka.io/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Typesafe</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Akka</dc:title>
        <dc:date>09:39:54</dc:date>
        <dc:identifier>
           <dcterms:URI><rdf:value>http://akka.io/</rdf:value></dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 09:39:54</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="http://redis.io/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Sanfilippo</foaf:surname>
                        <foaf:givenname>Salvatore</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Redis</dc:title>
        <dc:date>09:40:34</dc:date>
        <dc:identifier>
           <dcterms:URI><rdf:value>http://redis.io/</rdf:value></dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 09:40:34</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://code.google.com/p/protobuf/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Google</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Protocol Buffers</dc:title>
        <dcterms:abstract>Protocol Buffers - Google's data interchange format</dcterms:abstract>
        <dc:date>09:45:37</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://code.google.com/p/protobuf/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 09:45:37</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/twitter/finagle">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Twitter</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Finagle</dc:title>
        <dcterms:abstract>finagle - A fault tolerant, protocol-agnostic RPC system</dcterms:abstract>
        <dc:date>09:49:04</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/twitter/finagle</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 09:49:04</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="http://www.karmasphere.com/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Karmasphere</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Karmasphere</dc:title>
        <dcterms:abstract>Natively designed for Hadoop, Karmasphere is a unified workspace for full-fidelity Big Data Analytics that provides access to all the data in its original form to preserve richness and flexibility.</dcterms:abstract>
        <dc:date>09:52:22</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://www.karmasphere.com/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 09:52:22</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="http://parquet.io/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Twitter</foaf:surname></foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Cloudera</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Parquet</dc:title>
        <dcterms:abstract>Columnar Storage for Hadoop</dcterms:abstract>
        <dc:date>09:55:21</dc:date>
        <dc:identifier>
           <dcterms:URI><rdf:value>http://parquet.io/</rdf:value></dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 09:55:21</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="http://www.jboss.org/drools/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Redhat</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Drools</dc:title>
        <dc:date>10:02:40</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://www.jboss.org/drools/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 10:02:40</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="http://www.mongodb.org/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>MongoDB</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>MongoDB</dc:title>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://www.mongodb.org/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/quantcast/qfs">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Quantcast</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>QFS</dc:title>
        <dcterms:abstract>qfs - Quantcast File System</dcterms:abstract>
        <dc:date>10:07:59</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/quantcast/qfs</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 10:07:59</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="http://www.talend.com/products/big-data">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Talend</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Talend Big Data</dc:title>
        <dc:date>10:11:42</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://www.talend.com/products/big-data</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 10:11:42</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://launchpad.net/stado">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Stado Global Development Group</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Stado</dc:title>
        <dc:date>10:13:14</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://launchpad.net/stado</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 10:13:14</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="http://avro.apache.org/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Apache Software Foundation</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Apache Avro</dc:title>
        <dc:date>10:14:10</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://avro.apache.org/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 10:14:10</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Book rdf:about="urn:isbn:9781849514736">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
               <foaf:name>Packt Publishing Ltd</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Bowen</foaf:surname>
                        <foaf:givenname>Jonathan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Getting Started with Talend Open Studio for Data Integration</dc:title>
        <dcterms:abstract>Getting Started with Talend Open Studio for Data Integration takes a step-by-step, hands-on approach to learning with lots of examples and clear instructions. Are you a developer, business analyst, project manager, business intelligence specialist, system architect or a consultant who needs to undertake integration projects, then this book is for you. The book assumes a certain level of familiarity with Relational database management systems with SQL and experience and Java.</dcterms:abstract>
        <dc:date>2012</dc:date>
        <z:numPages>408</z:numPages>
        <z:language>en</z:language>
        <dc:identifier>ISBN 9781849514736</dc:identifier>
        <z:libraryCatalog>Google Books</z:libraryCatalog>
    </bib:Book>
    <bib:Data rdf:about="https://github.com/sematext/HBaseHUT">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Sematext Group</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>HBaseHUT</dc:title>
        <dcterms:abstract>HBaseHUT - HBase High Update Throughput</dcterms:abstract>
        <dc:date>13:19:05</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/sematext/HBaseHUT</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 13:19:05</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/sematext/HBaseWD">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Sematext Group</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>HBaseWD</dc:title>
        <dcterms:abstract>HBaseWD - HBase Writes Distributor</dcterms:abstract>
        <dc:date>13:19:38</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/sematext/HBaseWD</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 13:19:38</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/twitter/hraven">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Twitter</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>hRaven</dc:title>
        <dcterms:abstract>hraven - hRaven collects run time data and statistics from MapReduce jobs in an easily queryable format</dcterms:abstract>
        <dc:date>13:20:23</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/twitter/hraven</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 13:20:23</dcterms:dateSubmitted>
    </bib:Data>
    <rdf:Description rdf:about="http://x86.cs.duke.edu/~gang/documents/CIDR11_Paper36.pdf">
        <z:itemType>conferencePaper</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Herodotou</foaf:surname>
                        <foaf:givenname>Herodotos</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lim</foaf:surname>
                        <foaf:givenname>Harold</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Luo</foaf:surname>
                        <foaf:givenname>Gang</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Borisov</foaf:surname>
                        <foaf:givenname>Nedyalko</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Dong</foaf:surname>
                        <foaf:givenname>Liang</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Cetin</foaf:surname>
                        <foaf:givenname>Fatma Bilgen</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Babu</foaf:surname>
                        <foaf:givenname>Shivnath</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_234"/>
        <dc:title>Starfish: A Self-tuning System for Big Data Analytics.</dc:title>
        <dc:date>2011</dc:date>
        <prism:volume>11</prism:volume>
        <bib:pages>261–272</bib:pages>
        <z:shortTitle>Starfish</z:shortTitle>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://x86.cs.duke.edu/~gang/documents/CIDR11_Paper36.pdf</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 13:22:13</dcterms:dateSubmitted>
        <z:libraryCatalog>Google Scholar</z:libraryCatalog>
    </rdf:Description>
    <z:Attachment rdf:about="#item_234">
        <z:itemType>attachment</z:itemType>
        <dc:title>Herodotou_et_al_2011_Starfish.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Data rdf:about="http://www.tableausoftware.com">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Tableau Software</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Tableau</dc:title>
        <dc:date>11:00:58</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://www.tableausoftware.com</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-09 11:00:58</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="http://www.cs.duke.edu/starfish/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Herodotou</foaf:surname>
                        <foaf:givenname>Herodotos</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lim</foaf:surname>
                        <foaf:givenname>Harold</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Luo</foaf:surname>
                        <foaf:givenname>Gang</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Borisov</foaf:surname>
                        <foaf:givenname>Nedyalko</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Dong</foaf:surname>
                        <foaf:givenname>Liang</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Cetin</foaf:surname>
                        <foaf:givenname>Fatma Bilgen</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Babu</foaf:surname>
                        <foaf:givenname>Shivnath</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Li</foaf:surname>
                        <foaf:givenname>Jie</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Agarwal</foaf:surname>
                        <foaf:givenname>Kunal</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Dong</foaf:surname>
                        <foaf:givenname>Fei</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Starfish</dc:title>
        <dcterms:abstract>Self-tuning Analytics System</dcterms:abstract>
        <dc:date>13:22:13</dc:date>
        <z:shortTitle>Starfish</z:shortTitle>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://www.cs.duke.edu/starfish/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 13:22:13</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/nathanmarz/cascalog">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Marz</foaf:surname>
                        <foaf:givenname>Nathan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Cascalog</dc:title>
        <dcterms:abstract>cascalog - Data processing on Hadoop without the hassle.</dcterms:abstract>
        <dc:date>13:28:36</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/nathanmarz/cascalog</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 13:28:36</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="http://automic.com/the-automation-engine/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Automic (UC4)</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>ONE Automation</dc:title>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://automic.com/the-automation-engine/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/Netflix/exhibitor">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Netflix</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Exhibitor</dc:title>
        <dcterms:abstract>exhibitor - ZooKeeper co-process for instance monitoring, backup/recovery, cleanup and visualization.</dcterms:abstract>
        <dc:date>13:38:24</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/Netflix/exhibitor</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 13:38:24</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/Netflix/Lipstick">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Netflix</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Lipstick</dc:title>
        <dcterms:abstract>Lipstick - Pig Visualization framework</dcterms:abstract>
        <dc:date>13:38:42</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/Netflix/Lipstick</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 13:38:42</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/Netflix/SimianArmy">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>Netflix</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>SimianArmy</dc:title>
        <dcterms:abstract>SimianArmy - Tools for keeping your cloud operating in top form. Chaos Monkey is a resiliency tool that helps applications tolerate random instance failures.</dcterms:abstract>
        <dc:date>13:39:03</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/Netflix/SimianArmy</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-06 13:39:03</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="http://www.postgresql.org/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>The PostgreSQL Global Development Group</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>PostgreSQL</dc:title>
        <dc:date>11:40:33</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://www.postgresql.org/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-09 11:40:33</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="http://thrift.apache.org/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Apache Software Foundation</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:subject>framework</dc:subject>
        <dc:title>Apache Thrift</dc:title>
        <dc:date>11:45:38</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://thrift.apache.org/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-09 11:45:38</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/infochimps/wukong">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Infochimps</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Wukong</dc:title>
        <dcterms:abstract>wukong - Ruby libraries for efficient, effective Hadoop streaming</dcterms:abstract>
        <dc:date>12:12:51</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/infochimps/wukong</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-09 12:12:51</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="http://linkeddata.org/">
        <z:itemType>computerProgram</z:itemType>
        <dc:title>Linked Data</dc:title>
        <dc:date>12:36:26</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://linkeddata.org/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-09 12:36:26</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="http://www.scala-lang.org/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>EPFL</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Scala</dc:title>
        <dc:date>12:42:47</dc:date>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://www.scala-lang.org/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-09 12:42:47</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Book rdf:about="urn:isbn:9781935182689">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
               <foaf:name>Manning Publications Company</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Anil</foaf:surname>
                        <foaf:givenname>Robin</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Dunning</foaf:surname>
                        <foaf:givenname>Ted</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Friedman</foaf:surname>
                        <foaf:givenname>Ellen</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computers / Programming Languages / Java</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:title>Mahout in Action</dc:title>
        <dcterms:abstract>SummaryMahout in Action is a hands-on introduction to machine learning with Apache Mahout. Following real-world examples, the book presents practical use cases and then illustrates how Mahout can be applied to solve them. Includes a free audio- and video-enhanced ebook. About the TechnologyA computer system that learns and adapts as it collects data can be really powerful. Mahout, Apache's open source machine learning project, captures the core algorithms of recommendation systems, classification, and clustering in ready-to-use, scalable libraries. With Mahout, you can immediately apply to your own projects the machine learning techniques that drive Amazon, Netflix, and others. About this BookThis book covers machine learning using Apache Mahout. Based on experience with real-world applications, it introduces practical use cases and illustrates how Mahout can be applied to solve them. It places particular focus on issues of scalability and how to apply these techniques against large data sets using the Apache Hadoop framework.This book is written for developers familiar with Java -- no prior experience with Mahout is assumed.Owners of a Manning pBook purchased anywhere in the world can download a free eBook from manning.com at any time. They can do so multiple times and in any or all formats available (PDF, ePub or Kindle). To do so, customers must register their printed copy on Manning's site by creating a user account and then following instructions printed on the pBook registration insert at the front of the book. What's InsideUse group data to make individual recommendations Find logical clusters within your data Filter and refine with on-the-fly classification Free audio and video extrasTable of ContentsMeet Apache Mahout PART 1 RECOMMENDATIONS Introducing recommenders Representing recommender data Making recommendations Taking recommenders to production Distributing recommendation computations PART 2 CLUSTERING Introduction to clustering Representing data Clustering algorithms in Mahout Evaluating and improving clustering quality Taking clustering to production Real-world applications of clustering PART 3 CLASSIFICATION Introduction to classification Training a classifier  Evaluating and tuning a classifier Deploying a classifier Case study: Shop It To Me</dcterms:abstract>
        <dc:date>2011-07-15</dc:date>
        <z:numPages>387</z:numPages>
        <z:language>en</z:language>
        <dc:identifier>ISBN 9781935182689</dc:identifier>
        <z:libraryCatalog>Google Books</z:libraryCatalog>
    </bib:Book>
    <bib:Document rdf:about="http://www.r-bloggers.com/mahout-for-r-users/">
        <z:itemType>blogPost</z:itemType>
        <dcterms:isPartOf>
           <z:Blog><dc:title>R-bloggers</dc:title></z:Blog>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Raper</foaf:surname>
                        <foaf:givenname>Simon</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Mahout for R Users</dc:title>
        <dcterms:abstract>I have a few posts coming up on Apache Mahout so I thought it might be useful to share some notes. I came at it as primarily an R coder with some very rusty Java and C++ somewhere in the back of my head so that will be my point of reference. I’ve also included … Continue reading »</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.r-bloggers.com/mahout-for-r-users/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-10 17:19:46</dcterms:dateSubmitted>
    </bib:Document>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/tdunning/using-mahout-and-a-search-engine-for-recommendation">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Dunning</foaf:surname>
                        <foaf:givenname>Ted</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <link:link rdf:resource="#item_10"/>
        <dc:title>Using Mahout and a Search Engine for Recommendation</dc:title>
        <dcterms:abstract>I presented this talk at the Open World Forum in Paris in 2013.  The ideas here are that you can do basic recommendations and extended forms of recommendation such as intelligent search or cross recommendation or multi-modal recommendation using Mahout's cooccurrence analysis together with a search engine.</dcterms:abstract>
        <z:type>Technology</z:type>
        <dc:date>Sat Oct 05  2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/tdunning/using-mahout-and-a-search-engine-for-recommendation</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-10 17:22:21</dcterms:dateSubmitted>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <z:Attachment rdf:about="#item_10">
        <z:itemType>attachment</z:itemType>
        <dc:title>Dunning_2013_Using_Mahout_and_a_Search_Engine_for_Recommendation.pptx</dc:title>
        <link:type>application/vnd.openxmlformats-officedocument.presentationml.presentation</link:type>
    </z:Attachment>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/allenday54/20130905-singapore-big-datasg">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Day</foaf:surname>
                        <foaf:givenname>Allen</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <link:link rdf:resource="#item_1232"/>
        <dc:title>Data Platform Design Patterns</dc:title>
        <z:type>Education</z:type>
        <dc:date>Tue Sep 17  2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/allenday54/20130905-singapore-big-datasg</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-10 17:47:32</dcterms:dateSubmitted>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <z:Attachment rdf:about="#item_1232">
        <z:itemType>attachment</z:itemType>
        <dc:title>Allen_Day_2013_2013.pptx</dc:title>
        <link:type>application/vnd.openxmlformats-officedocument.presentationml.presentation</link:type>
    </z:Attachment>
    <bib:Book rdf:about="urn:isbn:1118010647">
        <z:itemType>book</z:itemType>
        <dc:publisher>
            <foaf:Organization>
               <foaf:name>John Wiley &amp; Sons</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Huber</foaf:surname>
                        <foaf:givenname>Peter J.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:subject>
            <z:AutomaticTag>
                <rdf:value>Mathematics / Probability &amp; Statistics / General</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:title>Data Analysis: What Can Be Learned From the Past 50 Years</dc:title>
        <dcterms:abstract>This book explores the many provocative questions concerning the fundamentals of data analysis. It is based on the time-tested experience of one of the gurus of the subject matter. Why should one study data analysis? How should it be taught? What techniques work best, and for whom? How valid are the results? How much data should be tested? Which machine languages should be used, if used at all? Emphasis on apprenticeship (through hands-on case studies) and anecdotes (through real-life applications) are the tools that Peter J. Huber uses in this volume. Concern with specific statistical techniques is not of immediate value; rather, questions of strategy – when to use which technique – are employed. Central to the discussion is an understanding of the significance of massive (or robust) data sets, the implementation of languages, and the use of models. Each is sprinkled with an ample number of examples and case studies. Personal practices, various pitfalls, and existing controversies are presented when applicable. The book serves as an excellent philosophical and historical companion to any present-day text in data analysis, robust statistics, data mining, statistical learning, or computational statistics.</dcterms:abstract>
        <dc:date>2012-01-09</dc:date>
        <z:numPages>228</z:numPages>
        <z:language>en</z:language>
        <dc:identifier>ISBN 1118010647</dc:identifier>
        <z:shortTitle>Data Analysis</z:shortTitle>
        <z:libraryCatalog>Google Books</z:libraryCatalog>
    </bib:Book>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/allenday54/20130617-new-york-open-analytics-summit-no-sql-and-sql">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Day</foaf:surname>
                        <foaf:givenname>Allen</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <link:link rdf:resource="#item_1235"/>
        <dc:title>NoSQL and SQL Work Side-by-Side to Tackle Real-time Big Data Needs</dc:title>
        <dc:date>Tue Sep 17  2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/allenday54/20130617-new-york-open-analytics-summit-no-sql-and-sql</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-10 17:48:21</dcterms:dateSubmitted>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <z:Attachment rdf:about="#item_1235">
        <z:itemType>attachment</z:itemType>
        <dc:title>Allen_Day_2013_20132.pptx</dc:title>
        <link:type>application/vnd.openxmlformats-officedocument.presentationml.presentation</link:type>
    </z:Attachment>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/matthewterencehayes/hourglass-a-library-for-incremental-processing-on-hadoop">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Hayes</foaf:surname>
                        <foaf:givenname>Matthew</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <link:link rdf:resource="#item_1238"/>
        <dc:title>Hourglass: a Library for Incremental Processing on Hadoop</dc:title>
        <dcterms:abstract>Slides from my talk at IEEE BigData 2013 presenting our paper &quot;Hourglass: a Library for Incremental Processing on Hadoop&quot;

Abstract:
Hadoop enables processing of large data sets through its relatively easy-to-use semantics. However, jobs are often written inefficiently for tasks that could be computed incrementally due to the burdensome incremental state management for the programmer. This paper introduces Hourglass, a library for developing incremental monoid computations on Hadoop. It runs on unmodified Hadoop and provides an accumulator-based interface for programmers to store and use state across successive runs; the framework ensures that only the necessary subcomputations are performed. It is successfully used at LinkedIn, one of the largest online social networks, for many use cases in dashboarding and machine learning. Hourglass is open source and freely available.</dcterms:abstract>
        <z:type>Education</z:type>
        <dc:date>Wed Oct 09  2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/matthewterencehayes/hourglass-a-library-for-incremental-processing-on-hadoop</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-12 17:07:17</dcterms:dateSubmitted>
        <z:shortTitle>Hourglass</z:shortTitle>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <z:Attachment rdf:about="#item_1238">
        <z:itemType>attachment</z:itemType>
        <dc:title>Matthew_Hayes_2013_Hourglass.pptx</dc:title>
        <link:type>application/vnd.openxmlformats-officedocument.presentationml.presentation</link:type>
    </z:Attachment>
    <bib:Data rdf:about="https://github.com/linkedin/camus">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>LinkedIn</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Camus</dc:title>
        <dcterms:abstract>Camus is LinkedIn's Kafka --> HDFS pipeline. It is a mapreduce job that does distributed data loads out of Kafka. The code includes automatic discovery of topics, Avro schema management and creation of folders partitioned by date and hour.</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/linkedin/camus</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-12 17:19:03</dcterms:dateSubmitted>
    </bib:Data>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/matthewterencehayes/building-data-products-at-linkedin-with-datafu">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Hayes</foaf:surname>
                        <foaf:givenname>Matthew</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <link:link rdf:resource="#item_1241"/>
        <dc:title>Building Data Products at LinkedIn with DataFu</dc:title>
        <dcterms:abstract>Examples of buildi</dcterms:abstract>
        <z:type>Technology</z:type>
        <dc:date>Mon Aug 26  2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/matthewterencehayes/building-data-products-at-linkedin-with-datafu</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-12 17:09:00</dcterms:dateSubmitted>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <z:Attachment rdf:about="#item_1241">
        <z:itemType>attachment</z:itemType>
        <dc:title>Matthew_Hayes_2013_Building_Data_Products_at_LinkedIn_with_DataFu.pptx</dc:title>
        <link:type>application/vnd.openxmlformats-officedocument.presentationml.presentation</link:type>
    </z:Attachment>
    <bib:Data rdf:about="https://github.com/linkedin/white-elephant">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>LinkedIn</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>White Elephant</dc:title>
        <dcterms:abstract>white-elephant - Hadoop log aggregator and dashboard</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/linkedin/white-elephant</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-12 17:11:14</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/chrislongo/Pig">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Longo</foaf:surname>
                        <foaf:givenname>Chris</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Pig for Sublime Text</dc:title>
        <dcterms:abstract>Package for Apache Pig support in Sublime Text 2</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/chrislongo/Pig</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-12 17:12:55</dcterms:dateSubmitted>
    </bib:Data>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/Hadoop_Summit/kamat-singh-june27425pmroom210cv2">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kamat</foaf:surname>
                        <foaf:givenname>Govind</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Singh</foaf:surname>
                        <foaf:givenname>Sumeet</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <link:link rdf:resource="#item_13"/>
        <dc:title>Compression Options in Hadoop - A Tale of Tradeoffs</dc:title>
        <dcterms:abstract>Yahoo! is one of the most-visited web sites in the world. It runs one of the largest private cloud infrastructures, one that operates on petabytes of data every day. Being able to store and manage that data well is essential to the efficient functioning of Yahoo!`s Hadoop clusters. A key component that enables this efficient operation is data compression. With regard to compression algorithms, there is an underlying tension between compression ratio and compression performance. Consequently, Hadoop provides support for several compression algorithms, including gzip, bzip2, Snappy, LZ4 and others. This plethora of options can make it difficult for users to select appropriate codecs for their MapReduce jobs. This paper attempts to provide guidance in that regard. Performance results with Gridmix and with several corpuses of data are presented. The paper also describes enhancements we have made to the bzip2 codec that improve its performance. This will be of particular interest to the increasing number of users operating on “Big Data” who require the best possible ratios. The impact of using the Intel IPP libraries is also investigated; these have the potential to improve performance significantly. Finally, a few proposals for future enhancements to Hadoop in this area are outlined.</dcterms:abstract>
        <dc:date>Wed Jul 10  2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/Hadoop_Summit/kamat-singh-june27425pmroom210cv2</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-12 23:05:05</dcterms:dateSubmitted>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <z:Attachment rdf:about="#item_13">
        <z:itemType>attachment</z:itemType>
        <dc:title>Kamat_Singh_2013_Compression_Options_in_Hadoop_-_A_Tale_of_Tradeoffs.pptx</dc:title>
        <link:type>application/vnd.openxmlformats-officedocument.presentationml.presentation</link:type>
    </z:Attachment>
    <bib:Data rdf:about="http://nutch.apache.org/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Apache Software Foundation</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Apache Nutch</dc:title>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://nutch.apache.org/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-14 22:05:41</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/senseidb/sensei">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>SenseiDB</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>SenseiDB</dc:title>
        <dcterms:abstract>Open-source, distributed, realtime, semi-structured database</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/senseidb/sensei</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-12 17:22:37</dcterms:dateSubmitted>
    </bib:Data>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/matthewterencehayes/datafu">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Hayes</foaf:surname>
                        <foaf:givenname>Matthew</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <link:link rdf:resource="#item_431"/>
        <dc:title>A Brief Tour of DataFu</dc:title>
        <dcterms:abstract>DataFu is a collection of user-defined functions for working with large-scale data in Hadoop and Pig. This library was born out of the need for a stable, well-tested library of UDFs for data mining and statistics. It is used at LinkedIn in many of our off-line workflows for data derived products like “People You May Know” and “Skills”.  It contains functions for:

* PageRank
* Quantiles (median), variance, etc.
* Sessionization
* Convenience bag functions (e.g., set operations, enumerating bags, etc)
* Convenience utility functions (e.g., assertions, easier writing of EvalFuncs)
* and more…</dcterms:abstract>
        <z:type>Design</z:type>
        <dc:date>Tue Jun 25  2013</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/matthewterencehayes/datafu</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-12 17:26:54</dcterms:dateSubmitted>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <z:Attachment rdf:about="#item_431">
        <z:itemType>attachment</z:itemType>
        <dc:title>Hayes_2013_A_Brief_Tour_of_DataFu.pptx</dc:title>
        <link:type>application/vnd.openxmlformats-officedocument.presentationml.presentation</link:type>
    </z:Attachment>
    <rdf:Description rdf:about="#item_1251">
        <z:itemType>conferencePaper</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Santa Clara, CA, USA</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Hayes</foaf:surname>
                        <foaf:givenname>Matthew</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Shah</foaf:surname>
                        <foaf:givenname>Sam</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_198"/>
        <dc:title>Hourglass: a Library for Incremental Processing on Hadoop</dc:title>
        <dcterms:abstract>This paper introduces Hourglass,
a library for developing incremental monoid computations
on Hadoop. It runs on unmodified Hadoop and provides an
accumulator-based interface for programmers to store and use
state across successive runs; the framework ensures that only
the necessary subcomputations are performed.</dcterms:abstract>
        <bib:presentedAt>
            <bib:Conference>
               <dc:title>IEEE International Conference on Big Data 2013</dc:title>
            </bib:Conference>
        </bib:presentedAt>
    </rdf:Description>
    <z:Attachment rdf:about="#item_198">
        <z:itemType>attachment</z:itemType>
        <dc:title>Hayes_Shah_Hourglass.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <rdf:Description rdf:about="http://static.usenix.org/events/usenix07/tech/full_papers/shah/shah_html/">
        <z:itemType>conferencePaper</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Shah</foaf:surname>
                        <foaf:givenname>Sam</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Soules</foaf:surname>
                        <foaf:givenname>Craig AN</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ganger</foaf:surname>
                        <foaf:givenname>Gregory R.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Noble</foaf:surname>
                        <foaf:givenname>Brian D.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_345"/>
        <dc:title>Using Provenance to Aid in Personal File Search.</dc:title>
        <dc:date>2007</dc:date>
        <dc:title>USENIX Annual Technical Conference</dc:title>
        <bib:pages>171–184</bib:pages>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://static.usenix.org/events/usenix07/tech/full_papers/shah/shah_html/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-12 17:37:03</dcterms:dateSubmitted>
        <z:libraryCatalog>Google Scholar</z:libraryCatalog>
    </rdf:Description>
    <z:Attachment rdf:about="#item_345">
        <z:itemType>attachment</z:itemType>
        <dc:title>Using Provenance to Aid in Pers - Sam Shah.azw3</dc:title>
        <link:type>application/octet-stream</link:type>
    </z:Attachment>
    <bib:Data rdf:about="https://github.com/internetarchive/heritrix3">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Internet Archive</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Heritrix</dc:title>
        <dcterms:abstract>heritrix3 - Heritrix is the Internet Archive's open-source, extensible, web-scale, archival-quality web crawler project.</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/internetarchive/heritrix3</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-12 23:07:44</dcterms:dateSubmitted>
    </bib:Data>
    <bib:ConferenceProceedings rdf:about="http://infolab.stanford.edu/wac/aaronBinnsTalk2012/index.html#slide1">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Binns</foaf:surname>
                        <foaf:givenname>Aaron</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <link:link rdf:resource="#item_1262"/>
        <dc:title>Web Analytics with Hadoop and Pig</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://infolab.stanford.edu/wac/aaronBinnsTalk2012/index.html#slide1</rdf:value>
            </dcterms:URI>
        </dc:identifier>
    </bib:ConferenceProceedings>
    <z:Attachment rdf:about="#item_1262">
        <z:itemType>attachment</z:itemType>
        <dc:title>Binns_Web_Analytics_with_Hadoop_and_Pig.zip</dc:title>
        <link:type>application/x-zip-compressed</link:type>
    </z:Attachment>
    <bib:Recording rdf:about="http://vimeo.com/59207751">
        <z:itemType>videoRecording</z:itemType>
        <z:directors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Deepspeed media</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:directors>
        <dc:title>Internet Archive</dc:title>
        <dcterms:abstract>Archive is a documentary focused on the future of long-term digital storage, the history of the Internet and attempts to preserve its contents on a massive scale.…</dcterms:abstract>
        <dc:date>2013-02-08</dc:date>
        <z:runningTime>PT00H13M04S</z:runningTime>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://vimeo.com/59207751</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-12 23:18:31</dcterms:dateSubmitted>
        <z:libraryCatalog>vimeo.com</z:libraryCatalog>
    </bib:Recording>
    <bib:Data rdf:about="https://code.google.com/p/hbase-writer/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Smith</foaf:surname>
                        <foaf:givenname>Justin</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Hbase-Writer</dc:title>
        <dcterms:abstract>An Hadoop HBase WriterPool implementation for the Heritrix crawler</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://code.google.com/p/hbase-writer/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-14 22:07:51</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://code.google.com/p/crawler4j/">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ganjisaffar</foaf:surname>
                        <foaf:givenname>Yasser</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>crawler4j</dc:title>
        <dcterms:abstract>Open Source Web Crawler for Java</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://code.google.com/p/crawler4j/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-14 22:15:16</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/commoncrawl/commoncrawl-crawler">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>CommonCrawl</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>CommonCrawl Crawler</dc:title>
        <dcterms:abstract>The CommonCrawl Crawler Engine and Related MapReduce code</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://github.com/commoncrawl/commoncrawl-crawler</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-14 22:18:14</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/lintool/warcbase">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lin</foaf:surname>
                        <foaf:givenname>Jimmy</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>WarcBase</dc:title>
        <dcterms:abstract>warcbase - A web archive browser built on HBase</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/lintool/warcbase</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-14 22:21:39</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/machawk1/warcreate">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kelly</foaf:surname>
                        <foaf:givenname>Mat</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>WARCreate</dc:title>
        <dcterms:abstract>warcreate - Chrome extension to &quot;Create WARC files from any webpage&quot;</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/machawk1/warcreate</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-14 22:23:28</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/machawk1/wail">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kelly</foaf:surname>
                        <foaf:givenname>Mat</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Web Archiving Integration Layer (WAIL)</dc:title>
        <dcterms:abstract>wail - One-Click User Instigated Preservation</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/machawk1/wail</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-14 22:24:11</dcterms:dateSubmitted>
    </bib:Data>
    <bib:ConferenceProceedings rdf:about="http://www.slideshare.net/matkelly01/warcreate-create-waybackconsumable-warc-files-from-any-webpage">
        <z:itemType>presentation</z:itemType>
        <z:presenters>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kelly</foaf:surname>
                        <foaf:givenname>Mat</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:presenters>
        <link:link rdf:resource="#item_1283"/>
        <dc:title>WARCreate - Create Wayback-Consumable WARC Files from Any Webpage</dc:title>
        <dcterms:abstract>The Internet Archive's Wayback Machine is the most common way that typical users interact with web archives. The Internet Archive uses the Heritrix web crawler to transform pages on the publicly available web into Web ARChive (WARC) ⬚files, which can then be accessed using the Wayback Machine. Because Heritrix can only access the publicly available web, many personal pages (e.g., password-protected pages, social media pages) cannot be easily archivedinto the standard WARC format. We have created a GoogleChrome extension,WARCreate, that allows a user to createa WARC ⬚file from any webpage. Using this tool, content that might have been otherwise lost in time can be archived in a standard format by any user. This tool provides a way for casual users to easily create archives of personal onlinecontent. This is one of the fi⬚rst steps in resolving issues oflong term storage, maintenance, and access of personal digital assets that have emotional, intellectual, and historicalvalue to individuals</dcterms:abstract>
        <z:type>Technology</z:type>
        <dc:date>Fri Jul 27  2012</dc:date>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.slideshare.net/matkelly01/warcreate-create-waybackconsumable-warc-files-from-any-webpage</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-14 22:25:10</dcterms:dateSubmitted>
        <dc:rights>© All Rights Reserved</dc:rights>
    </bib:ConferenceProceedings>
    <z:Attachment rdf:about="#item_1283">
        <z:itemType>attachment</z:itemType>
        <dc:title>Kelly_2012_WARCreate_-_Create_Wayback-Consumable_WARC_Files_from_Any_Webpage.pptx</dc:title>
        <link:type>application/vnd.openxmlformats-officedocument.presentationml.presentation</link:type>
    </z:Attachment>
    <bib:Document rdf:about="http://www.archiveteam.org/index.php?title=The_WARC_Ecosystem">
        <z:itemType>webpage</z:itemType>
        <dcterms:isPartOf>
           <z:Website></z:Website>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Archive Team</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_22"/>
        <dc:title>The WARC Ecosystem</dc:title>
        <dcterms:abstract>Everything about the WARC format and the tools that support it.</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://www.archiveteam.org/index.php?title=The_WARC_Ecosystem</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-14 22:27:29</dcterms:dateSubmitted>
    </bib:Document>
    <z:Attachment rdf:about="#item_22">
        <z:itemType>attachment</z:itemType>
        <dc:title>The WARC Ecosystem - Archive Team.azw3</dc:title>
        <link:type>application/octet-stream</link:type>
    </z:Attachment>
    <bib:Report rdf:about="http://papers.ssrn.com/abstract=2138121">
        <z:itemType>report</z:itemType>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Rochester, NY</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Social Science Research Network</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kim</foaf:surname>
                        <foaf:givenname>Henry M.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Gel</foaf:surname>
                        <foaf:givenname>Iryna</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Cheung</foaf:surname>
                        <foaf:givenname>Ho-Nam</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_1290"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>auditor decision-making</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Belief-Desires-Intentions</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>computational ontologies</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>data analytics</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>data driven decision-making</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
           <z:AutomaticTag><rdf:value>data science</rdf:value></z:AutomaticTag>
        </dc:subject>
        <dc:title>Data Analytics Using Ontologies of Management Theories: Towards Implementing 'From Theory to Practice'</dc:title>
        <dcterms:abstract>We explore how computational ontologies can be impactful vis-à-vis the developing discipline of “data science.” We posit an approach wherein management theories are represented as formal axioms, and then applied to draw inferences about data that reside in corporate databases. That is, management theories would be implemented as rules within a data analytics engine. We demonstrate a case study development of such an ontology by formally representing an accounting theory in First-Order Logic. Though quite preliminary, the idea that an information technology, namely ontologies, can potentially actualize the academic cliché, “From Theory to Practice,” and be applicable to the burgeoning domain of data analytics is novel and exciting.</dcterms:abstract>
        <prism:number>ID 2138121</prism:number>
        <z:type>SSRN Scholarly Paper</z:type>
        <dc:date>2012/08/29</dc:date>
        <z:shortTitle>Data Analytics Using Ontologies of Management Theories</z:shortTitle>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://papers.ssrn.com/abstract=2138121</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-14 22:30:07</dcterms:dateSubmitted>
        <z:libraryCatalog>papers.ssrn.com</z:libraryCatalog>
    </bib:Report>
    <z:Attachment rdf:about="#item_1290">
        <z:itemType>attachment</z:itemType>
        <dc:title>Kim_et_al_2012_Data_Analytics_Using_Ontologies_of_Management_Theories.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Data rdf:about="https://github.com/okfn/ckan">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Open Knowledge Foundation</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>CKAN</dc:title>
        <dcterms:abstract>ckan - CKAN is an open-source DMS (data management system) for powering data hubs and data portals. CKAN makes it easy to publish, share and use data. It powers the thedatahub.org, catalog.data.gov and data.gov.uk among many other sites.</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/okfn/ckan</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-14 22:35:15</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/okfn/messytables">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Open Knowledge Foundation</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>messytables</dc:title>
        <dcterms:abstract>messytables - Tools for parsing messy tabular data.</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/okfn/messytables</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-14 22:42:57</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/okfn/dataexplorer">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Open Knowledge Foundation</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Data Explorer</dc:title>
        <dcterms:abstract>dataexplorer - View, visualize, clean and process data in the browser.</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/okfn/dataexplorer</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-14 22:44:14</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/okfn/dataproxy">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Open Knowledge Foundation</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Data Proxy</dc:title>
        <dcterms:abstract>dataproxy - Web application (targeted at appengine) to proxy data from certain data types into a JSON-P data type so that users can create mashups against remote data sets.</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/okfn/dataproxy</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-14 22:44:42</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/okfn/recline">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Open Knowledge Foundation</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>Recline.js</dc:title>
        <dcterms:abstract>recline - A simple but powerful library for building data applications in pure Javascript and HTML.</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/okfn/recline</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-14 22:44:58</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Data rdf:about="https://github.com/okfn/bibserver">
        <z:itemType>computerProgram</z:itemType>
        <z:programmers>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                       <foaf:surname>Open Knowledge Foundation</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:programmers>
        <dc:title>BibServer</dc:title>
        <dcterms:abstract>bibserver - BibServer is open-source software what makes it easy to publish, manage and find bibliographies. BibServer is RESTful and web-friendly.</dcterms:abstract>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://github.com/okfn/bibserver</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-14 22:45:33</dcterms:dateSubmitted>
    </bib:Data>
    <bib:Document rdf:about="http://blogs.ischool.berkeley.edu/i290-abdt-s12/2012/12/13/uc-berkeley-course-lectures-analyzing-big-data-with-twitter/">
        <z:itemType>webpage</z:itemType>
        <dcterms:isPartOf>
           <z:Website></z:Website>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Hearst</foaf:surname>
                        <foaf:givenname>Marti</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dc:title>Analyzing Big Data with Twitter | A special UC Berkeley iSchool course</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://blogs.ischool.berkeley.edu/i290-abdt-s12/2012/12/13/uc-berkeley-course-lectures-analyzing-big-data-with-twitter/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2013-10-15 23:52:58</dcterms:dateSubmitted>
    </bib:Document>
</rdf:RDF>
